{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Car_predictions_Assignment#1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc-dLE2s9z-V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yapWvdmbv6XQ"
      },
      "source": [
        "# **Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3FzYFJq98nD",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9752f330-cd3b-40c6-8691-f9e4303310c9"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0dc00f15-9dac-4ad8-a569-a71370b08d7a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0dc00f15-9dac-4ad8-a569-a71370b08d7a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving CarPrice_Assignment.csv to CarPrice_Assignment.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsy54TK--EWT"
      },
      "source": [
        "data = pd.read_csv(\"CarPrice_Assignment.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNnPR9ycTDKW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "f594995e-8bf2-499d-eba0-022d6f1771bc"
      },
      "source": [
        "data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>car_ID</th>\n",
              "      <th>symboling</th>\n",
              "      <th>CarName</th>\n",
              "      <th>fueltype</th>\n",
              "      <th>aspiration</th>\n",
              "      <th>doornumber</th>\n",
              "      <th>carbody</th>\n",
              "      <th>drivewheel</th>\n",
              "      <th>enginelocation</th>\n",
              "      <th>wheelbase</th>\n",
              "      <th>carlength</th>\n",
              "      <th>carwidth</th>\n",
              "      <th>carheight</th>\n",
              "      <th>curbweight</th>\n",
              "      <th>enginetype</th>\n",
              "      <th>cylindernumber</th>\n",
              "      <th>enginesize</th>\n",
              "      <th>fuelsystem</th>\n",
              "      <th>boreratio</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compressionratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peakrpm</th>\n",
              "      <th>citympg</th>\n",
              "      <th>highwaympg</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>alfa-romero giulia</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>convertible</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548</td>\n",
              "      <td>dohc</td>\n",
              "      <td>four</td>\n",
              "      <td>130</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111</td>\n",
              "      <td>5000</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>13495.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>alfa-romero stelvio</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>convertible</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548</td>\n",
              "      <td>dohc</td>\n",
              "      <td>four</td>\n",
              "      <td>130</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111</td>\n",
              "      <td>5000</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>alfa-romero Quadrifoglio</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>hatchback</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>94.5</td>\n",
              "      <td>171.2</td>\n",
              "      <td>65.5</td>\n",
              "      <td>52.4</td>\n",
              "      <td>2823</td>\n",
              "      <td>ohcv</td>\n",
              "      <td>six</td>\n",
              "      <td>152</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>2.68</td>\n",
              "      <td>3.47</td>\n",
              "      <td>9.0</td>\n",
              "      <td>154</td>\n",
              "      <td>5000</td>\n",
              "      <td>19</td>\n",
              "      <td>26</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>audi 100 ls</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.8</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.2</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2337</td>\n",
              "      <td>ohc</td>\n",
              "      <td>four</td>\n",
              "      <td>109</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>10.0</td>\n",
              "      <td>102</td>\n",
              "      <td>5500</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>13950.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>audi 100ls</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>4wd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.4</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.4</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2824</td>\n",
              "      <td>ohc</td>\n",
              "      <td>five</td>\n",
              "      <td>136</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.0</td>\n",
              "      <td>115</td>\n",
              "      <td>5500</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>17450.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>201</td>\n",
              "      <td>-1</td>\n",
              "      <td>volvo 145e (sw)</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.9</td>\n",
              "      <td>55.5</td>\n",
              "      <td>2952</td>\n",
              "      <td>ohc</td>\n",
              "      <td>four</td>\n",
              "      <td>141</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.78</td>\n",
              "      <td>3.15</td>\n",
              "      <td>9.5</td>\n",
              "      <td>114</td>\n",
              "      <td>5400</td>\n",
              "      <td>23</td>\n",
              "      <td>28</td>\n",
              "      <td>16845.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>202</td>\n",
              "      <td>-1</td>\n",
              "      <td>volvo 144ea</td>\n",
              "      <td>gas</td>\n",
              "      <td>turbo</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.8</td>\n",
              "      <td>55.5</td>\n",
              "      <td>3049</td>\n",
              "      <td>ohc</td>\n",
              "      <td>four</td>\n",
              "      <td>141</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.78</td>\n",
              "      <td>3.15</td>\n",
              "      <td>8.7</td>\n",
              "      <td>160</td>\n",
              "      <td>5300</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>19045.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>203</td>\n",
              "      <td>-1</td>\n",
              "      <td>volvo 244dl</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.9</td>\n",
              "      <td>55.5</td>\n",
              "      <td>3012</td>\n",
              "      <td>ohcv</td>\n",
              "      <td>six</td>\n",
              "      <td>173</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.58</td>\n",
              "      <td>2.87</td>\n",
              "      <td>8.8</td>\n",
              "      <td>134</td>\n",
              "      <td>5500</td>\n",
              "      <td>18</td>\n",
              "      <td>23</td>\n",
              "      <td>21485.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>204</td>\n",
              "      <td>-1</td>\n",
              "      <td>volvo 246</td>\n",
              "      <td>diesel</td>\n",
              "      <td>turbo</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.9</td>\n",
              "      <td>55.5</td>\n",
              "      <td>3217</td>\n",
              "      <td>ohc</td>\n",
              "      <td>six</td>\n",
              "      <td>145</td>\n",
              "      <td>idi</td>\n",
              "      <td>3.01</td>\n",
              "      <td>3.40</td>\n",
              "      <td>23.0</td>\n",
              "      <td>106</td>\n",
              "      <td>4800</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>22470.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>205</td>\n",
              "      <td>-1</td>\n",
              "      <td>volvo 264gl</td>\n",
              "      <td>gas</td>\n",
              "      <td>turbo</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.9</td>\n",
              "      <td>55.5</td>\n",
              "      <td>3062</td>\n",
              "      <td>ohc</td>\n",
              "      <td>four</td>\n",
              "      <td>141</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.78</td>\n",
              "      <td>3.15</td>\n",
              "      <td>9.5</td>\n",
              "      <td>114</td>\n",
              "      <td>5400</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>22625.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>205 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     car_ID  symboling                   CarName  ... citympg highwaympg    price\n",
              "0         1          3        alfa-romero giulia  ...      21         27  13495.0\n",
              "1         2          3       alfa-romero stelvio  ...      21         27  16500.0\n",
              "2         3          1  alfa-romero Quadrifoglio  ...      19         26  16500.0\n",
              "3         4          2               audi 100 ls  ...      24         30  13950.0\n",
              "4         5          2                audi 100ls  ...      18         22  17450.0\n",
              "..      ...        ...                       ...  ...     ...        ...      ...\n",
              "200     201         -1           volvo 145e (sw)  ...      23         28  16845.0\n",
              "201     202         -1               volvo 144ea  ...      19         25  19045.0\n",
              "202     203         -1               volvo 244dl  ...      18         23  21485.0\n",
              "203     204         -1                 volvo 246  ...      26         27  22470.0\n",
              "204     205         -1               volvo 264gl  ...      19         25  22625.0\n",
              "\n",
              "[205 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kTqqY7Sepjw",
        "outputId": "492431c2-cad5-462d-a511-82b520f82783"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpsyqP1W-UNu"
      },
      "source": [
        "**Checking for Null in Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhuR5xEc-SFT",
        "outputId": "1c2bf767-c0a0-46dc-b0ee-dd149115408d"
      },
      "source": [
        "data.isnull().any()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "car_ID              False\n",
              "symboling           False\n",
              "CarName             False\n",
              "fueltype            False\n",
              "aspiration          False\n",
              "doornumber          False\n",
              "carbody             False\n",
              "drivewheel          False\n",
              "enginelocation      False\n",
              "wheelbase           False\n",
              "carlength           False\n",
              "carwidth            False\n",
              "carheight           False\n",
              "curbweight          False\n",
              "enginetype          False\n",
              "cylindernumber      False\n",
              "enginesize          False\n",
              "fuelsystem          False\n",
              "boreratio           False\n",
              "stroke              False\n",
              "compressionratio    False\n",
              "horsepower          False\n",
              "peakrpm             False\n",
              "citympg             False\n",
              "highwaympg          False\n",
              "price               False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxho0hkiwGO2"
      },
      "source": [
        "# **Removing and seprating labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcZ_kHRv-nW4"
      },
      "source": [
        "del data['car_ID']\n",
        "labels = data.pop('price')\n",
        "labels.astype('int16')\n",
        "data.loc[3,'CarName'] = 'audi 100ls'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFYSdxkNwduI"
      },
      "source": [
        "# **Checking objects datatypes in dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZtOQ6Uc-7Bj",
        "outputId": "2ac62a23-613e-42fe-9f71-9858261aeb59"
      },
      "source": [
        "data_with_object_dtype = data.dtypes[data.dtypes == 'object']\n",
        "data_with_object_dtype = list(data_with_object_dtype.keys())\n",
        "data_with_object_dtype"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CarName',\n",
              " 'fueltype',\n",
              " 'aspiration',\n",
              " 'doornumber',\n",
              " 'carbody',\n",
              " 'drivewheel',\n",
              " 'enginelocation',\n",
              " 'enginetype',\n",
              " 'cylindernumber',\n",
              " 'fuelsystem']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gBeYUInxW5C"
      },
      "source": [
        "## **One Hot Encode and vertorizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8lrDVia_oPd"
      },
      "source": [
        "New_data = pd.get_dummies(data, columns=data_with_object_dtype)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "zSpBOPfWAYj8",
        "outputId": "ea63e005-01fc-438e-8804-74e65cc65531"
      },
      "source": [
        "New_data.iloc[:,1:14] -= (New_data.iloc[:,1:14]).mean()\n",
        "New_data.iloc[:,1:14] /= (New_data.iloc[:,1:14]).std()\n",
        "New_data.iloc[:,1:14]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wheelbase</th>\n",
              "      <th>carlength</th>\n",
              "      <th>carwidth</th>\n",
              "      <th>carheight</th>\n",
              "      <th>curbweight</th>\n",
              "      <th>enginesize</th>\n",
              "      <th>boreratio</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compressionratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peakrpm</th>\n",
              "      <th>citympg</th>\n",
              "      <th>highwaympg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.686643</td>\n",
              "      <td>-0.425480</td>\n",
              "      <td>-0.842719</td>\n",
              "      <td>-2.015483</td>\n",
              "      <td>-0.014531</td>\n",
              "      <td>0.074267</td>\n",
              "      <td>0.517804</td>\n",
              "      <td>-1.834886</td>\n",
              "      <td>-0.287645</td>\n",
              "      <td>0.174057</td>\n",
              "      <td>-0.262318</td>\n",
              "      <td>-0.644974</td>\n",
              "      <td>-0.544725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.686643</td>\n",
              "      <td>-0.425480</td>\n",
              "      <td>-0.842719</td>\n",
              "      <td>-2.015483</td>\n",
              "      <td>-0.014531</td>\n",
              "      <td>0.074267</td>\n",
              "      <td>0.517804</td>\n",
              "      <td>-1.834886</td>\n",
              "      <td>-0.287645</td>\n",
              "      <td>0.174057</td>\n",
              "      <td>-0.262318</td>\n",
              "      <td>-0.644974</td>\n",
              "      <td>-0.544725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.706865</td>\n",
              "      <td>-0.230948</td>\n",
              "      <td>-0.190101</td>\n",
              "      <td>-0.542200</td>\n",
              "      <td>0.513625</td>\n",
              "      <td>0.602571</td>\n",
              "      <td>-2.399008</td>\n",
              "      <td>0.684271</td>\n",
              "      <td>-0.287645</td>\n",
              "      <td>1.261448</td>\n",
              "      <td>-0.262318</td>\n",
              "      <td>-0.950684</td>\n",
              "      <td>-0.689938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.173274</td>\n",
              "      <td>0.206750</td>\n",
              "      <td>0.136209</td>\n",
              "      <td>0.235366</td>\n",
              "      <td>-0.419770</td>\n",
              "      <td>-0.430023</td>\n",
              "      <td>-0.516003</td>\n",
              "      <td>0.461055</td>\n",
              "      <td>-0.035885</td>\n",
              "      <td>-0.053537</td>\n",
              "      <td>0.785932</td>\n",
              "      <td>-0.186409</td>\n",
              "      <td>-0.109087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.106848</td>\n",
              "      <td>0.206750</td>\n",
              "      <td>0.229440</td>\n",
              "      <td>0.235366</td>\n",
              "      <td>0.515545</td>\n",
              "      <td>0.218350</td>\n",
              "      <td>-0.516003</td>\n",
              "      <td>0.461055</td>\n",
              "      <td>-0.539405</td>\n",
              "      <td>0.275209</td>\n",
              "      <td>0.785932</td>\n",
              "      <td>-1.103540</td>\n",
              "      <td>-1.270789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>1.717669</td>\n",
              "      <td>1.195622</td>\n",
              "      <td>1.394830</td>\n",
              "      <td>0.726460</td>\n",
              "      <td>0.761377</td>\n",
              "      <td>0.338419</td>\n",
              "      <td>1.662375</td>\n",
              "      <td>-0.336147</td>\n",
              "      <td>-0.161765</td>\n",
              "      <td>0.249921</td>\n",
              "      <td>0.576282</td>\n",
              "      <td>-0.339264</td>\n",
              "      <td>-0.399512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>1.717669</td>\n",
              "      <td>1.195622</td>\n",
              "      <td>1.348215</td>\n",
              "      <td>0.726460</td>\n",
              "      <td>0.947672</td>\n",
              "      <td>0.338419</td>\n",
              "      <td>1.662375</td>\n",
              "      <td>-0.336147</td>\n",
              "      <td>-0.363173</td>\n",
              "      <td>1.413178</td>\n",
              "      <td>0.366632</td>\n",
              "      <td>-0.950684</td>\n",
              "      <td>-0.835151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>1.717669</td>\n",
              "      <td>1.195622</td>\n",
              "      <td>1.394830</td>\n",
              "      <td>0.726460</td>\n",
              "      <td>0.876611</td>\n",
              "      <td>1.106861</td>\n",
              "      <td>0.923942</td>\n",
              "      <td>-1.229012</td>\n",
              "      <td>-0.337997</td>\n",
              "      <td>0.755685</td>\n",
              "      <td>0.785932</td>\n",
              "      <td>-1.103540</td>\n",
              "      <td>-1.125577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>1.717669</td>\n",
              "      <td>1.195622</td>\n",
              "      <td>1.394830</td>\n",
              "      <td>0.726460</td>\n",
              "      <td>1.270327</td>\n",
              "      <td>0.434474</td>\n",
              "      <td>-1.180593</td>\n",
              "      <td>0.461055</td>\n",
              "      <td>3.236992</td>\n",
              "      <td>0.047616</td>\n",
              "      <td>-0.681618</td>\n",
              "      <td>0.119302</td>\n",
              "      <td>-0.544725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>1.717669</td>\n",
              "      <td>1.195622</td>\n",
              "      <td>1.394830</td>\n",
              "      <td>0.726460</td>\n",
              "      <td>0.972640</td>\n",
              "      <td>0.338419</td>\n",
              "      <td>1.662375</td>\n",
              "      <td>-0.336147</td>\n",
              "      <td>-0.161765</td>\n",
              "      <td>0.249921</td>\n",
              "      <td>0.576282</td>\n",
              "      <td>-0.950684</td>\n",
              "      <td>-0.835151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>205 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     wheelbase  carlength  carwidth  ...   peakrpm   citympg  highwaympg\n",
              "0    -1.686643  -0.425480 -0.842719  ... -0.262318 -0.644974   -0.544725\n",
              "1    -1.686643  -0.425480 -0.842719  ... -0.262318 -0.644974   -0.544725\n",
              "2    -0.706865  -0.230948 -0.190101  ... -0.262318 -0.950684   -0.689938\n",
              "3     0.173274   0.206750  0.136209  ...  0.785932 -0.186409   -0.109087\n",
              "4     0.106848   0.206750  0.229440  ...  0.785932 -1.103540   -1.270789\n",
              "..         ...        ...       ...  ...       ...       ...         ...\n",
              "200   1.717669   1.195622  1.394830  ...  0.576282 -0.339264   -0.399512\n",
              "201   1.717669   1.195622  1.348215  ...  0.366632 -0.950684   -0.835151\n",
              "202   1.717669   1.195622  1.394830  ...  0.785932 -1.103540   -1.125577\n",
              "203   1.717669   1.195622  1.394830  ... -0.681618  0.119302   -0.544725\n",
              "204   1.717669   1.195622  1.394830  ...  0.576282 -0.950684   -0.835151\n",
              "\n",
              "[205 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oam5mLdCcn-"
      },
      "source": [
        "data_len = len(New_data)\n",
        "train_data = New_data.iloc[:data_len*70//100]\n",
        "test_data = New_data.iloc[data_len*70//100:]\n",
        "\n",
        "labels_len = len(labels)\n",
        "train_labels = labels.iloc[:labels_len*70//100]\n",
        "test_labels = labels.iloc[labels_len*70//100:]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "50o3fR2xOnzC",
        "outputId": "88d8ddf2-f3db-4a7e-e04f-67ee4c1acffc"
      },
      "source": [
        "New_data.describe()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symboling</th>\n",
              "      <th>wheelbase</th>\n",
              "      <th>carlength</th>\n",
              "      <th>carwidth</th>\n",
              "      <th>carheight</th>\n",
              "      <th>curbweight</th>\n",
              "      <th>enginesize</th>\n",
              "      <th>boreratio</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compressionratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peakrpm</th>\n",
              "      <th>citympg</th>\n",
              "      <th>highwaympg</th>\n",
              "      <th>CarName_Nissan versa</th>\n",
              "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
              "      <th>CarName_alfa-romero giulia</th>\n",
              "      <th>CarName_alfa-romero stelvio</th>\n",
              "      <th>CarName_audi 100ls</th>\n",
              "      <th>CarName_audi 4000</th>\n",
              "      <th>CarName_audi 5000</th>\n",
              "      <th>CarName_audi 5000s (diesel)</th>\n",
              "      <th>CarName_audi fox</th>\n",
              "      <th>CarName_bmw 320i</th>\n",
              "      <th>CarName_bmw x1</th>\n",
              "      <th>CarName_bmw x3</th>\n",
              "      <th>CarName_bmw x4</th>\n",
              "      <th>CarName_bmw x5</th>\n",
              "      <th>CarName_bmw z4</th>\n",
              "      <th>CarName_buick century</th>\n",
              "      <th>CarName_buick century luxus (sw)</th>\n",
              "      <th>CarName_buick century special</th>\n",
              "      <th>CarName_buick electra 225 custom</th>\n",
              "      <th>CarName_buick opel isuzu deluxe</th>\n",
              "      <th>CarName_buick regal sport coupe (turbo)</th>\n",
              "      <th>CarName_buick skyhawk</th>\n",
              "      <th>CarName_buick skylark</th>\n",
              "      <th>CarName_chevrolet impala</th>\n",
              "      <th>CarName_chevrolet monte carlo</th>\n",
              "      <th>CarName_chevrolet vega 2300</th>\n",
              "      <th>...</th>\n",
              "      <th>CarName_vw dasher</th>\n",
              "      <th>CarName_vw rabbit</th>\n",
              "      <th>fueltype_diesel</th>\n",
              "      <th>fueltype_gas</th>\n",
              "      <th>aspiration_std</th>\n",
              "      <th>aspiration_turbo</th>\n",
              "      <th>doornumber_four</th>\n",
              "      <th>doornumber_two</th>\n",
              "      <th>carbody_convertible</th>\n",
              "      <th>carbody_hardtop</th>\n",
              "      <th>carbody_hatchback</th>\n",
              "      <th>carbody_sedan</th>\n",
              "      <th>carbody_wagon</th>\n",
              "      <th>drivewheel_4wd</th>\n",
              "      <th>drivewheel_fwd</th>\n",
              "      <th>drivewheel_rwd</th>\n",
              "      <th>enginelocation_front</th>\n",
              "      <th>enginelocation_rear</th>\n",
              "      <th>enginetype_dohc</th>\n",
              "      <th>enginetype_dohcv</th>\n",
              "      <th>enginetype_l</th>\n",
              "      <th>enginetype_ohc</th>\n",
              "      <th>enginetype_ohcf</th>\n",
              "      <th>enginetype_ohcv</th>\n",
              "      <th>enginetype_rotor</th>\n",
              "      <th>cylindernumber_eight</th>\n",
              "      <th>cylindernumber_five</th>\n",
              "      <th>cylindernumber_four</th>\n",
              "      <th>cylindernumber_six</th>\n",
              "      <th>cylindernumber_three</th>\n",
              "      <th>cylindernumber_twelve</th>\n",
              "      <th>cylindernumber_two</th>\n",
              "      <th>fuelsystem_1bbl</th>\n",
              "      <th>fuelsystem_2bbl</th>\n",
              "      <th>fuelsystem_4bbl</th>\n",
              "      <th>fuelsystem_idi</th>\n",
              "      <th>fuelsystem_mfi</th>\n",
              "      <th>fuelsystem_mpfi</th>\n",
              "      <th>fuelsystem_spdi</th>\n",
              "      <th>fuelsystem_spfi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>205.000000</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.834146</td>\n",
              "      <td>-2.017898e-14</td>\n",
              "      <td>-1.011440e-14</td>\n",
              "      <td>1.431700e-14</td>\n",
              "      <td>-1.499613e-14</td>\n",
              "      <td>1.261863e-16</td>\n",
              "      <td>4.034713e-17</td>\n",
              "      <td>-5.910719e-15</td>\n",
              "      <td>1.766473e-14</td>\n",
              "      <td>-5.315531e-16</td>\n",
              "      <td>1.775003e-16</td>\n",
              "      <td>3.103209e-16</td>\n",
              "      <td>1.223953e-16</td>\n",
              "      <td>1.792604e-16</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.014634</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.009756</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.009756</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.902439</td>\n",
              "      <td>0.819512</td>\n",
              "      <td>0.180488</td>\n",
              "      <td>0.560976</td>\n",
              "      <td>0.439024</td>\n",
              "      <td>0.029268</td>\n",
              "      <td>0.039024</td>\n",
              "      <td>0.341463</td>\n",
              "      <td>0.468293</td>\n",
              "      <td>0.121951</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.585366</td>\n",
              "      <td>0.370732</td>\n",
              "      <td>0.985366</td>\n",
              "      <td>0.014634</td>\n",
              "      <td>0.058537</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.058537</td>\n",
              "      <td>0.721951</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>0.063415</td>\n",
              "      <td>0.019512</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.053659</td>\n",
              "      <td>0.775610</td>\n",
              "      <td>0.117073</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.019512</td>\n",
              "      <td>0.053659</td>\n",
              "      <td>0.321951</td>\n",
              "      <td>0.014634</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.458537</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.004878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.245307</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.120377</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.098531</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.098531</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>...</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.297446</td>\n",
              "      <td>0.297446</td>\n",
              "      <td>0.385535</td>\n",
              "      <td>0.385535</td>\n",
              "      <td>0.497483</td>\n",
              "      <td>0.497483</td>\n",
              "      <td>0.168970</td>\n",
              "      <td>0.194127</td>\n",
              "      <td>0.475361</td>\n",
              "      <td>0.500215</td>\n",
              "      <td>0.328031</td>\n",
              "      <td>0.205380</td>\n",
              "      <td>0.493865</td>\n",
              "      <td>0.484183</td>\n",
              "      <td>0.120377</td>\n",
              "      <td>0.120377</td>\n",
              "      <td>0.235330</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.235330</td>\n",
              "      <td>0.449134</td>\n",
              "      <td>0.261054</td>\n",
              "      <td>0.244304</td>\n",
              "      <td>0.138655</td>\n",
              "      <td>0.154635</td>\n",
              "      <td>0.225894</td>\n",
              "      <td>0.418201</td>\n",
              "      <td>0.322294</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.138655</td>\n",
              "      <td>0.225894</td>\n",
              "      <td>0.468368</td>\n",
              "      <td>0.120377</td>\n",
              "      <td>0.297446</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.499498</td>\n",
              "      <td>0.205380</td>\n",
              "      <td>0.069843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.018771e+00</td>\n",
              "      <td>-2.670706e+00</td>\n",
              "      <td>-2.614113e+00</td>\n",
              "      <td>-2.424729e+00</td>\n",
              "      <td>-2.050329e+00</td>\n",
              "      <td>-1.582686e+00</td>\n",
              "      <td>-2.915911e+00</td>\n",
              "      <td>-3.780057e+00</td>\n",
              "      <td>-7.911643e-01</td>\n",
              "      <td>-1.419099e+00</td>\n",
              "      <td>-2.044342e+00</td>\n",
              "      <td>-1.867815e+00</td>\n",
              "      <td>-2.142067e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-7.068655e-01</td>\n",
              "      <td>-6.281176e-01</td>\n",
              "      <td>-8.427194e-01</td>\n",
              "      <td>-7.058983e-01</td>\n",
              "      <td>-7.885183e-01</td>\n",
              "      <td>-7.181888e-01</td>\n",
              "      <td>-6.636894e-01</td>\n",
              "      <td>-4.636990e-01</td>\n",
              "      <td>-3.883487e-01</td>\n",
              "      <td>-8.627587e-01</td>\n",
              "      <td>-6.816179e-01</td>\n",
              "      <td>-9.506844e-01</td>\n",
              "      <td>-8.351509e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-2.917055e-01</td>\n",
              "      <td>-6.883752e-02</td>\n",
              "      <td>-1.901008e-01</td>\n",
              "      <td>1.535169e-01</td>\n",
              "      <td>-2.718864e-01</td>\n",
              "      <td>-1.658710e-01</td>\n",
              "      <td>-7.294280e-02</td>\n",
              "      <td>1.102860e-01</td>\n",
              "      <td>-2.876448e-01</td>\n",
              "      <td>-2.305542e-01</td>\n",
              "      <td>1.569818e-01</td>\n",
              "      <td>-1.864087e-01</td>\n",
              "      <td>-1.090867e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.050399e-01</td>\n",
              "      <td>7.336078e-01</td>\n",
              "      <td>4.625179e-01</td>\n",
              "      <td>7.264604e-01</td>\n",
              "      <td>7.287278e-01</td>\n",
              "      <td>3.384191e-01</td>\n",
              "      <td>9.239421e-01</td>\n",
              "      <td>4.929427e-01</td>\n",
              "      <td>-1.869408e-01</td>\n",
              "      <td>3.004976e-01</td>\n",
              "      <td>7.859315e-01</td>\n",
              "      <td>7.307221e-01</td>\n",
              "      <td>4.717647e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.677223e+00</td>\n",
              "      <td>2.759985e+00</td>\n",
              "      <td>2.979761e+00</td>\n",
              "      <td>2.486215e+00</td>\n",
              "      <td>2.900886e+00</td>\n",
              "      <td>4.780975e+00</td>\n",
              "      <td>2.253122e+00</td>\n",
              "      <td>2.916435e+00</td>\n",
              "      <td>3.236992e+00</td>\n",
              "      <td>4.650065e+00</td>\n",
              "      <td>3.092081e+00</td>\n",
              "      <td>3.634970e+00</td>\n",
              "      <td>3.376022e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 198 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        symboling     wheelbase  ...  fuelsystem_spdi  fuelsystem_spfi\n",
              "count  205.000000  2.050000e+02  ...       205.000000       205.000000\n",
              "mean     0.834146 -2.017898e-14  ...         0.043902         0.004878\n",
              "std      1.245307  1.000000e+00  ...         0.205380         0.069843\n",
              "min     -2.000000 -2.018771e+00  ...         0.000000         0.000000\n",
              "25%      0.000000 -7.068655e-01  ...         0.000000         0.000000\n",
              "50%      1.000000 -2.917055e-01  ...         0.000000         0.000000\n",
              "75%      2.000000  6.050399e-01  ...         0.000000         0.000000\n",
              "max      3.000000  3.677223e+00  ...         1.000000         1.000000\n",
              "\n",
              "[8 rows x 198 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3CYfRPqPf92"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "def Train_Me_with(activation_function=\"relu\"):\n",
        "  network = models.Sequential()\n",
        "  network.add(layers.Dense(24, activation=activation_function,input_shape=(train_data.shape[1],)))\n",
        "  network.add(layers.Dense(18, activation=activation_function))\n",
        "  network.add(layers.Dense(12, activation=activation_function))\n",
        "  network.add(layers.Dense(1))\n",
        "  network.compile(\n",
        "      optimizer=\"rmsprop\",\n",
        "      loss=\"mse\",\n",
        "      metrics=['mae']\n",
        "  )\n",
        "  return network"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjQBE9otVETt"
      },
      "source": [
        "# **MAE without K fold and with tanh**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXwUd1vURdbz",
        "outputId": "697edaa7-9438-46f0-d7a9-ff5793f4f391"
      },
      "source": [
        "Model_Results1 = Train_Me_with(activation_function=\"tanh\").fit(\n",
        "      train_data,train_labels,batch_size=32,epochs=500,validation_data=(test_data,test_labels)\n",
        "  )"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 4s 94ms/step - loss: 285903440.0000 - mae: 14230.6982 - val_loss: 146548528.0000 - val_mae: 11350.4629\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 289909909.3333 - mae: 14225.8162 - val_loss: 146536144.0000 - val_mae: 11349.9453\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 283114752.0000 - mae: 14169.6258 - val_loss: 146526640.0000 - val_mae: 11349.5352\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 296333066.6667 - mae: 14674.7074 - val_loss: 146519168.0000 - val_mae: 11349.2090\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 256148562.6667 - mae: 13686.4647 - val_loss: 146513008.0000 - val_mae: 11348.9336\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 301723394.6667 - mae: 14506.9883 - val_loss: 146507808.0000 - val_mae: 11348.6943\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 277018026.6667 - mae: 13944.6986 - val_loss: 146502880.0000 - val_mae: 11348.4736\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 264170101.3333 - mae: 13642.4889 - val_loss: 146498432.0000 - val_mae: 11348.2725\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 301066586.6667 - mae: 14580.0924 - val_loss: 146494592.0000 - val_mae: 11348.0967\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 263492322.6667 - mae: 13807.1912 - val_loss: 146490864.0000 - val_mae: 11347.9277\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 289496869.3333 - mae: 14390.9069 - val_loss: 146487472.0000 - val_mae: 11347.7744\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 298798357.3333 - mae: 14427.1981 - val_loss: 146484320.0000 - val_mae: 11347.6318\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 280182690.6667 - mae: 13965.8088 - val_loss: 146481328.0000 - val_mae: 11347.4990\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 287273968.0000 - mae: 14443.3965 - val_loss: 146478800.0000 - val_mae: 11347.3848\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 257292613.3333 - mae: 13702.1704 - val_loss: 146476304.0000 - val_mae: 11347.2725\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 293026613.3333 - mae: 14461.7598 - val_loss: 146474112.0000 - val_mae: 11347.1738\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 309156554.6667 - mae: 14623.8332 - val_loss: 146471904.0000 - val_mae: 11347.0742\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 239354976.0000 - mae: 13201.0986 - val_loss: 146469760.0000 - val_mae: 11346.9795\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 292455088.0000 - mae: 14273.3470 - val_loss: 146467840.0000 - val_mae: 11346.8955\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 257261090.6667 - mae: 13585.1903 - val_loss: 146465952.0000 - val_mae: 11346.8105\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 286995117.3333 - mae: 14197.2821 - val_loss: 146464096.0000 - val_mae: 11346.7275\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 269289320.0000 - mae: 13816.5597 - val_loss: 146462272.0000 - val_mae: 11346.6475\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 247288754.6667 - mae: 13366.7546 - val_loss: 146460512.0000 - val_mae: 11346.5684\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 277502386.6667 - mae: 14062.5049 - val_loss: 146458896.0000 - val_mae: 11346.4971\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 284900381.3333 - mae: 14196.4154 - val_loss: 146457200.0000 - val_mae: 11346.4248\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 277594533.3333 - mae: 13962.4440 - val_loss: 146455584.0000 - val_mae: 11346.3506\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 299272629.3333 - mae: 14600.6146 - val_loss: 146454000.0000 - val_mae: 11346.2812\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 276920712.0000 - mae: 14094.1896 - val_loss: 146452368.0000 - val_mae: 11346.2100\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 278112544.0000 - mae: 14182.2876 - val_loss: 146450832.0000 - val_mae: 11346.1426\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 270152170.6667 - mae: 13889.5306 - val_loss: 146449280.0000 - val_mae: 11346.0723\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 304997221.3333 - mae: 14629.3058 - val_loss: 146447760.0000 - val_mae: 11346.0059\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 300573818.6667 - mae: 14458.0869 - val_loss: 146446240.0000 - val_mae: 11345.9395\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 280008266.6667 - mae: 13917.1740 - val_loss: 146444688.0000 - val_mae: 11345.8711\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 295672368.0000 - mae: 14400.5129 - val_loss: 146443152.0000 - val_mae: 11345.8037\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 272391154.6667 - mae: 13969.7210 - val_loss: 146441648.0000 - val_mae: 11345.7383\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 288410720.0000 - mae: 14235.1372 - val_loss: 146440160.0000 - val_mae: 11345.6709\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 255907664.0000 - mae: 13643.7440 - val_loss: 146438656.0000 - val_mae: 11345.6045\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 261811058.6667 - mae: 13681.6994 - val_loss: 146437152.0000 - val_mae: 11345.5381\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 283636778.6667 - mae: 14346.7493 - val_loss: 146435632.0000 - val_mae: 11345.4717\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 256921512.0000 - mae: 13436.0321 - val_loss: 146434080.0000 - val_mae: 11345.4033\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 272471394.6667 - mae: 14031.5132 - val_loss: 146432608.0000 - val_mae: 11345.3389\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 262670290.6667 - mae: 13582.5669 - val_loss: 146431136.0000 - val_mae: 11345.2744\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 277133624.0000 - mae: 13936.7638 - val_loss: 146429648.0000 - val_mae: 11345.2080\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 309293536.0000 - mae: 14695.0628 - val_loss: 146428176.0000 - val_mae: 11345.1436\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 281562965.3333 - mae: 14046.5758 - val_loss: 146426704.0000 - val_mae: 11345.0762\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 297079706.6667 - mae: 14338.2386 - val_loss: 146425200.0000 - val_mae: 11345.0117\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 323186704.0000 - mae: 14944.7241 - val_loss: 146423728.0000 - val_mae: 11344.9463\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 308416442.6667 - mae: 14789.4201 - val_loss: 146422288.0000 - val_mae: 11344.8838\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 308697840.0000 - mae: 14888.7228 - val_loss: 146420832.0000 - val_mae: 11344.8193\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 267220464.0000 - mae: 13650.1820 - val_loss: 146419344.0000 - val_mae: 11344.7549\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 296333488.0000 - mae: 14605.9095 - val_loss: 146417936.0000 - val_mae: 11344.6904\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 282148650.6667 - mae: 14135.1222 - val_loss: 146416448.0000 - val_mae: 11344.6260\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 291208997.3333 - mae: 14567.8538 - val_loss: 146414960.0000 - val_mae: 11344.5615\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 267203029.3333 - mae: 13846.1172 - val_loss: 146413456.0000 - val_mae: 11344.4951\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 283041544.0000 - mae: 14205.6157 - val_loss: 146412016.0000 - val_mae: 11344.4307\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 271079634.6667 - mae: 13881.3301 - val_loss: 146410544.0000 - val_mae: 11344.3662\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 231220992.0000 - mae: 13041.2599 - val_loss: 146408992.0000 - val_mae: 11344.2988\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 252958770.6667 - mae: 13462.0705 - val_loss: 146407520.0000 - val_mae: 11344.2334\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 280457248.0000 - mae: 14353.9626 - val_loss: 146406064.0000 - val_mae: 11344.1689\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 278218322.6667 - mae: 14054.4102 - val_loss: 146404656.0000 - val_mae: 11344.1064\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 263646818.6667 - mae: 13806.9784 - val_loss: 146403168.0000 - val_mae: 11344.0420\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 313836757.3333 - mae: 14862.3210 - val_loss: 146401776.0000 - val_mae: 11343.9795\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 290451621.3333 - mae: 14118.4627 - val_loss: 146400304.0000 - val_mae: 11343.9150\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 296666096.0000 - mae: 14578.4486 - val_loss: 146398848.0000 - val_mae: 11343.8506\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 285523008.0000 - mae: 14249.5288 - val_loss: 146397392.0000 - val_mae: 11343.7861\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 312364320.0000 - mae: 14759.2218 - val_loss: 146395936.0000 - val_mae: 11343.7217\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 293176064.0000 - mae: 14411.1071 - val_loss: 146394448.0000 - val_mae: 11343.6572\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 279932293.3333 - mae: 13930.3680 - val_loss: 146392944.0000 - val_mae: 11343.5908\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 261225234.6667 - mae: 13757.0885 - val_loss: 146391472.0000 - val_mae: 11343.5264\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 272012245.3333 - mae: 13993.6027 - val_loss: 146390032.0000 - val_mae: 11343.4619\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 286810634.6667 - mae: 14127.6183 - val_loss: 146388528.0000 - val_mae: 11343.3955\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 296948666.6667 - mae: 14447.9950 - val_loss: 146387088.0000 - val_mae: 11343.3330\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 297148437.3333 - mae: 14434.3068 - val_loss: 146385696.0000 - val_mae: 11343.2705\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 281306949.3333 - mae: 14111.0036 - val_loss: 146384176.0000 - val_mae: 11343.2041\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 249277728.0000 - mae: 13423.7178 - val_loss: 146382688.0000 - val_mae: 11343.1367\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 261155578.6667 - mae: 13751.9160 - val_loss: 146381216.0000 - val_mae: 11343.0723\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 275248669.3333 - mae: 13792.3602 - val_loss: 146379712.0000 - val_mae: 11343.0068\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 288717402.6667 - mae: 14225.7573 - val_loss: 146378256.0000 - val_mae: 11342.9424\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 300980837.3333 - mae: 14374.0330 - val_loss: 146376832.0000 - val_mae: 11342.8799\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 271756002.6667 - mae: 14019.3665 - val_loss: 146375376.0000 - val_mae: 11342.8154\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 284467168.0000 - mae: 14190.5353 - val_loss: 146373904.0000 - val_mae: 11342.7510\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 274801133.3333 - mae: 14063.1717 - val_loss: 146372416.0000 - val_mae: 11342.6846\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 301299866.6667 - mae: 14579.0701 - val_loss: 146371008.0000 - val_mae: 11342.6240\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 319654650.6667 - mae: 15026.6978 - val_loss: 146369600.0000 - val_mae: 11342.5615\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 270511741.3333 - mae: 13772.3187 - val_loss: 146368048.0000 - val_mae: 11342.4932\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285836941.3333 - mae: 14162.6330 - val_loss: 146366592.0000 - val_mae: 11342.4287\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 302898698.6667 - mae: 14545.2718 - val_loss: 146365168.0000 - val_mae: 11342.3662\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 289931616.0000 - mae: 14471.2244 - val_loss: 146363696.0000 - val_mae: 11342.3018\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 247535733.3333 - mae: 13372.0955 - val_loss: 146362192.0000 - val_mae: 11342.2363\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 252197954.6667 - mae: 13470.9562 - val_loss: 146360688.0000 - val_mae: 11342.1689\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 274276797.3333 - mae: 13957.9181 - val_loss: 146359264.0000 - val_mae: 11342.1045\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 301572202.6667 - mae: 14460.0290 - val_loss: 146357808.0000 - val_mae: 11342.0420\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 275510325.3333 - mae: 14011.3843 - val_loss: 146356320.0000 - val_mae: 11341.9756\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 304677242.6667 - mae: 14549.0721 - val_loss: 146354864.0000 - val_mae: 11341.9111\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 319115701.3333 - mae: 14957.4858 - val_loss: 146353456.0000 - val_mae: 11341.8486\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 270613616.0000 - mae: 13837.7166 - val_loss: 146351968.0000 - val_mae: 11341.7842\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 273827757.3333 - mae: 14008.9972 - val_loss: 146350528.0000 - val_mae: 11341.7197\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 298885709.3333 - mae: 14499.2157 - val_loss: 146349024.0000 - val_mae: 11341.6533\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 251017725.3333 - mae: 13475.7858 - val_loss: 146347584.0000 - val_mae: 11341.5908\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 278105552.0000 - mae: 13860.4048 - val_loss: 146346144.0000 - val_mae: 11341.5283\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 301074090.6667 - mae: 14641.0802 - val_loss: 146344688.0000 - val_mae: 11341.4639\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 287753949.3333 - mae: 14376.3374 - val_loss: 146343216.0000 - val_mae: 11341.3975\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 273446805.3333 - mae: 13959.6401 - val_loss: 146341744.0000 - val_mae: 11341.3330\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 309554410.6667 - mae: 14668.6896 - val_loss: 146340272.0000 - val_mae: 11341.2686\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 294351290.6667 - mae: 14429.3040 - val_loss: 146338816.0000 - val_mae: 11341.2041\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 262943314.6667 - mae: 13753.9924 - val_loss: 146337328.0000 - val_mae: 11341.1387\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 275571994.6667 - mae: 14041.7803 - val_loss: 146335792.0000 - val_mae: 11341.0713\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 279606549.3333 - mae: 14053.0197 - val_loss: 146334368.0000 - val_mae: 11341.0088\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 281576064.0000 - mae: 14047.9144 - val_loss: 146332880.0000 - val_mae: 11340.9424\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 275595290.6667 - mae: 14120.2259 - val_loss: 146331456.0000 - val_mae: 11340.8799\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 312763418.6667 - mae: 14875.4403 - val_loss: 146330064.0000 - val_mae: 11340.8174\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 275563402.6667 - mae: 13992.7435 - val_loss: 146328576.0000 - val_mae: 11340.7529\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 243002602.6667 - mae: 13232.7653 - val_loss: 146327072.0000 - val_mae: 11340.6865\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 303226266.6667 - mae: 14586.1992 - val_loss: 146325600.0000 - val_mae: 11340.6221\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 278827490.6667 - mae: 14072.7451 - val_loss: 146324112.0000 - val_mae: 11340.5557\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 289007173.3333 - mae: 14436.6717 - val_loss: 146322736.0000 - val_mae: 11340.4951\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 286167752.0000 - mae: 14319.3608 - val_loss: 146321216.0000 - val_mae: 11340.4287\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 299077045.3333 - mae: 14508.1408 - val_loss: 146319776.0000 - val_mae: 11340.3643\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 286342160.0000 - mae: 14339.6048 - val_loss: 146318304.0000 - val_mae: 11340.3008\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 289399968.0000 - mae: 14225.5452 - val_loss: 146316816.0000 - val_mae: 11340.2334\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 268330589.3333 - mae: 13890.9279 - val_loss: 146315328.0000 - val_mae: 11340.1689\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 299757840.0000 - mae: 14500.4531 - val_loss: 146313872.0000 - val_mae: 11340.1045\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 281095434.6667 - mae: 14105.1180 - val_loss: 146312416.0000 - val_mae: 11340.0400\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 299315685.3333 - mae: 14555.1265 - val_loss: 146310960.0000 - val_mae: 11339.9756\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 314772581.3333 - mae: 14948.4925 - val_loss: 146309536.0000 - val_mae: 11339.9131\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 294664821.3333 - mae: 14531.4881 - val_loss: 146308048.0000 - val_mae: 11339.8486\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 280749976.0000 - mae: 14254.1966 - val_loss: 146306592.0000 - val_mae: 11339.7842\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 294777792.0000 - mae: 14324.4020 - val_loss: 146305104.0000 - val_mae: 11339.7178\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 248673362.6667 - mae: 13366.9451 - val_loss: 146303600.0000 - val_mae: 11339.6514\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 271797757.3333 - mae: 13875.4897 - val_loss: 146302112.0000 - val_mae: 11339.5869\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 267398277.3333 - mae: 13870.0488 - val_loss: 146300624.0000 - val_mae: 11339.5205\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 254577445.3333 - mae: 13391.0505 - val_loss: 146299184.0000 - val_mae: 11339.4561\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 254963853.3333 - mae: 13437.9469 - val_loss: 146297696.0000 - val_mae: 11339.3916\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 303355637.3333 - mae: 14583.0179 - val_loss: 146296304.0000 - val_mae: 11339.3291\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 281556312.0000 - mae: 14073.3215 - val_loss: 146294784.0000 - val_mae: 11339.2617\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 275064170.6667 - mae: 14114.3185 - val_loss: 146293360.0000 - val_mae: 11339.1992\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 271058472.0000 - mae: 13775.3177 - val_loss: 146291904.0000 - val_mae: 11339.1348\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 318184176.0000 - mae: 14904.5343 - val_loss: 146290464.0000 - val_mae: 11339.0713\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 288847749.3333 - mae: 14337.1499 - val_loss: 146289040.0000 - val_mae: 11339.0088\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 245500589.3333 - mae: 13432.5148 - val_loss: 146287488.0000 - val_mae: 11338.9404\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 281500384.0000 - mae: 14324.3926 - val_loss: 146286016.0000 - val_mae: 11338.8760\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 284624837.3333 - mae: 14224.0771 - val_loss: 146284544.0000 - val_mae: 11338.8115\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 281922874.6667 - mae: 14137.9495 - val_loss: 146283056.0000 - val_mae: 11338.7451\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 292726992.0000 - mae: 14399.6310 - val_loss: 146281600.0000 - val_mae: 11338.6826\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 259885168.0000 - mae: 13687.0618 - val_loss: 146280144.0000 - val_mae: 11338.6182\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 282317642.6667 - mae: 14011.1805 - val_loss: 146278672.0000 - val_mae: 11338.5518\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 300360544.0000 - mae: 14648.7344 - val_loss: 146277248.0000 - val_mae: 11338.4893\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 293466069.3333 - mae: 14603.0119 - val_loss: 146275824.0000 - val_mae: 11338.4268\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 300013978.6667 - mae: 14408.0360 - val_loss: 146274352.0000 - val_mae: 11338.3633\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 257907306.6667 - mae: 13429.5884 - val_loss: 146272816.0000 - val_mae: 11338.2939\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 279398045.3333 - mae: 14108.5894 - val_loss: 146271392.0000 - val_mae: 11338.2314\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 275518458.6667 - mae: 14082.7904 - val_loss: 146269936.0000 - val_mae: 11338.1670\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 277718781.3333 - mae: 14118.9678 - val_loss: 146268480.0000 - val_mae: 11338.1025\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 296094557.3333 - mae: 14528.3652 - val_loss: 146267008.0000 - val_mae: 11338.0381\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 314174362.6667 - mae: 14735.2620 - val_loss: 146265552.0000 - val_mae: 11337.9736\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 280970784.0000 - mae: 14192.5122 - val_loss: 146264064.0000 - val_mae: 11337.9092\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 258083522.6667 - mae: 13692.4458 - val_loss: 146262576.0000 - val_mae: 11337.8428\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 268841536.0000 - mae: 13792.5688 - val_loss: 146261120.0000 - val_mae: 11337.7783\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 292049872.0000 - mae: 14117.1051 - val_loss: 146259648.0000 - val_mae: 11337.7139\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 239305392.0000 - mae: 13109.3953 - val_loss: 146258144.0000 - val_mae: 11337.6475\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 282153954.6667 - mae: 14293.7054 - val_loss: 146256736.0000 - val_mae: 11337.5850\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 273358994.6667 - mae: 13953.1921 - val_loss: 146255264.0000 - val_mae: 11337.5205\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 284677392.0000 - mae: 14276.3675 - val_loss: 146253808.0000 - val_mae: 11337.4561\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 300031621.3333 - mae: 14536.9224 - val_loss: 146252384.0000 - val_mae: 11337.3936\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 264468453.3333 - mae: 13670.0895 - val_loss: 146250880.0000 - val_mae: 11337.3262\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 292071888.0000 - mae: 14281.6826 - val_loss: 146249440.0000 - val_mae: 11337.2617\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 276229933.3333 - mae: 13845.1932 - val_loss: 146247920.0000 - val_mae: 11337.1963\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 230188232.0000 - mae: 12931.9797 - val_loss: 146246384.0000 - val_mae: 11337.1299\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 280633914.6667 - mae: 14232.1911 - val_loss: 146244960.0000 - val_mae: 11337.0654\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 267081285.3333 - mae: 13769.3717 - val_loss: 146243536.0000 - val_mae: 11337.0029\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 302713210.6667 - mae: 14648.1688 - val_loss: 146242096.0000 - val_mae: 11336.9404\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 286777210.6667 - mae: 14282.5646 - val_loss: 146240656.0000 - val_mae: 11336.8760\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 290297722.6667 - mae: 14218.8667 - val_loss: 146239184.0000 - val_mae: 11336.8115\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285273282.6667 - mae: 14065.7804 - val_loss: 146237744.0000 - val_mae: 11336.7471\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 290188874.6667 - mae: 14381.4082 - val_loss: 146236256.0000 - val_mae: 11336.6826\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 289624234.6667 - mae: 14204.0977 - val_loss: 146234832.0000 - val_mae: 11336.6182\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 260046325.3333 - mae: 13541.7269 - val_loss: 146233344.0000 - val_mae: 11336.5537\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 242384586.6667 - mae: 13326.1406 - val_loss: 146231824.0000 - val_mae: 11336.4883\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 296218805.3333 - mae: 14526.5623 - val_loss: 146230384.0000 - val_mae: 11336.4238\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 276397597.3333 - mae: 13986.3105 - val_loss: 146228944.0000 - val_mae: 11336.3613\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 288142944.0000 - mae: 14375.4671 - val_loss: 146227504.0000 - val_mae: 11336.2959\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 282765168.0000 - mae: 14057.8372 - val_loss: 146226000.0000 - val_mae: 11336.2295\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 278988640.0000 - mae: 14015.9378 - val_loss: 146224544.0000 - val_mae: 11336.1650\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 243134690.6667 - mae: 13176.5023 - val_loss: 146223040.0000 - val_mae: 11336.0986\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 251504760.0000 - mae: 13578.2622 - val_loss: 146221584.0000 - val_mae: 11336.0361\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 280141914.6667 - mae: 14035.9808 - val_loss: 146220160.0000 - val_mae: 11335.9717\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 279865642.6667 - mae: 13961.7891 - val_loss: 146218688.0000 - val_mae: 11335.9072\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 273411610.6667 - mae: 13897.1554 - val_loss: 146217168.0000 - val_mae: 11335.8408\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 247867053.3333 - mae: 13317.0203 - val_loss: 146215696.0000 - val_mae: 11335.7744\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 300948053.3333 - mae: 14558.3875 - val_loss: 146214288.0000 - val_mae: 11335.7139\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 293016954.6667 - mae: 14285.2116 - val_loss: 146212880.0000 - val_mae: 11335.6514\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 318875792.0000 - mae: 15048.2215 - val_loss: 146211472.0000 - val_mae: 11335.5889\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 262092778.6667 - mae: 13543.0431 - val_loss: 146209984.0000 - val_mae: 11335.5225\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 260154248.0000 - mae: 13620.4012 - val_loss: 146208464.0000 - val_mae: 11335.4561\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 268640029.3333 - mae: 13879.3693 - val_loss: 146207024.0000 - val_mae: 11335.3916\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 284882138.6667 - mae: 14062.7046 - val_loss: 146205568.0000 - val_mae: 11335.3291\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 258258117.3333 - mae: 13445.1712 - val_loss: 146204080.0000 - val_mae: 11335.2617\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 282474277.3333 - mae: 14286.7747 - val_loss: 146202608.0000 - val_mae: 11335.1973\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 268625173.3333 - mae: 13910.6022 - val_loss: 146201168.0000 - val_mae: 11335.1338\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 282101018.6667 - mae: 14253.7729 - val_loss: 146199712.0000 - val_mae: 11335.0693\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 271122272.0000 - mae: 14132.0933 - val_loss: 146198224.0000 - val_mae: 11335.0049\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 283414912.0000 - mae: 14278.0304 - val_loss: 146196784.0000 - val_mae: 11334.9404\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 274606586.6667 - mae: 13848.3688 - val_loss: 146195312.0000 - val_mae: 11334.8760\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 284650842.6667 - mae: 14142.3151 - val_loss: 146193856.0000 - val_mae: 11334.8115\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 277563522.6667 - mae: 14057.2909 - val_loss: 146192400.0000 - val_mae: 11334.7471\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 290956640.0000 - mae: 14290.5138 - val_loss: 146190880.0000 - val_mae: 11334.6807\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 305718256.0000 - mae: 14520.8145 - val_loss: 146189424.0000 - val_mae: 11334.6162\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 294800869.3333 - mae: 14361.3994 - val_loss: 146187952.0000 - val_mae: 11334.5518\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 276991920.0000 - mae: 13955.4425 - val_loss: 146186512.0000 - val_mae: 11334.4883\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 275166138.6667 - mae: 14228.7682 - val_loss: 146185056.0000 - val_mae: 11334.4238\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 241573784.0000 - mae: 13181.4827 - val_loss: 146183568.0000 - val_mae: 11334.3564\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 281314330.6667 - mae: 14010.9958 - val_loss: 146182112.0000 - val_mae: 11334.2939\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 311139306.6667 - mae: 14960.7858 - val_loss: 146180656.0000 - val_mae: 11334.2295\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285205509.3333 - mae: 14184.9079 - val_loss: 146179152.0000 - val_mae: 11334.1631\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 309878522.6667 - mae: 15018.8844 - val_loss: 146177760.0000 - val_mae: 11334.1025\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 292443088.0000 - mae: 14368.0005 - val_loss: 146176304.0000 - val_mae: 11334.0361\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 250025344.0000 - mae: 13366.5431 - val_loss: 146174816.0000 - val_mae: 11333.9717\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 271793725.3333 - mae: 13866.1130 - val_loss: 146173312.0000 - val_mae: 11333.9053\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 304887674.6667 - mae: 14791.4015 - val_loss: 146171888.0000 - val_mae: 11333.8428\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 305876656.0000 - mae: 14721.4222 - val_loss: 146170448.0000 - val_mae: 11333.7783\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285136946.6667 - mae: 14115.0981 - val_loss: 146168960.0000 - val_mae: 11333.7139\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 293102554.6667 - mae: 14629.3579 - val_loss: 146167472.0000 - val_mae: 11333.6475\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 310283530.6667 - mae: 14820.9077 - val_loss: 146166064.0000 - val_mae: 11333.5850\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 262104821.3333 - mae: 13619.2839 - val_loss: 146164576.0000 - val_mae: 11333.5186\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 254386874.6667 - mae: 13266.0068 - val_loss: 146163024.0000 - val_mae: 11333.4512\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 273373706.6667 - mae: 13991.9357 - val_loss: 146161600.0000 - val_mae: 11333.3887\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 272875501.3333 - mae: 14005.1820 - val_loss: 146160176.0000 - val_mae: 11333.3242\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 287274861.3333 - mae: 14259.9647 - val_loss: 146158688.0000 - val_mae: 11333.2598\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 287153930.6667 - mae: 14182.7959 - val_loss: 146157232.0000 - val_mae: 11333.1963\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 293619194.6667 - mae: 14639.4302 - val_loss: 146155792.0000 - val_mae: 11333.1318\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 290282138.6667 - mae: 14345.2879 - val_loss: 146154336.0000 - val_mae: 11333.0674\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 294611168.0000 - mae: 14387.3385 - val_loss: 146152896.0000 - val_mae: 11333.0049\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 277086194.6667 - mae: 14159.3039 - val_loss: 146151424.0000 - val_mae: 11332.9404\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 271595213.3333 - mae: 13706.3534 - val_loss: 146149888.0000 - val_mae: 11332.8721\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 273172125.3333 - mae: 13842.1525 - val_loss: 146148448.0000 - val_mae: 11332.8076\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 265200466.6667 - mae: 13875.3576 - val_loss: 146147024.0000 - val_mae: 11332.7451\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 269030018.6667 - mae: 13810.0146 - val_loss: 146145552.0000 - val_mae: 11332.6807\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 276011789.3333 - mae: 14064.6870 - val_loss: 146144064.0000 - val_mae: 11332.6143\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 314990677.3333 - mae: 14928.5780 - val_loss: 146142640.0000 - val_mae: 11332.5518\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 275626309.3333 - mae: 13916.2298 - val_loss: 146141216.0000 - val_mae: 11332.4893\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 274750090.6667 - mae: 13955.7399 - val_loss: 146139760.0000 - val_mae: 11332.4258\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 259198218.6667 - mae: 13697.7352 - val_loss: 146138288.0000 - val_mae: 11332.3613\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 299719184.0000 - mae: 14465.6058 - val_loss: 146136864.0000 - val_mae: 11332.2988\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 267200232.0000 - mae: 13992.0334 - val_loss: 146135344.0000 - val_mae: 11332.2295\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 300792608.0000 - mae: 14741.0716 - val_loss: 146133904.0000 - val_mae: 11332.1670\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 304220754.6667 - mae: 14590.5153 - val_loss: 146132432.0000 - val_mae: 11332.1025\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 275876405.3333 - mae: 14001.8958 - val_loss: 146130944.0000 - val_mae: 11332.0361\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 280152362.6667 - mae: 13958.2196 - val_loss: 146129424.0000 - val_mae: 11331.9697\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 275630253.3333 - mae: 14037.4372 - val_loss: 146127968.0000 - val_mae: 11331.9053\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 279952565.3333 - mae: 14073.9132 - val_loss: 146126512.0000 - val_mae: 11331.8408\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 284192229.3333 - mae: 14057.1789 - val_loss: 146125088.0000 - val_mae: 11331.7783\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 256170210.6667 - mae: 13523.5573 - val_loss: 146123600.0000 - val_mae: 11331.7119\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 286055040.0000 - mae: 14350.8888 - val_loss: 146122128.0000 - val_mae: 11331.6475\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 277107296.0000 - mae: 14035.4588 - val_loss: 146120704.0000 - val_mae: 11331.5850\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 239646642.6667 - mae: 13034.8809 - val_loss: 146119184.0000 - val_mae: 11331.5166\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 280963258.6667 - mae: 13958.1976 - val_loss: 146117760.0000 - val_mae: 11331.4541\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 280350498.6667 - mae: 14273.3504 - val_loss: 146116272.0000 - val_mae: 11331.3867\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 264022706.6667 - mae: 13782.4355 - val_loss: 146114784.0000 - val_mae: 11331.3223\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 295264341.3333 - mae: 14327.9505 - val_loss: 146113344.0000 - val_mae: 11331.2588\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 259242208.0000 - mae: 13754.2404 - val_loss: 146111872.0000 - val_mae: 11331.1943\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 289563994.6667 - mae: 14482.1978 - val_loss: 146110432.0000 - val_mae: 11331.1318\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 264966941.3333 - mae: 13859.9427 - val_loss: 146108944.0000 - val_mae: 11331.0654\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 313167109.3333 - mae: 14817.8862 - val_loss: 146107568.0000 - val_mae: 11331.0049\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 267837845.3333 - mae: 13807.9993 - val_loss: 146106128.0000 - val_mae: 11330.9404\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 247105885.3333 - mae: 13408.4513 - val_loss: 146104656.0000 - val_mae: 11330.8760\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 281528424.0000 - mae: 14265.5638 - val_loss: 146103200.0000 - val_mae: 11330.8115\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 311356085.3333 - mae: 14881.7401 - val_loss: 146101728.0000 - val_mae: 11330.7471\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 245580117.3333 - mae: 13178.7840 - val_loss: 146100224.0000 - val_mae: 11330.6807\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 258666610.6667 - mae: 13583.8680 - val_loss: 146098736.0000 - val_mae: 11330.6143\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 274196226.6667 - mae: 13955.1540 - val_loss: 146097232.0000 - val_mae: 11330.5488\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 259161848.0000 - mae: 13656.6045 - val_loss: 146095728.0000 - val_mae: 11330.4834\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 249263586.6667 - mae: 13386.7098 - val_loss: 146094288.0000 - val_mae: 11330.4189\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 283002816.0000 - mae: 14237.2713 - val_loss: 146092864.0000 - val_mae: 11330.3564\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 294906309.3333 - mae: 14632.0638 - val_loss: 146091472.0000 - val_mae: 11330.2939\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 281294530.6667 - mae: 14026.6349 - val_loss: 146090000.0000 - val_mae: 11330.2295\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 315753813.3333 - mae: 14805.1860 - val_loss: 146088592.0000 - val_mae: 11330.1670\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 256742365.3333 - mae: 13646.2160 - val_loss: 146087136.0000 - val_mae: 11330.1025\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 267032536.0000 - mae: 13723.4344 - val_loss: 146085664.0000 - val_mae: 11330.0381\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 273213757.3333 - mae: 13971.3721 - val_loss: 146084176.0000 - val_mae: 11329.9717\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 290717109.3333 - mae: 14437.1789 - val_loss: 146082752.0000 - val_mae: 11329.9092\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 290472328.0000 - mae: 14272.4189 - val_loss: 146081280.0000 - val_mae: 11329.8447\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 268687621.3333 - mae: 13823.2990 - val_loss: 146079776.0000 - val_mae: 11329.7783\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 267864506.6667 - mae: 13791.8735 - val_loss: 146078304.0000 - val_mae: 11329.7139\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 269476653.3333 - mae: 13900.7534 - val_loss: 146076848.0000 - val_mae: 11329.6494\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 280444685.3333 - mae: 14181.7427 - val_loss: 146075424.0000 - val_mae: 11329.5850\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 279372277.3333 - mae: 14148.6496 - val_loss: 146073968.0000 - val_mae: 11329.5225\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 294413816.0000 - mae: 14389.6439 - val_loss: 146072512.0000 - val_mae: 11329.4580\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 295123146.6667 - mae: 14453.7285 - val_loss: 146071024.0000 - val_mae: 11329.3916\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 288998165.3333 - mae: 14256.9894 - val_loss: 146069600.0000 - val_mae: 11329.3291\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 265745488.0000 - mae: 13527.8501 - val_loss: 146068112.0000 - val_mae: 11329.2617\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 263113261.3333 - mae: 13382.0628 - val_loss: 146066624.0000 - val_mae: 11329.1973\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 291185818.6667 - mae: 14255.0228 - val_loss: 146065200.0000 - val_mae: 11329.1338\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 306865888.0000 - mae: 14766.3530 - val_loss: 146063744.0000 - val_mae: 11329.0713\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 275833072.0000 - mae: 13922.5332 - val_loss: 146062304.0000 - val_mae: 11329.0068\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 254402869.3333 - mae: 13604.6730 - val_loss: 146060784.0000 - val_mae: 11328.9404\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 236306733.3333 - mae: 13229.6921 - val_loss: 146059280.0000 - val_mae: 11328.8740\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 299026026.6667 - mae: 14589.5933 - val_loss: 146057872.0000 - val_mae: 11328.8115\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 247386792.0000 - mae: 13449.0671 - val_loss: 146056384.0000 - val_mae: 11328.7471\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 298103722.6667 - mae: 14598.5911 - val_loss: 146055008.0000 - val_mae: 11328.6846\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 288075850.6667 - mae: 14243.0226 - val_loss: 146053520.0000 - val_mae: 11328.6182\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 278164205.3333 - mae: 14090.2264 - val_loss: 146052032.0000 - val_mae: 11328.5537\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 286365621.3333 - mae: 14118.7689 - val_loss: 146050560.0000 - val_mae: 11328.4893\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 266090896.0000 - mae: 13869.2980 - val_loss: 146049088.0000 - val_mae: 11328.4258\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 301286837.3333 - mae: 14677.6650 - val_loss: 146047632.0000 - val_mae: 11328.3613\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 295632149.3333 - mae: 14443.1185 - val_loss: 146046176.0000 - val_mae: 11328.2959\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 290196592.0000 - mae: 14195.6605 - val_loss: 146044704.0000 - val_mae: 11328.2295\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 263851026.6667 - mae: 13872.0065 - val_loss: 146043200.0000 - val_mae: 11328.1631\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 273850056.0000 - mae: 13762.2645 - val_loss: 146041728.0000 - val_mae: 11328.0986\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 260276864.0000 - mae: 13510.5591 - val_loss: 146040272.0000 - val_mae: 11328.0342\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 266824013.3333 - mae: 13650.0662 - val_loss: 146038848.0000 - val_mae: 11327.9717\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 305306917.3333 - mae: 14793.2158 - val_loss: 146037440.0000 - val_mae: 11327.9092\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 268015117.3333 - mae: 13639.1289 - val_loss: 146035920.0000 - val_mae: 11327.8428\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 267541010.6667 - mae: 13767.5913 - val_loss: 146034416.0000 - val_mae: 11327.7764\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 273590781.3333 - mae: 14133.8792 - val_loss: 146032960.0000 - val_mae: 11327.7119\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 282659136.0000 - mae: 14069.9946 - val_loss: 146031520.0000 - val_mae: 11327.6475\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 282996928.0000 - mae: 14308.0509 - val_loss: 146030080.0000 - val_mae: 11327.5850\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 277511509.3333 - mae: 14198.8690 - val_loss: 146028608.0000 - val_mae: 11327.5205\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285128256.0000 - mae: 14193.3079 - val_loss: 146027184.0000 - val_mae: 11327.4561\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 279673146.6667 - mae: 14340.4909 - val_loss: 146025696.0000 - val_mae: 11327.3916\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 284527530.6667 - mae: 14329.4155 - val_loss: 146024256.0000 - val_mae: 11327.3262\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 282588208.0000 - mae: 14107.8996 - val_loss: 146022768.0000 - val_mae: 11327.2598\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 272237106.6667 - mae: 13810.8483 - val_loss: 146021280.0000 - val_mae: 11327.1963\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 269714266.6667 - mae: 13791.2573 - val_loss: 146019856.0000 - val_mae: 11327.1338\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 293007626.6667 - mae: 14519.5451 - val_loss: 146018384.0000 - val_mae: 11327.0693\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 272433546.6667 - mae: 13957.5726 - val_loss: 146016960.0000 - val_mae: 11327.0049\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 282944506.6667 - mae: 14090.3503 - val_loss: 146015472.0000 - val_mae: 11326.9404\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 251652040.0000 - mae: 13416.0697 - val_loss: 146013936.0000 - val_mae: 11326.8721\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 298163130.6667 - mae: 14361.9246 - val_loss: 146012528.0000 - val_mae: 11326.8096\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 295951520.0000 - mae: 14393.4958 - val_loss: 146011104.0000 - val_mae: 11326.7471\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 310236480.0000 - mae: 14727.0316 - val_loss: 146009648.0000 - val_mae: 11326.6826\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 286516672.0000 - mae: 14214.0819 - val_loss: 146008144.0000 - val_mae: 11326.6162\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 259943552.0000 - mae: 13627.4325 - val_loss: 146006672.0000 - val_mae: 11326.5518\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 260427224.0000 - mae: 13647.1772 - val_loss: 146005216.0000 - val_mae: 11326.4883\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 274355733.3333 - mae: 14030.1156 - val_loss: 146003728.0000 - val_mae: 11326.4209\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 261660976.0000 - mae: 13723.7230 - val_loss: 146002256.0000 - val_mae: 11326.3564\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 281850682.6667 - mae: 14161.5342 - val_loss: 146000800.0000 - val_mae: 11326.2920\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 315980810.6667 - mae: 14933.6019 - val_loss: 145999344.0000 - val_mae: 11326.2275\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 301707157.3333 - mae: 14502.3659 - val_loss: 145997888.0000 - val_mae: 11326.1650\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 282471146.6667 - mae: 14249.8953 - val_loss: 145996464.0000 - val_mae: 11326.1006\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 280672029.3333 - mae: 14117.9421 - val_loss: 145994960.0000 - val_mae: 11326.0342\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 251095378.6667 - mae: 13515.3853 - val_loss: 145993488.0000 - val_mae: 11325.9697\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 264218034.6667 - mae: 13766.1527 - val_loss: 145992016.0000 - val_mae: 11325.9053\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 287901040.0000 - mae: 14241.9046 - val_loss: 145990576.0000 - val_mae: 11325.8408\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 290869770.6667 - mae: 14324.7458 - val_loss: 145989104.0000 - val_mae: 11325.7764\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 264384072.0000 - mae: 13588.8031 - val_loss: 145987680.0000 - val_mae: 11325.7139\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 294873114.6667 - mae: 14581.3179 - val_loss: 145986224.0000 - val_mae: 11325.6494\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 247798957.3333 - mae: 13496.3231 - val_loss: 145984736.0000 - val_mae: 11325.5830\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 271905890.6667 - mae: 13813.3810 - val_loss: 145983296.0000 - val_mae: 11325.5205\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 260247488.0000 - mae: 13831.2025 - val_loss: 145981808.0000 - val_mae: 11325.4541\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 294035098.6667 - mae: 14440.0521 - val_loss: 145980336.0000 - val_mae: 11325.3887\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 305586962.6667 - mae: 14741.3841 - val_loss: 145978848.0000 - val_mae: 11325.3223\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 285710192.0000 - mae: 14066.0166 - val_loss: 145977376.0000 - val_mae: 11325.2588\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 284773509.3333 - mae: 14031.3029 - val_loss: 145975920.0000 - val_mae: 11325.1943\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 263045130.6667 - mae: 13695.9419 - val_loss: 145974480.0000 - val_mae: 11325.1299\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 261234568.0000 - mae: 13703.6854 - val_loss: 145973072.0000 - val_mae: 11325.0674\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 291473338.6667 - mae: 14357.9627 - val_loss: 145971632.0000 - val_mae: 11325.0049\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 271541632.0000 - mae: 13790.3270 - val_loss: 145970144.0000 - val_mae: 11324.9385\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 277460197.3333 - mae: 13936.2148 - val_loss: 145968688.0000 - val_mae: 11324.8760\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 279533085.3333 - mae: 14136.6159 - val_loss: 145967200.0000 - val_mae: 11324.8096\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 280011005.3333 - mae: 14071.1204 - val_loss: 145965712.0000 - val_mae: 11324.7432\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 260465032.0000 - mae: 13687.8363 - val_loss: 145964256.0000 - val_mae: 11324.6787\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 275084501.3333 - mae: 13932.0876 - val_loss: 145962816.0000 - val_mae: 11324.6162\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 280834709.3333 - mae: 14072.0659 - val_loss: 145961360.0000 - val_mae: 11324.5518\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 268337021.3333 - mae: 13714.7118 - val_loss: 145959952.0000 - val_mae: 11324.4893\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 269936706.6667 - mae: 13965.6240 - val_loss: 145958480.0000 - val_mae: 11324.4258\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 259358653.3333 - mae: 13596.8716 - val_loss: 145956992.0000 - val_mae: 11324.3584\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285610837.3333 - mae: 14080.1787 - val_loss: 145955536.0000 - val_mae: 11324.2939\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 321670032.0000 - mae: 15127.2030 - val_loss: 145954160.0000 - val_mae: 11324.2334\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285727306.6667 - mae: 14330.0998 - val_loss: 145952672.0000 - val_mae: 11324.1670\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 286519890.6667 - mae: 14270.4325 - val_loss: 145951152.0000 - val_mae: 11324.1006\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 272702880.0000 - mae: 13977.4196 - val_loss: 145949728.0000 - val_mae: 11324.0381\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 282733456.0000 - mae: 14347.4717 - val_loss: 145948272.0000 - val_mae: 11323.9736\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 256577802.6667 - mae: 13525.2293 - val_loss: 145946752.0000 - val_mae: 11323.9072\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 281733429.3333 - mae: 14094.9023 - val_loss: 145945296.0000 - val_mae: 11323.8408\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 277993141.3333 - mae: 13925.0275 - val_loss: 145943840.0000 - val_mae: 11323.7764\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 265186706.6667 - mae: 13726.5099 - val_loss: 145942352.0000 - val_mae: 11323.7119\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 267718794.6667 - mae: 13949.8605 - val_loss: 145940944.0000 - val_mae: 11323.6494\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 295617722.6667 - mae: 14327.3374 - val_loss: 145939456.0000 - val_mae: 11323.5850\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 243107370.6667 - mae: 13206.6374 - val_loss: 145937952.0000 - val_mae: 11323.5166\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 287661066.6667 - mae: 14342.4966 - val_loss: 145936512.0000 - val_mae: 11323.4541\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 250240778.6667 - mae: 13332.0737 - val_loss: 145935088.0000 - val_mae: 11323.3916\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 287255946.6667 - mae: 14259.8581 - val_loss: 145933632.0000 - val_mae: 11323.3262\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 252671114.6667 - mae: 13558.5249 - val_loss: 145932144.0000 - val_mae: 11323.2598\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 270131608.0000 - mae: 13799.0649 - val_loss: 145930672.0000 - val_mae: 11323.1963\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 280851226.6667 - mae: 14188.1699 - val_loss: 145929184.0000 - val_mae: 11323.1299\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 288640282.6667 - mae: 14324.2158 - val_loss: 145927712.0000 - val_mae: 11323.0654\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 273515690.6667 - mae: 13924.8377 - val_loss: 145926304.0000 - val_mae: 11323.0029\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 280559154.6667 - mae: 14187.8911 - val_loss: 145924832.0000 - val_mae: 11322.9385\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 279302325.3333 - mae: 14086.1302 - val_loss: 145923376.0000 - val_mae: 11322.8740\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 324307498.6667 - mae: 14990.3254 - val_loss: 145921936.0000 - val_mae: 11322.8096\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 293673632.0000 - mae: 14194.4320 - val_loss: 145920496.0000 - val_mae: 11322.7471\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285826634.6667 - mae: 14243.6859 - val_loss: 145919040.0000 - val_mae: 11322.6826\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 286180773.3333 - mae: 14236.4059 - val_loss: 145917568.0000 - val_mae: 11322.6182\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 307211072.0000 - mae: 14685.6989 - val_loss: 145916128.0000 - val_mae: 11322.5537\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 265167610.6667 - mae: 13813.1919 - val_loss: 145914656.0000 - val_mae: 11322.4893\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 281804709.3333 - mae: 14176.3664 - val_loss: 145913152.0000 - val_mae: 11322.4238\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 258596552.0000 - mae: 13641.9964 - val_loss: 145911664.0000 - val_mae: 11322.3564\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285272789.3333 - mae: 14193.0109 - val_loss: 145910192.0000 - val_mae: 11322.2920\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 268554498.6667 - mae: 13980.5459 - val_loss: 145908688.0000 - val_mae: 11322.2256\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 267218106.6667 - mae: 13698.8882 - val_loss: 145907184.0000 - val_mae: 11322.1592\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 279380397.3333 - mae: 14192.3405 - val_loss: 145905824.0000 - val_mae: 11322.0986\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 249717397.3333 - mae: 13366.4284 - val_loss: 145904304.0000 - val_mae: 11322.0322\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 283482720.0000 - mae: 14188.2336 - val_loss: 145902896.0000 - val_mae: 11321.9697\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 255976512.0000 - mae: 13530.7887 - val_loss: 145901440.0000 - val_mae: 11321.9053\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 306846074.6667 - mae: 14722.1185 - val_loss: 145900016.0000 - val_mae: 11321.8428\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 286330389.3333 - mae: 14143.6691 - val_loss: 145898528.0000 - val_mae: 11321.7764\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 299554602.6667 - mae: 14448.9038 - val_loss: 145897104.0000 - val_mae: 11321.7139\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 272667682.6667 - mae: 14029.8812 - val_loss: 145895584.0000 - val_mae: 11321.6475\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 265997602.6667 - mae: 13709.1411 - val_loss: 145894128.0000 - val_mae: 11321.5830\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 282473946.6667 - mae: 14217.8145 - val_loss: 145892656.0000 - val_mae: 11321.5186\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 266790645.3333 - mae: 13767.1987 - val_loss: 145891184.0000 - val_mae: 11321.4512\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 263471114.6667 - mae: 13660.0381 - val_loss: 145889712.0000 - val_mae: 11321.3867\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 260990026.6667 - mae: 13695.5132 - val_loss: 145888288.0000 - val_mae: 11321.3242\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 275402064.0000 - mae: 13972.1366 - val_loss: 145886816.0000 - val_mae: 11321.2588\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 246065181.3333 - mae: 13373.8110 - val_loss: 145885312.0000 - val_mae: 11321.1924\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 273174106.6667 - mae: 14070.1442 - val_loss: 145883872.0000 - val_mae: 11321.1299\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 296977088.0000 - mae: 14543.7808 - val_loss: 145882480.0000 - val_mae: 11321.0674\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 269159738.6667 - mae: 13878.3068 - val_loss: 145880992.0000 - val_mae: 11321.0010\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 259929405.3333 - mae: 13629.9416 - val_loss: 145879520.0000 - val_mae: 11320.9365\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 265274474.6667 - mae: 13860.6735 - val_loss: 145878048.0000 - val_mae: 11320.8721\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 301438976.0000 - mae: 14549.0223 - val_loss: 145876592.0000 - val_mae: 11320.8076\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 256352432.0000 - mae: 13522.6452 - val_loss: 145875072.0000 - val_mae: 11320.7412\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 241734229.3333 - mae: 13316.8346 - val_loss: 145873600.0000 - val_mae: 11320.6768\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 249694597.3333 - mae: 13260.6896 - val_loss: 145872176.0000 - val_mae: 11320.6133\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 289719301.3333 - mae: 14490.8550 - val_loss: 145870752.0000 - val_mae: 11320.5508\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 281621488.0000 - mae: 14125.1217 - val_loss: 145869296.0000 - val_mae: 11320.4863\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 300291434.6667 - mae: 14550.4212 - val_loss: 145867872.0000 - val_mae: 11320.4238\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 293298885.3333 - mae: 14395.9165 - val_loss: 145866416.0000 - val_mae: 11320.3584\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 271732589.3333 - mae: 13868.3026 - val_loss: 145864896.0000 - val_mae: 11320.2920\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 277470605.3333 - mae: 14035.8429 - val_loss: 145863456.0000 - val_mae: 11320.2275\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 257709573.3333 - mae: 13474.1439 - val_loss: 145861904.0000 - val_mae: 11320.1592\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 286900304.0000 - mae: 14237.0767 - val_loss: 145860480.0000 - val_mae: 11320.0967\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 279705066.6667 - mae: 14079.0599 - val_loss: 145859024.0000 - val_mae: 11320.0322\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 270023882.6667 - mae: 13911.0104 - val_loss: 145857568.0000 - val_mae: 11319.9678\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 272367288.0000 - mae: 13735.6899 - val_loss: 145856080.0000 - val_mae: 11319.9014\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 255238072.0000 - mae: 13598.4061 - val_loss: 145854624.0000 - val_mae: 11319.8369\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 285329901.3333 - mae: 14076.2113 - val_loss: 145853136.0000 - val_mae: 11319.7725\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 285236821.3333 - mae: 14320.7596 - val_loss: 145851680.0000 - val_mae: 11319.7080\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 330976736.0000 - mae: 15187.6872 - val_loss: 145850272.0000 - val_mae: 11319.6455\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 268672346.6667 - mae: 13971.5679 - val_loss: 145848816.0000 - val_mae: 11319.5811\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 254473514.6667 - mae: 13418.4163 - val_loss: 145847280.0000 - val_mae: 11319.5117\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 290203418.6667 - mae: 14265.4603 - val_loss: 145845856.0000 - val_mae: 11319.4492\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 322871429.3333 - mae: 15082.3926 - val_loss: 145844432.0000 - val_mae: 11319.3867\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 285660746.6667 - mae: 14192.5259 - val_loss: 145843008.0000 - val_mae: 11319.3223\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 268934226.6667 - mae: 13807.8480 - val_loss: 145841520.0000 - val_mae: 11319.2588\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 252471293.3333 - mae: 13509.3747 - val_loss: 145840032.0000 - val_mae: 11319.1924\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 272219968.0000 - mae: 13896.0412 - val_loss: 145838576.0000 - val_mae: 11319.1299\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 247148730.6667 - mae: 13064.5547 - val_loss: 145837104.0000 - val_mae: 11319.0635\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 249636101.3333 - mae: 13433.5303 - val_loss: 145835616.0000 - val_mae: 11318.9990\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 280570272.0000 - mae: 14359.1353 - val_loss: 145834192.0000 - val_mae: 11318.9346\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 277781613.3333 - mae: 14105.4591 - val_loss: 145832768.0000 - val_mae: 11318.8721\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 258264864.0000 - mae: 13554.7710 - val_loss: 145831296.0000 - val_mae: 11318.8076\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 275618173.3333 - mae: 14001.5021 - val_loss: 145829792.0000 - val_mae: 11318.7412\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 291789776.0000 - mae: 14534.8786 - val_loss: 145828368.0000 - val_mae: 11318.6768\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 276296437.3333 - mae: 14085.3646 - val_loss: 145826944.0000 - val_mae: 11318.6143\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 275503000.0000 - mae: 14066.0900 - val_loss: 145825488.0000 - val_mae: 11318.5518\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 272117656.0000 - mae: 14072.2163 - val_loss: 145824016.0000 - val_mae: 11318.4863\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 288770064.0000 - mae: 14357.5304 - val_loss: 145822560.0000 - val_mae: 11318.4209\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 285154314.6667 - mae: 14108.8875 - val_loss: 145821056.0000 - val_mae: 11318.3545\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 325104645.3333 - mae: 15157.3467 - val_loss: 145819648.0000 - val_mae: 11318.2920\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 318102442.6667 - mae: 14901.9495 - val_loss: 145818160.0000 - val_mae: 11318.2275\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 286148021.3333 - mae: 14156.0885 - val_loss: 145816704.0000 - val_mae: 11318.1631\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 270539240.0000 - mae: 13905.0031 - val_loss: 145815168.0000 - val_mae: 11318.0947\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 303012592.0000 - mae: 14588.5184 - val_loss: 145813776.0000 - val_mae: 11318.0322\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 287152298.6667 - mae: 14359.9925 - val_loss: 145812320.0000 - val_mae: 11317.9697\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 274111536.0000 - mae: 14013.0342 - val_loss: 145810880.0000 - val_mae: 11317.9053\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 256339493.3333 - mae: 13566.2467 - val_loss: 145809392.0000 - val_mae: 11317.8389\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 279188445.3333 - mae: 13897.2231 - val_loss: 145807936.0000 - val_mae: 11317.7744\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 277993637.3333 - mae: 14116.1802 - val_loss: 145806480.0000 - val_mae: 11317.7119\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 292378496.0000 - mae: 14273.7510 - val_loss: 145805040.0000 - val_mae: 11317.6475\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 294912650.6667 - mae: 14549.9365 - val_loss: 145803600.0000 - val_mae: 11317.5830\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 294765541.3333 - mae: 14338.6984 - val_loss: 145802128.0000 - val_mae: 11317.5186\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 296423088.0000 - mae: 14580.6759 - val_loss: 145800672.0000 - val_mae: 11317.4541\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 279517088.0000 - mae: 14110.6992 - val_loss: 145799168.0000 - val_mae: 11317.3867\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 273170856.0000 - mae: 13848.7038 - val_loss: 145797712.0000 - val_mae: 11317.3223\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 275252096.0000 - mae: 13868.3999 - val_loss: 145796224.0000 - val_mae: 11317.2588\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 255529293.3333 - mae: 13666.3507 - val_loss: 145794736.0000 - val_mae: 11317.1924\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 276014530.6667 - mae: 14079.0910 - val_loss: 145793296.0000 - val_mae: 11317.1279\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 300965802.6667 - mae: 14584.9821 - val_loss: 145791888.0000 - val_mae: 11317.0654\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 255320277.3333 - mae: 13569.3003 - val_loss: 145790352.0000 - val_mae: 11316.9990\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 314167994.6667 - mae: 14915.9035 - val_loss: 145788976.0000 - val_mae: 11316.9365\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 284756293.3333 - mae: 14299.9212 - val_loss: 145787536.0000 - val_mae: 11316.8740\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 262562810.6667 - mae: 13708.6077 - val_loss: 145786080.0000 - val_mae: 11316.8096\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 246152320.0000 - mae: 13233.3903 - val_loss: 145784608.0000 - val_mae: 11316.7451\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 289674949.3333 - mae: 14303.7671 - val_loss: 145783152.0000 - val_mae: 11316.6807\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 252561000.0000 - mae: 13498.3496 - val_loss: 145781696.0000 - val_mae: 11316.6162\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 280968640.0000 - mae: 14081.7573 - val_loss: 145780240.0000 - val_mae: 11316.5518\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 294780480.0000 - mae: 14299.8123 - val_loss: 145778736.0000 - val_mae: 11316.4863\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 289779136.0000 - mae: 14362.6340 - val_loss: 145777296.0000 - val_mae: 11316.4209\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 277736586.6667 - mae: 14048.9910 - val_loss: 145775888.0000 - val_mae: 11316.3584\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 270311944.0000 - mae: 13885.6170 - val_loss: 145774416.0000 - val_mae: 11316.2939\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 241602237.3333 - mae: 13263.3568 - val_loss: 145772912.0000 - val_mae: 11316.2275\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 270139690.6667 - mae: 13809.7565 - val_loss: 145771424.0000 - val_mae: 11316.1611\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 286650461.3333 - mae: 14247.4611 - val_loss: 145770000.0000 - val_mae: 11316.0986\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 307981024.0000 - mae: 14834.2952 - val_loss: 145768576.0000 - val_mae: 11316.0361\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 279995885.3333 - mae: 14105.4175 - val_loss: 145767072.0000 - val_mae: 11315.9697\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 271478144.0000 - mae: 14038.3765 - val_loss: 145765584.0000 - val_mae: 11315.9033\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 264121210.6667 - mae: 13626.8327 - val_loss: 145764128.0000 - val_mae: 11315.8389\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 244281669.3333 - mae: 13104.8950 - val_loss: 145762672.0000 - val_mae: 11315.7744\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 248605906.6667 - mae: 13417.6273 - val_loss: 145761200.0000 - val_mae: 11315.7100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "J0kdwyvnsBMU",
        "outputId": "5f8cc12f-566d-4979-ca23-07447c3e522d"
      },
      "source": [
        "history_dict = Model_Results1.history\n",
        "mae_values = history_dict['mae']\n",
        "val_mae_values = history_dict['val_mae']\n",
        "epoches = np.arange(1,len(history_dict['mae'])+1)\n",
        "plt.plot(epoches,mae_values,'r',label=\"Training Mae\")\n",
        "plt.plot(epoches,val_mae_values,'g',label=\"Validating Mae\")\n",
        "plt.title('Training and validation Mae')\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Mae\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwV1Z338c9XQFBBZXNFBZVI3GigEXEbNImiccQFF8ZXBHfRJMYZYyQmYnR8nmT0GQ1J1HELahAkyWjcUNBoMCrRRlExYEDF2EYFUbaAyvJ7/qjT7aXtjaJvN939fb9e9bpVvzpVdc6lub9bp+qeUkRgZmaWx2ZNXQEzM2u+nETMzCw3JxEzM8vNScTMzHJzEjEzs9ycRMzMLDcnEdtkSJoiaWRDl21KkhZI+noR9huS9kzzt0j6cX3K5jjO6ZKm5q2ntXzy70RsY0haUbC4JfAZsDYtnx8RExq/VpsOSQuAcyLiiQbebwC9I2J+Q5WV1BN4G2gXEWsaop61HGsI8BTwQEScUBDvC8wC/hQRQ4pZB2sYbZu6Ata8RUTHivnaPjAltS32B5M1O4uAwZK6RsTiFBsJ/K0J62QbyN1ZVhSShkgql/QDSR8Av5bUWdLDkhZJ+iTN9yjY5mlJ56T5UZL+LOn6VPZtSUfnLNtL0nRJyyU9IelXkn5TQ73rU8drJD2b9jdVUreC9d+S9I6kxZKuqOX9GSTpA0ltCmInSHo1zR8g6XlJSyS9L+mXkjavYV/jJf1nwfL30zb/kHRWlbLflPSypGWS3pV0VcHq6el1iaQVkgZXvLcF2x8k6UVJS9PrQfV9b6rxOfAAcFravg1wKrDe2aukn6e6LpM0U9KhBes2k3S5pDfTez5ZUpdajmkNzEnEimkHoAuwG3Ae2d/br9PyrsAq4Je1bD8IeAPoBvwXcIck5Sh7L/AC0BW4CvhWLcesTx3/DTgT2A7YHLgUQNLewM1p/zul4/WgGhHxF+CfwBFV9ntvml8LXJLaMxj4GnBhLfUm1WFoqs83gN5A1esx/wTOALYFvgmMlnR8WndYet02IjpGxPNV9t0FeAQYl9r238AjkrpWacOX3pta3J3qA3AUMBv4R5UyLwIlZH9L9wK/ldQhrfsOcDzwL2Tv+SfAr+o4pjUgJxErpnXA2Ij4LCJWRcTiiPh9RKyMiOXAtWT/+WvyTkTcFhFrgbuAHYHtN6SspF2BgcCVEfF5RPwZeLCmA9azjr+OiL9FxCpgMtkHHMBw4OGImB4RnwE/Tu9BTSYCIwAkdQKOSTEiYmZEzIiINRGxAPifaupRnVNS/WZHxD/JkmZh+56OiNciYl1EvJqOV5/9QpZ05kXEPaleE4G5wL8WlKnpvalWRDwHdJG0F1kyubuaMr9J/y5rIuL/Ae2BvdLqC4ArIqI8vedXAcMluau+kTiJWDEtiohPKxYkbSnpf1J3zzKy7pNtC7t0qvigYiYiVqbZjhtYdifg44IYwLs1VbiedfygYH5lQZ12Ktx3+hBfTM3uBU6U1B44EXgpIt5J9fhK6kr7INXj/5CdldRlvToA71Rp3yBJT6XuuqVkH8L12W/Fvt+pEnsH2Llguab3pjb3AN8GDgfur7pS0qWS5qQutCXANgV13g24P3X7LQHmkJ3F1fRlwxqYk4gVU9Vb//6D7BvkoIjYmi+6T2rqomoI75N9092yILZLLeU3po7vF+47HbNrTYUj4q9kH8JHs35XFmTdYnPJ7qraGvhhnjqQdckVupfsTGyXiNgGuKVgv3XdqvkPsg/tQrsC79WjXrW5h6yr7tEqyZ50/eMysjOszhGxLbC0oM7vAkdHxLYFU4eI2Ng6WT05iVhj6kR2jWFJ6l8fW+wDpm/2ZcBVkjaXNJj1u18aso6/A46VdEi6CH41df8fuxe4mCxZ/bZKPZYBKyT1AUbXsw6TgVGS9k5JrGr9O5GdmX0q6QCy5FVhEVn32+417PtR4CuS/k1SW0mnAnsDD9ezbtWKiLfJutSquxGhE7Am1a2tpCuBrQvW3wJcK2k3AEndJQ3bmPrYhnESscZ0I7AF8BEwA3iskY57OtnF6cXAfwL3kf2epTq56xgRrwMXkSWG98ku8pbXsVnFNYk/RsRHBfFLyT7glwO3pTrXpw5TUhv+CMxPr4UuBK6WtBy4kizpVGy7kuwa0LOpe+jAKvteDBxLdra2mOwM4dgq9c4lIv4cEVUvqAM8TvZv8Deys7ZPWb+77udkZ1ZTU5tmkN1kYY3EPza0VkfSfcDciCj6mZBZS+czEWvxJA2UtEf6TcFQYBjZ7xPMbCP5NjhrDXYA/pfsInc5MDoiXm7aKpm1DO7OMjOz3NydZWZmubW67qxu3bpFz549m7oaZmbNysyZMz+KiO5V460uifTs2ZOysrKmroaZWbMiqepoBYC7s8zMbCM4iZiZWW5OImZmlpuTiJmZ5eYkYmZmuTmJmJlZbk4iZmaWW6v7nUhu99wDCxZAp07QsSNsuSW0aQNt237xWjhf+LrZZhs/SfUvV+NjyM3MGpaTSH3ddx888khT16J+aks49U1GDZHQirWPDd22tZf3FwsrIieR+nr4YVi9GlasgOXLYdUqWLs2m9asyaaK+aqv69ZlU8QX83mn5rKPwnbn3c/atTWvr+v4Hlh0fTUlok09Abp8w5bffPMG/0LhJLIh2rWDzp2zyTZtEesnmg1NnC5fnPIN8eViY8q2dnPmQJ8+DbpLJxFrmSq6cDbbrKlrYpuSql8uNqUE2xjlu39p/MSN5iRiZq2Hv1w0uKK+k5LulLRQ0uxq1v2HpJDULS1L0jhJ8yW9Kql/QdmRkualaWRBfICk19I24yRfPTQza0zFTsfjgaFVg5J2AY4E/l4QPhronabzgJtT2S7AWGAQcAAwVlLFRYmbgXMLtvvSsczMrHiKmkQiYjrwcTWrbgAuAwpvoRkG3B2ZGcC2knYEjgKmRcTHEfEJMA0YmtZtHREzInvG793A8cVsj5mZra/ROwYlDQPei4hXqqzaGXi3YLk8xWqLl1cTr+6Y50kqk1S2aNGijWyBmZlVaNQkImlL4IfAlY153Ii4NSJKI6K0exHuTjAza60a+0xkD6AX8IqkBUAP4CVJOwDvAbsUlO2RYrXFe1QTNzOzRtKoSSQiXouI7SKiZ0T0JOuC6h8RHwAPAmeku7QOBJZGxPvA48CRkjqnC+pHAo+ndcskHZjuyjoD+ENjtsfMrLUr9i2+E4Hngb0klUs6u5bijwJvAfOB24ALASLiY+Aa4MU0XZ1ipDK3p23eBKYUox1mZlY9RSsbY6i0tDTKysqauhpmZs2KpJkRUVo17p9tmplZbk4iZmaWm5OImZnl5iRiZma5OYmYmVluTiJmZpabk4iZmeXmJGJmZrk5iZiZWW5OImZmlpuTiJmZ5eYkYmZmuTmJmJlZbk4iZmaWm5OImZnl5iRiZma5OYmYmVluTiJmZpabk4iZmeXmJGJmZrk5iZiZWW5OImZmlpuTiJmZ5eYkYmZmuTmJmJlZbk4iZmaWW9GSiKQ7JS2UNLsgdo2kVyXNkjRV0k4pPkTS0hSfJenKgm2GSnpD0nxJlxfEe0n6S4rfJ2nzYrXFzMyqV8wzkfHA0Cqx6yJi/4goAR4GrixY90xElKTpagBJbYBfAUcDewMjJO2dyv8MuCEi9gQ+Ac4uXlPMzKw6RUsiETEd+LhKbFnB4lZA1LGbA4D5EfFWRHwOTAKGSRJwBPC7VO4u4PgGqbiZmdVbo18TkXStpHeB01n/TGSwpFckTZG0T4rtDLxbUKY8xboCSyJiTZV4Tcc8T1KZpLJFixY1WFvMzFq7Rk8iEXFFROwCTAC+ncIvAbtFRF/gF8ADDXzMWyOiNCJKu3fv3pC7NjNr1Zry7qwJwEmQdXNFxIo0/yjQTlI34D1gl4JteqTYYmBbSW2rxM3MrBE1ahKR1LtgcRgwN8V3SNc5kHRAqtdi4EWgd7oTa3PgNODBiAjgKWB42tdI4A+N0wozM6vQtu4i+UiaCAwBukkqB8YCx0jaC1gHvANckIoPB0ZLWgOsAk5LiWKNpG8DjwNtgDsj4vW0zQ+ASZL+E3gZuKNYbTEzs+op+6xuPUpLS6OsrKypq2Fm1qxImhkRpVXj/sW6mZnl5iRiZma5OYmYmVluTiJmZpabk4iZmeXmJGJmZrk5iZiZWW5OImZmlpuTiJmZ5eYkYmZmuTmJmJlZbk4iZmaWm5OImZnl5iRiZma5OYmYmVluTiJmZpabk4iZmeXmJGJmZrk5iZiZWW5OImZmlpuTiJmZ5eYkYmZmuTmJmJlZbk4iZmaWm5OImZnl5iRiZma5OYmYmVluRU0iku6UtFDS7ILYNZJelTRL0lRJO6W4JI2TND+t71+wzUhJ89I0siA+QNJraZtxklTM9piZ2fqKfSYyHhhaJXZdROwfESXAw8CVKX400DtN5wE3A0jqAowFBgEHAGMldU7b3AycW7Bd1WOZmVkRFTWJRMR04OMqsWUFi1sBkeaHAXdHZgawraQdgaOAaRHxcUR8AkwDhqZ1W0fEjIgI4G7g+GK2x8zM1te2KQ4q6VrgDGApcHgK7wy8W1CsPMVqi5dXE6/ueOeRnd2w6667bnwDzMwMaKIL6xFxRUTsAkwAvt0Ix7s1IkojorR79+7FPpyZWavR1HdnTQBOSvPvAbsUrOuRYrXFe1QTNzOzRtLoSURS74LFYcDcNP8gcEa6S+tAYGlEvA88DhwpqXO6oH4k8Hhat0zSgemurDOAPzReS8zMrKjXRCRNBIYA3SSVk91ldYykvYB1wDvABan4o8AxwHxgJXAmQER8LOka4MVU7uqIqLhYfyHZHWBbAFPSZGabiNWrV1NeXs6nn37a1FWxeurQoQM9evSgXbt29Sqv7Mam1qO0tDTKysqauhpmrcLbb79Np06d6Nq1K/4Z16YvIli8eDHLly+nV69e662TNDMiSqtu09TXRMysBfv000+dQJoRSXTt2nWDzhydRMysqJxAmpcN/fdyEjGzFmvx4sWUlJRQUlLCDjvswM4771y5/Pnnn9e6bVlZGd/97nfrPMZBBx3UIHV9+umnkcTtt99eGZs1axaSuP766xvkGMXQJD82NDNrDF27dmXWrFkAXHXVVXTs2JFLL720cv2aNWto27b6j8HS0lJKS790CeBLnnvuuYapLLDvvvsyefJkzjnnHAAmTpxI3759G2z/xeAzETNrVUaNGsUFF1zAoEGDuOyyy3jhhRcYPHgw/fr146CDDuKNN94AsjODY489FsgS0FlnncWQIUPYfffdGTduXOX+OnbsWFl+yJAhDB8+nD59+nD66adTcePSo48+Sp8+fRgwYADf/e53K/db1W677cann37Khx9+SETw2GOPcfTRR1euv+222xg4cCB9+/blpJNOYuXKlQAsWrSIk046iYEDBzJw4ECeffbZhn/jauAzETNrHN/7HqSzggZTUgI33rjBm5WXl/Pcc8/Rpk0bli1bxjPPPEPbtm154okn+OEPf8jvf//7L20zd+5cnnrqKZYvX85ee+3F6NGjv3Qb7Msvv8zrr7/OTjvtxMEHH8yzzz5LaWkp559/PtOnT6dXr16MGDGi1roNHz6c3/72t/Tr14/+/fvTvn37ynUnnngi5557LgA/+tGPuOOOO/jOd77DxRdfzCWXXMIhhxzC3//+d4466ijmzJmzwe9LHvVOIpJ2A3pHxBOStgDaRsTy4lXNzKw4Tj75ZNq0aQPA0qVLGTlyJPPmzUMSq1evrnabb37zm7Rv35727duz3Xbb8eGHH9KjR4/1yhxwwAGVsZKSEhYsWEDHjh3ZfffdK2+ZHTFiBLfeemuNdTvllFM49dRTmTt3LiNGjFivu2z27Nn86Ec/YsmSJaxYsYKjjjoKgCeeeIK//vWvleWWLVvGihUrKs+SiqleSUTSuWQDGHYB9iAbYuQW4GvFq5qZtSg5zhiKZauttqqc//GPf8zhhx/O/fffz4IFCxgyZEi12xSeEbRp04Y1a9bkKlOXHXbYgXbt2jFt2jR+/vOfr5dERo0axQMPPEDfvn0ZP348Tz/9NADr1q1jxowZdOjQYYOPt7Hqe03kIuBgYBlARMwDtitWpczMGsvSpUvZeedsAPDx48c3+P732msv3nrrLRYsWADAfffdV+c2V199NT/72c8qz5YqLF++nB133JHVq1czYcKEyviRRx7JL37xi8rlWQ3dbViL+iaRzyKi8n44SW354jkgZmbN1mWXXcaYMWPo169frjOHumyxxRbcdNNNDB06lAEDBtCpUye22WabWrc56KCDOP74Lz8e6ZprrmHQoEEcfPDB9OnTpzI+btw4ysrK2H///dl777255ZZbGrwdNanXsCeS/gtYQjbI4XfIxqz6a0RcUdzqNTwPe2LWeObMmcNXv/rVpq5Gk6u4PhERXHTRRfTu3ZtLLrmkqatVo+r+3TZ22JPLgUXAa8D5ZIMl/mgj62lm1ircdtttlJSUsM8++7B06VLOP//8pq5Sg6nXhfWIWAfcliYzM9sAl1xyySZ95rEx6nt3Vm/g/wJ7A5WX/yNi9yLVy8zMmoH6dmf9GrgZWEP2TPS7gd8Uq1JmZtY81DeJbBERT5JdiH8nIq4Cvlm8apmZWXNQ31+sfyZpM2CepG+TPcu8+D+FNDOzTVp9z0QuBrYEvgsMAL4FjCxWpczMGsLhhx/O448/vl7sxhtvZPTo0TVuM2TIECp+BnDMMcewZMmSL5W56qqr6hye/YEHHlhvKJIrr7ySJ554YkOqX6OePXty6KGHrhcrKSlh3333bZD9b4h6JZGIeDEiVkREeUScGREnRsSMYlfOzGxjjBgxgkmTJq0XmzRpUp2DIFZ49NFH2XbbbXMdu2oSufrqq/n617+ea1/VWb58Oe+++y5Aow22WJ1ak4ikB2ubGquSZmZ5DB8+nEceeaTyAVQLFizgH//4B4ceeiijR4+mtLSUffbZh7Fjx1a7fc+ePfnoo48AuPbaa/nKV77CIYccUjlcPFQ/PPtzzz3Hgw8+yPe//31KSkp48803GTVqFL/73e8q9zt27Fj69+/Pfvvtx9y5c4FsSPdvfOMb7LPPPpxzzjnstttulcev6pRTTqkcQmXixInrJcYFCxZw6KGH0r9/f/r377/e+FvXXXcdAwcOZP/996+x3Ruirmsig4F3gYnAXwA/59LMcvneY99j1gcNO6ZTyQ4l3Di05oEdu3TpwgEHHMCUKVMYNmwYkyZN4pRTTkES1157LV26dGHt2rV87Wtf49VXX2X//fevdj8zZ85k0qRJzJo1izVr1tC/f38GDBgA1Dw8+3HHHcexxx7L8OHDq91nt27deOmll7jpppu4/vrruf322/nJT37CEUccwZgxY3jssce44447amzbSSedxJlnnsmll17KQw89xIQJE7jnnnsA2G677Zg2bRodOnRg3rx5jBgxgrKyMqZOncq8efN44YUXiAiOO+44pk+fzmGHHVav97s6dXVn7QD8ENgX+DnwDeCjiPhTRPwp91HNzBpJYZdWYVfW5MmT6d+/P/369eP1119fr+upqmeeeYYTTjiBLbfckq233prjjjuuct3s2bM59NBD2W+//ZgwYQKvv/56vep14oknAjBgwIDKwRn//Oc/c9pppwEwdOhQOnfuXOP2Xbt2pXPnzkyaNImvfvWrbLnllpXrVq9ezbnnnst+++3HySefXNm2qVOnMnXq1MpnlcydO5d58+bVq741qfVMJCLWAo8Bj0lqD4wAnpb0k4j45UYd2cxaldrOGIpp2LBhXHLJJbz00kusXLmSAQMG8Pbbb3P99dfz4osv0rlzZ0aNGsWnn36aa/81Dc9el4ph4/MOGQ9w6qmnctFFF31p9OEbbriB7bffnldeeYV169ZVDhEfEYwZM6ZBh12p88K6pPaSTiT7ceFFwDjg/gargZlZEXXs2JHDDz+cs846q/IsZNmyZWy11VZss802fPjhh0yZMqXWfRx22GE88MADrFq1iuXLl/PQQw9VrqtpePZOnTqxfPmGPbfv4IMPZvLkyUB21vDJJ5/UWv6EE07gsssuq3w4VYWlS5ey4447stlmm3HPPfewdu1aAI466ijuvPNOVqxYAcB7773HwoULN6iOVdV6JiLpbrKurEeBn0TE7I06mplZExgxYgQnnHBCZbdW37596devH3369GGXXXbh4IMPrnX7/v37c+qpp9K3b1+22247Bg4cWLmuYnj27t27M2jQoMrEcdppp3Huuecybty4ygvqdRk7diwjRozgnnvuYfDgweywww506tSpxvKdOnXiBz/4wZfiF154ISeddBJ33303Q4cOrXwI15FHHsmcOXMYPHgwkCXY3/zmN2y3Xf7HQ9U6FLykdcA/02JhQQEREVvnPnIT8VDwZo3HQ8FvmM8++4w2bdrQtm1bnn/+eUaPHt2oD5iqsCFDwdd1TaS+P0b8Ekl3AscCCyNi3xS7DvhX4HPgTeDMiFgiqScwB6i4b25GRFyQthkAjAe2IDsjujgiQlIX4D6gJ7AAOCUiaj/3MzPbhP3973/nlFNOYd26dWy++ebcdtumP3B67iRRD+OBoVVi04B9I2J/4G/AmIJ1b0ZESZouKIjfDJwL9E5TxT4vB56MiN7Ak2nZzKzZ6t27Ny+//DKvvPIKL7744nrdZpuqoiWRiJgOfFwlNjUiKm5DmAH0qG0fknYEto6IGZH1u90NVDwzchhwV5q/qyBuZmaNpJhnInU5Cyi8JaKXpJcl/UlSxaAwOwPlBWXKUwxg+4h4P81/AGxf04EknSepTFLZokWLGqj6ZlYf9XkEt206NvTfq0mSiKQryJ5NUnE/3PvArhHRD/h34F5J9b5on85Samx5RNwaEaURUdq9e/eNqLmZbYgOHTqwePFiJ5JmIiJYvHhx5e9K6qO+Q8E3GEmjyC64fy19+BMRnwGfpfmZkt4EvkI25Hxhl1ePFAP4UNKOEfF+6vbauJudzazB9ejRg/LyctwD0Hx06NCBHj1qvdKwnkZNIpKGApcB/xIRKwvi3YGPI2KtpN3JLqC/FREfS1om6UCysbvOAH6RNnuQbDj6n6bXPzRiU8ysHtq1a0evXr2auhpWREVLIpImAkOAbpLKgbFkd2O1B6ZJgi9u5T0MuFrSamAdcEFEVFyUv5AvbvGdwhfXUX4KTJZ0NvAOcEqx2mJmZtWr9ceGLZF/bGhmtuFq+rFhU96dZWZmzZyTiJmZ5eYkYmZmuTmJmJlZbk4iZmaWm5OImZnl5iRiZma5OYmYmVluTiJmZpabk4iZmeXmJGJmZrk5iZiZWW5OImZmlpuTiJmZ5eYkYmZmuTmJmJlZbk4iZmaWm5OImZnl5iRiZma5OYmYmVluTiJmZpabk4iZmeXmJGJmZrk5iZiZWW5OImZmlpuTiJmZ5Va0JCLpTkkLJc0uiF0naa6kVyXdL2nbgnVjJM2X9IakowriQ1NsvqTLC+K9JP0lxe+TtHmx2mJmZtUr5pnIeGBoldg0YN+I2B/4GzAGQNLewGnAPmmbmyS1kdQG+BVwNLA3MCKVBfgZcENE7Al8ApxdxLaYmVk1ipZEImI68HGV2NSIWJMWZwA90vwwYFJEfBYRbwPzgQPSND8i3oqIz4FJwDBJAo4Afpe2vws4vlhtMTOz6jXlNZGzgClpfmfg3YJ15SlWU7wrsKQgIVXEzcysETVJEpF0BbAGmNBIxztPUpmkskWLFjXGIc3MWoVGTyKSRgHHAqdHRKTwe8AuBcV6pFhN8cXAtpLaVolXKyJujYjSiCjt3r17g7TDzMwaOYlIGgpcBhwXESsLVj0InCapvaReQG/gBeBFoHe6E2tzsovvD6bk8xQwPG0/EvhDY7XDzMwyxbzFdyLwPLCXpHJJZwO/BDoB0yTNknQLQES8DkwG/go8BlwUEWvTNY9vA48Dc4DJqSzAD4B/lzSf7BrJHcVqi5mZVU9f9Ci1DqWlpVFWVtbU1TAza1YkzYyI0qpx/2LdzMxycxIxM7PcnETMzCw3JxEzM8vNScTMzHJzEjEzs9ycRMzMLDcnETMzy81JxMzMcnMSMTOz3JxEzMwsNycRMzPLzUnEzMxycxIxM7PcnETMzCw3JxEzM8vNScTMzHJzEjEzs9ycRMzMLDcnETMzy81JxMzMcnMSMTOz3JxEzMwsNycRMzPLzUnEzMxycxIxM7PcnETMzCy3oiURSXdKWihpdkHsZEmvS1onqbQg3lPSKkmz0nRLwboBkl6TNF/SOElK8S6Spkmal147F6stZmZWvWKeiYwHhlaJzQZOBKZXU/7NiChJ0wUF8ZuBc4HeaarY5+XAkxHRG3gyLZuZWSMqWhKJiOnAx1VicyLijfruQ9KOwNYRMSMiArgbOD6tHgbclebvKoibmVkj2ZSuifSS9LKkP0k6NMV2BsoLypSnGMD2EfF+mv8A2L6mHUs6T1KZpLJFixY1eMXNzFqrTSWJvA/sGhH9gH8H7pW0dX03TmcpUcv6WyOiNCJKu3fvvvG1NTMzYBNJIhHxWUQsTvMzgTeBrwDvAT0KivZIMYAPU3dXRbfXwsarsZmZwSaSRCR1l9Qmze9OdgH9rdRdtUzSgemurDOAP6TNHgRGpvmRBXEzM2skxbzFdyLwPLCXpHJJZ0s6QVI5MBh4RNLjqfhhwKuSZgG/Ay6IiIqL8hcCtwPzyc5QpqT4T4FvSJoHfD0tm5lZI1J2OaH1KC0tjbKysqauhplZsyJpZkSUVo1vEt1ZZmbWPDmJmJlZbk4iZmaWW9umrkBz8cJ7L/DJqk/Yot0WbNF2i8rXNpu1oY3a1Ot1Mzlnm1nL4iRST1c9fRVT5k+pu2Ad2ihLJrVNkuoss155NrB8sfe/qdVnE95/Gk/UrNlyEqmncUePY9E/F7Fy9UpWrVnFqtWrWLVmFWvXrWVtrN2g1yBYF+tqnSKqlGEDy9cwrVm3Jitfjzrk2X9l+Vr2b+vblJLaRu2fTaguzXj/Qs3qy4WTSD3t2WVP9uyyZ1NXo0WoLiE1ZVJrkfvfwPIVXy7WxTrWxto669fQ7Y2aRy1qlWpKRhub1CmlVhsAAAZCSURBVB4a8RB7dNmjQevqJGKNTlJ2nYg2TV0V20RExHqJqZhJttl/Qahr/9RcvkPbDg3+b+ckYmZNTlLlt2ZrXvwvZmZmuTmJmJlZbk4iZmaWm5OImZnl5iRiZma5OYmYmVluTiJmZpabk4iZmeXW6p5sKGkR8E6OTbsBHzVwdTZ1bnPr4Da3Dhvb5t0ionvVYKtLInlJKqvu0ZAtmdvcOrjNrUOx2uzuLDMzy81JxMzMcnMSqb9bm7oCTcBtbh3c5tahKG32NREzM8vNZyJmZpabk4iZmeXmJFIPkoZKekPSfEmXN3V9GoqkOyUtlDS7INZF0jRJ89Jr5xSXpHHpPXhVUv+mq3l+knaR9JSkv0p6XdLFKd5i2y2pg6QXJL2S2vyTFO8l6S+pbfdJ2jzF26fl+Wl9z6asf16S2kh6WdLDablFtxdA0gJJr0maJaksxYr6t+0kUgdJbYBfAUcDewMjJO3dtLVqMOOBoVVilwNPRkRv4Mm0DFn7e6fpPODmRqpjQ1sD/EdE7A0cCFyU/j1bcrs/A46IiL5ACTBU0oHAz4AbImJP4BPg7FT+bOCTFL8hlWuOLgbmFCy39PZWODwiSgp+E1Lcv+2I8FTLBAwGHi9YHgOMaep6NWD7egKzC5bfAHZM8zsCb6T5/wFGVFeuOU/AH4BvtJZ2A1sCLwGDyH693DbFK//OgceBwWm+bSqnpq77BrazR/rAPAJ4GFBLbm9BuxcA3arEivq37TORuu0MvFuwXJ5iLdX2EfF+mv8A2D7Nt7j3IXVb9AP+Qgtvd+ramQUsBKYBbwJLImJNKlLYrso2p/VLga6NW+ONdiNwGbAuLXelZbe3QgBTJc2UdF6KFfVvu23emlrLFxEhqUXeAy6pI/B74HsRsUxS5bqW2O6IWAuUSNoWuB/o08RVKhpJxwILI2KmpCFNXZ9GdkhEvCdpO2CapLmFK4vxt+0zkbq9B+xSsNwjxVqqDyXtCJBeF6Z4i3kfJLUjSyATIuJ/U7jFtxsgIpYAT5F152wrqeKLZGG7Ktuc1m8DLG7kqm6Mg4HjJC0AJpF1af2cltveShHxXnpdSPZl4QCK/LftJFK3F4He6c6OzYHTgAebuE7F9CAwMs2PJLtmUBE/I93RcSCwtOAUudlQdspxBzAnIv67YFWLbbek7ukMBElbkF0DmkOWTIanYlXbXPFeDAf+GKnTvDmIiDER0SMiepL9f/1jRJxOC21vBUlbSepUMQ8cCcym2H/bTX0hqDlMwDHA38j6ka9o6vo0YLsmAu8Dq8n6Q88m6wt+EpgHPAF0SWVFdpfam8BrQGlT1z9nmw8h6zd+FZiVpmNacruB/YGXU5tnA1em+O7AC8B84LdA+xTvkJbnp/W7N3UbNqLtQ4CHW0N7U/teSdPrFZ9Vxf7b9rAnZmaWm7uzzMwsNycRMzPLzUnEzMxycxIxM7PcnETMzCw3JxGznCStTaOlVkwNNsKzpJ4qGF3ZbFPlYU/M8lsVESVNXQmzpuQzEbMGlp7p8F/puQ4vSNozxXtK+mN6dsOTknZN8e0l3Z+e9/GKpIPSrtpIui09A2Rq+rU5kvaQ9FgaZO8ZSX1S/GRJs9M+pjdJ463VcRIxy2+LKt1ZpxasWxoR+wG/JBtRFuAXwF0RsT8wARiX4uOAP0X2vI/+ZL82huw5D7+KiH2AJcBJKX4r8J2IGABcCtyU4lcCR6X9HNfQjTWrjn+xbpaTpBUR0bGa+AKyh0C9lQZ7/CAiukr6iOx5DatT/P2I6CZpEdAjIj4r2EdPYFpkDxJC0g+AdmQJaRHZsx8qtI+Ir0q6BdgDmAz8b0Q0y0EErXnxNRGz4oga5jfEZwXza4EtyHoPllR3LSYiLpA0CPgmMFPSACcSKzZ3Z5kVx6kFr8+n+efIRpUFOB14Js0/CYyGyodHbVPTTiNiGfC2pJNTeUnqm+b3iIi/RMSVZGcru9S0H7OG4iRill/VayI/LVjXWdKrZM/5viTFvgOcmeLfSutIr4dLeg2YCexdx3FPB86WVDFa67AUvy5dzJ9NlrBe2dgGmtXF10TMGli6JlIaER81dV3Mis1nImZmlpvPRMzMLDefiZiZWW5OImZmlpuTiJmZ5eYkYmZmuTmJmJlZbv8fGckavYGngI4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSaegsocTG0P",
        "outputId": "6d3540c6-c29d-4930-8968-4816bde4bf0e"
      },
      "source": [
        "history_dict = Model_Results1.history\n",
        "val_acc_values = history_dict['val_mae']\n",
        "maxi = np.max(val_acc_values)\n",
        "mini = np.min(val_acc_values)\n",
        "avrg = (maxi+mini)/2\n",
        "print(f\"FOR MODEL1 Average Validation Absolute Error = {avrg}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOR MODEL1 Average Validation Absolute Error = 11333.08642578125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjM7-hq0VW1B"
      },
      "source": [
        "# **MAE without K fold and with selu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj4MmPC7SFU0",
        "outputId": "962bad12-6433-4a4b-9960-11b5fc7c7c3e"
      },
      "source": [
        "Model_Results2 = Train_Me_with(activation_function=\"selu\").fit(\n",
        "      train_data,train_labels,batch_size=20,epochs=500,validation_data=(test_data,test_labels)\n",
        "  )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 1s 34ms/step - loss: 289106211.5556 - mae: 14328.1742 - val_loss: 146517312.0000 - val_mae: 11349.2373\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 258147255.1111 - mae: 13362.6207 - val_loss: 146488128.0000 - val_mae: 11347.9229\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 301819260.4444 - mae: 14650.1109 - val_loss: 146462880.0000 - val_mae: 11346.7783\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 298500227.5556 - mae: 14576.8304 - val_loss: 146435184.0000 - val_mae: 11345.5625\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 268701564.4444 - mae: 13804.2567 - val_loss: 146400480.0000 - val_mae: 11344.0879\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 264720645.3333 - mae: 13792.0420 - val_loss: 146363536.0000 - val_mae: 11342.4971\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 294982074.6667 - mae: 14384.4756 - val_loss: 146324096.0000 - val_mae: 11340.7988\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 249131041.7778 - mae: 13309.2088 - val_loss: 146274640.0000 - val_mae: 11338.7070\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 274825413.3333 - mae: 14047.2706 - val_loss: 146218032.0000 - val_mae: 11336.3271\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 243933162.6667 - mae: 13205.1865 - val_loss: 146157744.0000 - val_mae: 11333.7754\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 288480896.0000 - mae: 14208.5856 - val_loss: 146088000.0000 - val_mae: 11330.8379\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 269676492.4444 - mae: 13746.3213 - val_loss: 145999680.0000 - val_mae: 11327.1875\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 268033514.6667 - mae: 13971.9271 - val_loss: 145913488.0000 - val_mae: 11323.5654\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 252554295.1111 - mae: 13554.5859 - val_loss: 145799696.0000 - val_mae: 11318.8799\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 267609360.0000 - mae: 13873.8234 - val_loss: 145699104.0000 - val_mae: 11314.6416\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 279768668.4444 - mae: 13902.3975 - val_loss: 145575952.0000 - val_mae: 11309.4941\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 291204586.6667 - mae: 14424.0744 - val_loss: 145445408.0000 - val_mae: 11304.0361\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 253580067.5556 - mae: 13424.5803 - val_loss: 145284608.0000 - val_mae: 11297.4111\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 312001870.2222 - mae: 15228.0027 - val_loss: 145128128.0000 - val_mae: 11290.8428\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 265608231.1111 - mae: 13894.9529 - val_loss: 144927904.0000 - val_mae: 11282.5938\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 264086645.3333 - mae: 13831.2346 - val_loss: 144725872.0000 - val_mae: 11274.2266\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 277393116.4444 - mae: 14116.2827 - val_loss: 144529232.0000 - val_mae: 11265.9648\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 290111242.6667 - mae: 14316.0105 - val_loss: 144306576.0000 - val_mae: 11256.6592\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 277504901.3333 - mae: 13991.4640 - val_loss: 144021056.0000 - val_mae: 11244.9463\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 280522012.4444 - mae: 13987.0216 - val_loss: 143771056.0000 - val_mae: 11234.4697\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 291595310.2222 - mae: 14278.9153 - val_loss: 143460768.0000 - val_mae: 11221.6465\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 257015239.1111 - mae: 13568.6637 - val_loss: 143158480.0000 - val_mae: 11209.0693\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 302466392.8889 - mae: 14539.0947 - val_loss: 142817392.0000 - val_mae: 11194.8896\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 268936314.6667 - mae: 13899.3539 - val_loss: 142402784.0000 - val_mae: 11177.8799\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 298916679.1111 - mae: 14434.1718 - val_loss: 142043360.0000 - val_mae: 11162.9395\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 301121344.0000 - mae: 14585.8346 - val_loss: 141669312.0000 - val_mae: 11147.2568\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 262035463.1111 - mae: 13693.8969 - val_loss: 141178368.0000 - val_mae: 11127.0303\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 265593374.2222 - mae: 13755.6654 - val_loss: 140764672.0000 - val_mae: 11109.6572\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 258144679.1111 - mae: 13622.8049 - val_loss: 140270816.0000 - val_mae: 11089.0420\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 228534250.6667 - mae: 12700.9149 - val_loss: 139731904.0000 - val_mae: 11066.5723\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 224675834.6667 - mae: 12820.3102 - val_loss: 139199376.0000 - val_mae: 11044.2754\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 285398272.0000 - mae: 14097.0029 - val_loss: 138610464.0000 - val_mae: 11019.6660\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 276121498.6667 - mae: 14054.2253 - val_loss: 137972240.0000 - val_mae: 10992.9375\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 303826360.8889 - mae: 14456.8632 - val_loss: 137329952.0000 - val_mae: 10965.9688\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 251041406.2222 - mae: 13313.4632 - val_loss: 136594512.0000 - val_mae: 10935.1562\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 280473239.1111 - mae: 13894.9004 - val_loss: 135844384.0000 - val_mae: 10903.7373\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 308685939.5556 - mae: 14445.5671 - val_loss: 135098992.0000 - val_mae: 10872.2930\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 277002853.3333 - mae: 13998.1697 - val_loss: 134304928.0000 - val_mae: 10838.5996\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 256548336.0000 - mae: 13441.5676 - val_loss: 133469968.0000 - val_mae: 10803.1201\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 262092389.3333 - mae: 13601.1058 - val_loss: 132512656.0000 - val_mae: 10762.8154\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 263804138.6667 - mae: 13667.9094 - val_loss: 131602104.0000 - val_mae: 10723.8887\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 237692810.6667 - mae: 12824.0184 - val_loss: 130562400.0000 - val_mae: 10679.6777\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 302913283.5556 - mae: 14372.3929 - val_loss: 129619704.0000 - val_mae: 10638.8936\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 254487402.6667 - mae: 13421.8648 - val_loss: 128422600.0000 - val_mae: 10587.7676\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 260479025.7778 - mae: 13616.8923 - val_loss: 127397592.0000 - val_mae: 10543.1855\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 281447283.5556 - mae: 14086.8727 - val_loss: 126398880.0000 - val_mae: 10499.5020\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 245344001.7778 - mae: 13158.5166 - val_loss: 125276336.0000 - val_mae: 10450.2666\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 249027164.4444 - mae: 13286.5098 - val_loss: 123905224.0000 - val_mae: 10390.6621\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 259474012.4444 - mae: 13530.1948 - val_loss: 122638400.0000 - val_mae: 10334.6924\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 224070616.0000 - mae: 12454.4319 - val_loss: 121357160.0000 - val_mae: 10277.7354\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 247300597.3333 - mae: 13149.6039 - val_loss: 119900432.0000 - val_mae: 10213.3438\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 239815550.2222 - mae: 12712.6847 - val_loss: 118398976.0000 - val_mae: 10146.3877\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 209359052.4444 - mae: 12012.5838 - val_loss: 116825368.0000 - val_mae: 10076.1035\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 261976691.5556 - mae: 13473.1579 - val_loss: 115547584.0000 - val_mae: 10017.3760\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 229836757.3333 - mae: 12483.1815 - val_loss: 113811864.0000 - val_mae: 9938.5918\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 210498503.1111 - mae: 12094.2857 - val_loss: 112308464.0000 - val_mae: 9868.8457\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 202685738.6667 - mae: 11912.9206 - val_loss: 110730216.0000 - val_mae: 9795.2549\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 208041306.6667 - mae: 11945.3045 - val_loss: 109142720.0000 - val_mae: 9720.6484\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 210059530.6667 - mae: 12023.6135 - val_loss: 107393344.0000 - val_mae: 9638.0771\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 200159256.8889 - mae: 11559.8394 - val_loss: 105644272.0000 - val_mae: 9554.9268\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 228574576.0000 - mae: 12356.4652 - val_loss: 103792984.0000 - val_mae: 9466.4297\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 208033809.7778 - mae: 11889.7948 - val_loss: 101597696.0000 - val_mae: 9361.1289\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 169800816.8889 - mae: 10887.0233 - val_loss: 99881120.0000 - val_mae: 9276.6621\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 222704736.0000 - mae: 12126.0067 - val_loss: 98015312.0000 - val_mae: 9184.1484\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 191020689.7778 - mae: 11391.4169 - val_loss: 96061480.0000 - val_mae: 9086.8389\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 208857422.2222 - mae: 11820.4766 - val_loss: 93967864.0000 - val_mae: 8981.8975\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 202975978.6667 - mae: 11530.5086 - val_loss: 91752464.0000 - val_mae: 8869.1729\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 202911011.5556 - mae: 11830.5994 - val_loss: 89634520.0000 - val_mae: 8759.5342\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 195297404.4444 - mae: 11469.5398 - val_loss: 87520176.0000 - val_mae: 8648.7070\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 199653760.0000 - mae: 11331.0939 - val_loss: 85314168.0000 - val_mae: 8531.4395\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 177090691.5556 - mae: 10947.3150 - val_loss: 82822936.0000 - val_mae: 8397.6572\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 172979528.8889 - mae: 10658.3640 - val_loss: 80468592.0000 - val_mae: 8270.0127\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 195529505.7778 - mae: 11149.9940 - val_loss: 77857392.0000 - val_mae: 8126.6191\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 133248614.6667 - mae: 9285.3934 - val_loss: 75462440.0000 - val_mae: 7990.3706\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 178204419.5556 - mae: 10804.9679 - val_loss: 73001960.0000 - val_mae: 7849.7007\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 163615379.5556 - mae: 10193.4099 - val_loss: 70855792.0000 - val_mae: 7722.7939\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 160777792.0000 - mae: 10090.2062 - val_loss: 68605464.0000 - val_mae: 7588.0757\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 147899824.8889 - mae: 9664.6240 - val_loss: 66078120.0000 - val_mae: 7434.5981\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 144494240.0000 - mae: 9486.2772 - val_loss: 63246328.0000 - val_mae: 7260.9629\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 128395503.1111 - mae: 8898.6782 - val_loss: 60747928.0000 - val_mae: 7101.0562\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 117489707.5556 - mae: 8583.9002 - val_loss: 58459872.0000 - val_mae: 6951.8579\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 148748016.0000 - mae: 9638.4209 - val_loss: 56179844.0000 - val_mae: 6799.9077\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 141705817.7778 - mae: 9202.2507 - val_loss: 53734412.0000 - val_mae: 6633.7544\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 117058734.2222 - mae: 8451.4773 - val_loss: 51210112.0000 - val_mae: 6457.7661\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 111813818.6667 - mae: 8209.7697 - val_loss: 48343860.0000 - val_mae: 6253.3564\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 126295128.8889 - mae: 8639.9785 - val_loss: 46141416.0000 - val_mae: 6089.1431\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 138124931.5556 - mae: 8808.2083 - val_loss: 43500076.0000 - val_mae: 5888.1611\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 110655044.4444 - mae: 7802.7727 - val_loss: 41087016.0000 - val_mae: 5696.4741\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 103857021.3333 - mae: 7594.6063 - val_loss: 38707376.0000 - val_mae: 5501.3135\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 84536214.2222 - mae: 6690.2636 - val_loss: 35919180.0000 - val_mae: 5266.0044\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 107963406.2222 - mae: 7431.4714 - val_loss: 33751428.0000 - val_mae: 5073.5361\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 72087210.2222 - mae: 6343.8953 - val_loss: 31316172.0000 - val_mae: 4852.6270\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 85600287.1111 - mae: 6623.9144 - val_loss: 29205814.0000 - val_mae: 4654.1514\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 82267854.2222 - mae: 6324.8261 - val_loss: 26909094.0000 - val_mae: 4430.1870\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 71781257.7778 - mae: 5719.3088 - val_loss: 24845948.0000 - val_mae: 4218.3940\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 70282496.0000 - mae: 5909.7861 - val_loss: 23097674.0000 - val_mae: 4028.9216\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 83123791.1111 - mae: 6179.2927 - val_loss: 21567720.0000 - val_mae: 3869.2188\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 69170803.1111 - mae: 5669.5175 - val_loss: 19702184.0000 - val_mae: 3664.8262\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 66392302.2222 - mae: 5429.2785 - val_loss: 18134756.0000 - val_mae: 3480.3096\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 59884120.8889 - mae: 5137.5281 - val_loss: 16601238.0000 - val_mae: 3293.3362\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 46920610.2222 - mae: 4559.3950 - val_loss: 14888201.0000 - val_mae: 3086.8821\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 56612800.4444 - mae: 4689.3040 - val_loss: 13498144.0000 - val_mae: 2923.3887\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 48882590.0000 - mae: 4399.9760 - val_loss: 12076119.0000 - val_mae: 2740.4343\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 47274340.4444 - mae: 4246.5380 - val_loss: 10737893.0000 - val_mae: 2557.3149\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 45119400.4444 - mae: 4222.2332 - val_loss: 9799955.0000 - val_mae: 2431.0911\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 44288516.4444 - mae: 4213.0489 - val_loss: 8924978.0000 - val_mae: 2309.6814\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 35670859.1111 - mae: 3507.7230 - val_loss: 8024317.0000 - val_mae: 2173.4910\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 34547218.6667 - mae: 3683.3913 - val_loss: 7452563.0000 - val_mae: 2090.7964\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 30687315.5556 - mae: 3321.2083 - val_loss: 7092386.0000 - val_mae: 2026.4221\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 33706641.7778 - mae: 3508.4722 - val_loss: 6852634.5000 - val_mae: 1977.6797\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 35060195.5556 - mae: 3585.3802 - val_loss: 6682510.5000 - val_mae: 1931.2827\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24580582.6667 - mae: 3176.7887 - val_loss: 6674912.5000 - val_mae: 1895.0509\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 26092920.6667 - mae: 3335.1097 - val_loss: 6725323.0000 - val_mae: 1889.3228\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 34593634.4444 - mae: 3950.7046 - val_loss: 6804187.5000 - val_mae: 1898.2054\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 22872118.6667 - mae: 3049.4161 - val_loss: 6920860.0000 - val_mae: 1914.8282\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 22431770.2222 - mae: 3177.3459 - val_loss: 7145438.5000 - val_mae: 1944.6121\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 22863143.3333 - mae: 3210.3419 - val_loss: 7398501.0000 - val_mae: 1979.4165\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19386218.7778 - mae: 3054.4188 - val_loss: 7600935.5000 - val_mae: 2008.1185\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 22403730.4444 - mae: 3170.8844 - val_loss: 7821666.5000 - val_mae: 2040.1711\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 23738461.3333 - mae: 3379.7939 - val_loss: 7981273.0000 - val_mae: 2063.6711\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 21568646.8889 - mae: 3187.7987 - val_loss: 8115690.5000 - val_mae: 2085.7766\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 23056483.7778 - mae: 3462.6740 - val_loss: 8308901.5000 - val_mae: 2116.8936\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 23139907.7778 - mae: 3361.6187 - val_loss: 8423500.0000 - val_mae: 2136.8823\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24349228.0000 - mae: 3339.3907 - val_loss: 8438632.0000 - val_mae: 2144.3403\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17657888.8889 - mae: 3088.9956 - val_loss: 8737697.0000 - val_mae: 2184.5193\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19914791.3333 - mae: 3254.4114 - val_loss: 8762176.0000 - val_mae: 2191.3411\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 19547393.0000 - mae: 3235.7220 - val_loss: 9249814.0000 - val_mae: 2265.2900\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 20709909.3333 - mae: 3222.3180 - val_loss: 9239358.0000 - val_mae: 2265.2273\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17834284.1111 - mae: 3072.4914 - val_loss: 9553934.0000 - val_mae: 2315.5991\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 21343106.8889 - mae: 3490.3624 - val_loss: 9746317.0000 - val_mae: 2345.1025\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17679631.2222 - mae: 3175.7313 - val_loss: 9558720.0000 - val_mae: 2318.0610\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 20701544.2222 - mae: 3282.5397 - val_loss: 9691109.0000 - val_mae: 2342.1658\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19554854.2222 - mae: 3212.5958 - val_loss: 9407144.0000 - val_mae: 2303.2817\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 22337484.2222 - mae: 3323.8958 - val_loss: 9219547.0000 - val_mae: 2277.6218\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18301975.6667 - mae: 3119.3024 - val_loss: 9697796.0000 - val_mae: 2349.2639\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19576464.7778 - mae: 3298.1468 - val_loss: 9815431.0000 - val_mae: 2364.1665\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18083235.4444 - mae: 3246.9819 - val_loss: 9833796.0000 - val_mae: 2366.0229\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18343347.6667 - mae: 3158.9317 - val_loss: 9766276.0000 - val_mae: 2357.7251\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17254569.7778 - mae: 3019.1627 - val_loss: 10033338.0000 - val_mae: 2397.4229\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16262660.6667 - mae: 3106.7942 - val_loss: 9995252.0000 - val_mae: 2393.5359\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19243517.7778 - mae: 3245.7039 - val_loss: 9872249.0000 - val_mae: 2374.6206\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19018454.2222 - mae: 3229.7815 - val_loss: 9885214.0000 - val_mae: 2377.5676\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 20024341.5556 - mae: 3340.0863 - val_loss: 9923766.0000 - val_mae: 2383.8435\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16120858.3333 - mae: 3030.8607 - val_loss: 9800452.0000 - val_mae: 2366.2346\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18752200.0000 - mae: 3153.4457 - val_loss: 9682517.0000 - val_mae: 2349.7322\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16937807.6667 - mae: 2953.5012 - val_loss: 9957052.0000 - val_mae: 2392.2971\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17013138.4444 - mae: 3105.8681 - val_loss: 10295231.0000 - val_mae: 2443.4722\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18379996.5556 - mae: 3283.3995 - val_loss: 10215782.0000 - val_mae: 2433.5496\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13846477.3333 - mae: 2833.6395 - val_loss: 10056133.0000 - val_mae: 2409.4839\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15307910.1111 - mae: 2945.3551 - val_loss: 10267794.0000 - val_mae: 2439.4177\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16767048.1111 - mae: 3011.1891 - val_loss: 10585224.0000 - val_mae: 2479.5295\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16810571.7778 - mae: 2990.2797 - val_loss: 10292748.0000 - val_mae: 2440.1772\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 21439540.3333 - mae: 3446.6653 - val_loss: 10119332.0000 - val_mae: 2415.8967\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14487488.8889 - mae: 2793.4937 - val_loss: 9932403.0000 - val_mae: 2389.5659\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17379840.0000 - mae: 2917.1213 - val_loss: 9784771.0000 - val_mae: 2370.2971\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18835577.4444 - mae: 3169.9035 - val_loss: 9647839.0000 - val_mae: 2348.6477\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14386498.1111 - mae: 2824.2807 - val_loss: 9803614.0000 - val_mae: 2371.3828\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16805934.1111 - mae: 2974.9012 - val_loss: 9987012.0000 - val_mae: 2394.3928\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16693522.8889 - mae: 2915.4174 - val_loss: 9970553.0000 - val_mae: 2392.6140\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16567939.8889 - mae: 2989.9540 - val_loss: 9913126.0000 - val_mae: 2384.8723\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18820201.3333 - mae: 3180.2681 - val_loss: 9947811.0000 - val_mae: 2387.2808\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13840573.2222 - mae: 2820.7179 - val_loss: 9921788.0000 - val_mae: 2384.4033\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13659221.7778 - mae: 2833.3582 - val_loss: 9982623.0000 - val_mae: 2392.3528\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15398920.2222 - mae: 2994.0717 - val_loss: 9882701.0000 - val_mae: 2379.3274\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13327018.3333 - mae: 2812.6438 - val_loss: 9841886.0000 - val_mae: 2372.0706\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13524369.3333 - mae: 2783.9171 - val_loss: 9881013.0000 - val_mae: 2379.1638\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16329051.0000 - mae: 3070.4274 - val_loss: 10024474.0000 - val_mae: 2395.0518\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17333216.4444 - mae: 2991.2033 - val_loss: 10041219.0000 - val_mae: 2394.7346\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13327250.0556 - mae: 2686.7391 - val_loss: 9897810.0000 - val_mae: 2380.3342\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13193550.4444 - mae: 2598.0869 - val_loss: 9758957.0000 - val_mae: 2366.8423\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12748372.6667 - mae: 2566.4533 - val_loss: 9673766.0000 - val_mae: 2353.1997\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16124212.7778 - mae: 2855.8966 - val_loss: 9786310.0000 - val_mae: 2368.9438\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11639599.0000 - mae: 2559.8293 - val_loss: 10220447.0000 - val_mae: 2419.7163\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13422453.3889 - mae: 2678.9326 - val_loss: 10286490.0000 - val_mae: 2426.2417\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18561127.8889 - mae: 3104.6099 - val_loss: 10073959.0000 - val_mae: 2400.8362\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14911821.4444 - mae: 2849.9564 - val_loss: 10050202.0000 - val_mae: 2398.1399\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14293446.5556 - mae: 2711.0218 - val_loss: 9954802.0000 - val_mae: 2386.4031\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10381380.0000 - mae: 2354.5458 - val_loss: 9972136.0000 - val_mae: 2389.4250\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12890228.2222 - mae: 2483.4795 - val_loss: 10023530.0000 - val_mae: 2393.0808\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12919489.6667 - mae: 2657.2280 - val_loss: 10156711.0000 - val_mae: 2410.4387\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10364489.4444 - mae: 2307.6437 - val_loss: 10630371.0000 - val_mae: 2466.8733\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12551343.0000 - mae: 2612.6609 - val_loss: 11003648.0000 - val_mae: 2508.3840\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13597302.1111 - mae: 2655.6969 - val_loss: 10827426.0000 - val_mae: 2490.7817\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11862674.3889 - mae: 2479.8459 - val_loss: 11007359.0000 - val_mae: 2511.1267\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11953517.8889 - mae: 2570.7893 - val_loss: 10828896.0000 - val_mae: 2492.5962\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13014230.0556 - mae: 2626.0026 - val_loss: 10692741.0000 - val_mae: 2477.8745\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12538926.2222 - mae: 2643.5524 - val_loss: 10351816.0000 - val_mae: 2440.1863\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12208543.4444 - mae: 2548.6274 - val_loss: 10346579.0000 - val_mae: 2438.8447\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11055360.3333 - mae: 2484.9771 - val_loss: 10213386.0000 - val_mae: 2425.5552\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10337692.7778 - mae: 2265.8439 - val_loss: 10112860.0000 - val_mae: 2415.7715\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11765013.3333 - mae: 2421.2081 - val_loss: 10182446.0000 - val_mae: 2425.5120\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11431782.5556 - mae: 2434.8852 - val_loss: 10064283.0000 - val_mae: 2415.2285\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12713532.6667 - mae: 2486.5071 - val_loss: 10215118.0000 - val_mae: 2430.4583\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12664741.3333 - mae: 2590.5073 - val_loss: 10148932.0000 - val_mae: 2423.1370\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11974092.1667 - mae: 2452.4612 - val_loss: 10581106.0000 - val_mae: 2459.4197\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11866575.5556 - mae: 2445.3325 - val_loss: 10620754.0000 - val_mae: 2466.0620\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12396226.0000 - mae: 2577.5241 - val_loss: 10739241.0000 - val_mae: 2476.1169\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9178499.0556 - mae: 2180.4291 - val_loss: 10529219.0000 - val_mae: 2459.7397\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14105321.1111 - mae: 2691.2513 - val_loss: 10483060.0000 - val_mae: 2456.3455\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9867840.0000 - mae: 2245.9358 - val_loss: 10712334.0000 - val_mae: 2476.2310\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9169350.9444 - mae: 2185.5116 - val_loss: 10828934.0000 - val_mae: 2489.0872\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10426332.1667 - mae: 2342.5964 - val_loss: 10827628.0000 - val_mae: 2490.4451\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10588750.0000 - mae: 2247.6797 - val_loss: 11257074.0000 - val_mae: 2531.8589\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 11006924.0000 - mae: 2439.6868 - val_loss: 11090578.0000 - val_mae: 2518.8787\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10965118.7778 - mae: 2279.2907 - val_loss: 11224824.0000 - val_mae: 2534.3079\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10996299.3333 - mae: 2389.9693 - val_loss: 11063771.0000 - val_mae: 2522.2937\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9134670.7778 - mae: 2191.4017 - val_loss: 11197105.0000 - val_mae: 2535.1294\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9762728.4167 - mae: 2225.1669 - val_loss: 10989714.0000 - val_mae: 2518.6091\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9632154.5556 - mae: 2263.0199 - val_loss: 11146659.0000 - val_mae: 2535.2898\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8167317.3889 - mae: 2049.7064 - val_loss: 11543954.0000 - val_mae: 2574.0579\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11627855.0000 - mae: 2425.6562 - val_loss: 11451626.0000 - val_mae: 2566.2156\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8095946.0556 - mae: 2017.7108 - val_loss: 11880013.0000 - val_mae: 2606.7893\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10340758.0000 - mae: 2290.6340 - val_loss: 11589970.0000 - val_mae: 2584.7209\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8104618.8333 - mae: 2129.0323 - val_loss: 11956280.0000 - val_mae: 2619.2761\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11804197.7778 - mae: 2419.3145 - val_loss: 11730249.0000 - val_mae: 2604.9006\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11418541.2222 - mae: 2439.5165 - val_loss: 11704483.0000 - val_mae: 2605.3093\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8923942.7778 - mae: 2136.2564 - val_loss: 11764974.0000 - val_mae: 2612.0886\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7957403.8333 - mae: 2016.1323 - val_loss: 11394381.0000 - val_mae: 2580.7551\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8715842.2778 - mae: 2068.5637 - val_loss: 11715315.0000 - val_mae: 2614.9971\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10614900.6111 - mae: 2266.1471 - val_loss: 12057862.0000 - val_mae: 2646.5242\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7993402.5556 - mae: 1985.6626 - val_loss: 11885446.0000 - val_mae: 2633.8447\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8242223.0556 - mae: 2069.9399 - val_loss: 11577106.0000 - val_mae: 2609.2168\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9717574.1667 - mae: 2197.5098 - val_loss: 11537992.0000 - val_mae: 2608.0989\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10884707.7778 - mae: 2280.5294 - val_loss: 11804300.0000 - val_mae: 2634.0686\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7793753.3889 - mae: 2026.2971 - val_loss: 11652352.0000 - val_mae: 2620.3606\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7606907.3333 - mae: 1952.2190 - val_loss: 11728902.0000 - val_mae: 2628.0168\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8980742.3333 - mae: 2190.5193 - val_loss: 11512149.0000 - val_mae: 2612.4846\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9734972.8889 - mae: 2221.2077 - val_loss: 12084807.0000 - val_mae: 2662.5481\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8795766.0556 - mae: 2062.8986 - val_loss: 11969252.0000 - val_mae: 2659.8445\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10253763.3333 - mae: 2253.0140 - val_loss: 11809069.0000 - val_mae: 2649.2036\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9525676.1111 - mae: 2109.0628 - val_loss: 11850208.0000 - val_mae: 2651.6550\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9514079.3889 - mae: 2262.7697 - val_loss: 12116451.0000 - val_mae: 2673.6111\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7789861.5000 - mae: 2033.9160 - val_loss: 12090170.0000 - val_mae: 2674.0752\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7500994.7222 - mae: 1990.2646 - val_loss: 12469825.0000 - val_mae: 2708.2593\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8182492.9444 - mae: 2064.9880 - val_loss: 12731659.0000 - val_mae: 2732.3691\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7146451.5556 - mae: 1892.2380 - val_loss: 12375637.0000 - val_mae: 2702.4778\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9324091.3333 - mae: 2073.4733 - val_loss: 12320744.0000 - val_mae: 2698.8472\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7347554.2778 - mae: 1941.5598 - val_loss: 12259907.0000 - val_mae: 2693.2166\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9360059.3889 - mae: 2140.9296 - val_loss: 12647117.0000 - val_mae: 2727.6885\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7417055.8333 - mae: 1927.7664 - val_loss: 12182626.0000 - val_mae: 2690.1460\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6915539.7222 - mae: 1900.7273 - val_loss: 12591358.0000 - val_mae: 2724.8528\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7428864.7778 - mae: 1877.8643 - val_loss: 12196440.0000 - val_mae: 2692.3889\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8540227.1111 - mae: 2022.5393 - val_loss: 12341574.0000 - val_mae: 2703.5454\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7408888.9722 - mae: 1855.4536 - val_loss: 12160765.0000 - val_mae: 2687.3735\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7637051.4444 - mae: 1919.1707 - val_loss: 12200758.0000 - val_mae: 2689.7336\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8541255.5000 - mae: 1938.9324 - val_loss: 12110541.0000 - val_mae: 2683.9465\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7293870.8333 - mae: 1933.1813 - val_loss: 12276184.0000 - val_mae: 2696.4573\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7407649.4444 - mae: 1907.2206 - val_loss: 12212539.0000 - val_mae: 2692.2231\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8878365.3889 - mae: 2099.8416 - val_loss: 12411540.0000 - val_mae: 2707.0264\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7350918.5556 - mae: 1856.4720 - val_loss: 12355201.0000 - val_mae: 2703.3481\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6707461.1111 - mae: 1765.9701 - val_loss: 12243059.0000 - val_mae: 2696.0461\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6593189.6667 - mae: 1792.3552 - val_loss: 12746025.0000 - val_mae: 2739.0996\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6840119.3889 - mae: 1892.6530 - val_loss: 12788485.0000 - val_mae: 2742.8474\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7103515.0000 - mae: 1798.1509 - val_loss: 12718957.0000 - val_mae: 2736.6296\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7735805.1111 - mae: 1922.7236 - val_loss: 12871324.0000 - val_mae: 2749.0354\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7388499.9444 - mae: 1879.8992 - val_loss: 12581523.0000 - val_mae: 2727.7290\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8389579.4444 - mae: 1997.8297 - val_loss: 12916137.0000 - val_mae: 2751.8208\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6530448.2778 - mae: 1800.4320 - val_loss: 12855224.0000 - val_mae: 2746.0449\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5729413.3333 - mae: 1686.5683 - val_loss: 12514696.0000 - val_mae: 2716.3240\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6222184.0000 - mae: 1755.3337 - val_loss: 12557557.0000 - val_mae: 2719.9368\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6320223.6389 - mae: 1681.0846 - val_loss: 12740671.0000 - val_mae: 2734.3621\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6020307.6111 - mae: 1669.2257 - val_loss: 12625342.0000 - val_mae: 2723.9875\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5825662.0000 - mae: 1680.6153 - val_loss: 12601329.0000 - val_mae: 2725.8860\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5756445.0833 - mae: 1662.1574 - val_loss: 12858920.0000 - val_mae: 2746.9143\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5583185.8611 - mae: 1633.8793 - val_loss: 12942621.0000 - val_mae: 2757.9854\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5452450.8750 - mae: 1570.8437 - val_loss: 12875744.0000 - val_mae: 2751.2761\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6094534.7361 - mae: 1629.4090 - val_loss: 13263397.0000 - val_mae: 2782.6411\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6819423.7222 - mae: 1767.0984 - val_loss: 13185818.0000 - val_mae: 2776.0073\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6980152.6111 - mae: 1671.8423 - val_loss: 12776085.0000 - val_mae: 2742.9954\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5709226.2500 - mae: 1603.9250 - val_loss: 12604185.0000 - val_mae: 2728.4226\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7472989.2778 - mae: 1782.1672 - val_loss: 12658966.0000 - val_mae: 2730.4236\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5739347.2778 - mae: 1573.2574 - val_loss: 12557752.0000 - val_mae: 2725.9788\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5615879.5833 - mae: 1637.2438 - val_loss: 12705034.0000 - val_mae: 2734.7161\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4778132.4722 - mae: 1511.5558 - val_loss: 12897752.0000 - val_mae: 2750.4783\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5939132.2778 - mae: 1664.4808 - val_loss: 13174303.0000 - val_mae: 2770.8425\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5450305.0556 - mae: 1635.3181 - val_loss: 13587895.0000 - val_mae: 2807.8293\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5806945.6111 - mae: 1613.3272 - val_loss: 13449310.0000 - val_mae: 2799.5842\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7119855.7222 - mae: 1802.7738 - val_loss: 13500594.0000 - val_mae: 2801.6135\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6155332.1111 - mae: 1662.7225 - val_loss: 13466199.0000 - val_mae: 2796.4795\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6664843.0556 - mae: 1659.6186 - val_loss: 13838065.0000 - val_mae: 2829.1260\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6191634.1111 - mae: 1664.2106 - val_loss: 13505752.0000 - val_mae: 2803.6526\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4174628.7222 - mae: 1392.5101 - val_loss: 13447931.0000 - val_mae: 2796.5125\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6072260.4444 - mae: 1617.4263 - val_loss: 13689460.0000 - val_mae: 2816.0212\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5350198.2778 - mae: 1459.4249 - val_loss: 13194388.0000 - val_mae: 2775.9324\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5282443.0000 - mae: 1557.2793 - val_loss: 13701444.0000 - val_mae: 2812.6609\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5179295.1667 - mae: 1485.8723 - val_loss: 13210973.0000 - val_mae: 2775.3071\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6051311.8889 - mae: 1614.8499 - val_loss: 13207148.0000 - val_mae: 2772.5674\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4944503.7500 - mae: 1519.4818 - val_loss: 13397218.0000 - val_mae: 2783.8594\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7051418.1111 - mae: 1704.9595 - val_loss: 13534895.0000 - val_mae: 2793.0581\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4786853.3472 - mae: 1454.5970 - val_loss: 13541021.0000 - val_mae: 2791.1118\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5426074.0556 - mae: 1557.9193 - val_loss: 13088420.0000 - val_mae: 2751.1118\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4899693.1944 - mae: 1408.2205 - val_loss: 12899096.0000 - val_mae: 2731.9585\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4662325.5556 - mae: 1451.0694 - val_loss: 13136284.0000 - val_mae: 2750.2314\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5552414.5000 - mae: 1473.1043 - val_loss: 13158887.0000 - val_mae: 2752.2295\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4737915.2222 - mae: 1354.0114 - val_loss: 12862454.0000 - val_mae: 2725.5413\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7186618.0000 - mae: 1716.7628 - val_loss: 13184542.0000 - val_mae: 2751.4587\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5128555.5278 - mae: 1543.0070 - val_loss: 13174949.0000 - val_mae: 2750.6360\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4128950.9722 - mae: 1335.6661 - val_loss: 13036618.0000 - val_mae: 2737.8855\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4352730.6944 - mae: 1379.2853 - val_loss: 13169443.0000 - val_mae: 2748.1689\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5560463.4444 - mae: 1525.8457 - val_loss: 13260417.0000 - val_mae: 2755.7432\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4503197.9167 - mae: 1367.9586 - val_loss: 13487450.0000 - val_mae: 2774.4590\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4727468.6667 - mae: 1431.2439 - val_loss: 13513274.0000 - val_mae: 2776.7454\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5733589.7778 - mae: 1504.6150 - val_loss: 13288982.0000 - val_mae: 2756.0068\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3684431.1667 - mae: 1299.6389 - val_loss: 13202898.0000 - val_mae: 2746.7351\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3868075.1528 - mae: 1288.1094 - val_loss: 13307566.0000 - val_mae: 2755.5730\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4095858.3611 - mae: 1347.7615 - val_loss: 13312950.0000 - val_mae: 2758.2678\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4828668.1667 - mae: 1467.2716 - val_loss: 13220124.0000 - val_mae: 2752.1807\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4098486.1944 - mae: 1288.6533 - val_loss: 12854963.0000 - val_mae: 2723.6196\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4967186.3889 - mae: 1449.7098 - val_loss: 13014783.0000 - val_mae: 2730.5061\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5913406.1667 - mae: 1563.2537 - val_loss: 13168449.0000 - val_mae: 2741.1230\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5677745.7778 - mae: 1492.8401 - val_loss: 13299425.0000 - val_mae: 2751.5056\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4069941.1389 - mae: 1315.7270 - val_loss: 13073430.0000 - val_mae: 2734.7463\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4357213.4722 - mae: 1341.0442 - val_loss: 12836507.0000 - val_mae: 2716.3010\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3600697.1944 - mae: 1276.1715 - val_loss: 12945774.0000 - val_mae: 2723.8506\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5728528.5000 - mae: 1478.1478 - val_loss: 12811389.0000 - val_mae: 2713.1621\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4532552.6667 - mae: 1341.9915 - val_loss: 13164805.0000 - val_mae: 2740.9734\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4654969.0000 - mae: 1374.7271 - val_loss: 13012678.0000 - val_mae: 2729.3882\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3860914.4167 - mae: 1288.0507 - val_loss: 13356704.0000 - val_mae: 2754.7908\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3413158.4306 - mae: 1191.3789 - val_loss: 13290308.0000 - val_mae: 2750.8369\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4837696.2778 - mae: 1401.7176 - val_loss: 12963374.0000 - val_mae: 2722.9822\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4631845.5556 - mae: 1352.9296 - val_loss: 12917203.0000 - val_mae: 2720.4688\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4025041.3472 - mae: 1278.8493 - val_loss: 12930996.0000 - val_mae: 2719.8374\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3673684.7917 - mae: 1276.5437 - val_loss: 13407705.0000 - val_mae: 2759.3352\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4995465.6111 - mae: 1411.0312 - val_loss: 13313418.0000 - val_mae: 2753.3823\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3498964.3472 - mae: 1259.5561 - val_loss: 13634711.0000 - val_mae: 2782.4512\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3880813.6389 - mae: 1289.1258 - val_loss: 13827182.0000 - val_mae: 2794.2634\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5156879.8333 - mae: 1400.2984 - val_loss: 14070447.0000 - val_mae: 2811.6421\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4921187.1944 - mae: 1384.0196 - val_loss: 13617691.0000 - val_mae: 2776.7920\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4985132.9167 - mae: 1415.3925 - val_loss: 13657976.0000 - val_mae: 2778.3347\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4698105.3889 - mae: 1423.4975 - val_loss: 13966543.0000 - val_mae: 2803.8049\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3407192.3194 - mae: 1135.3255 - val_loss: 13343758.0000 - val_mae: 2755.7778\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3783423.1944 - mae: 1310.2012 - val_loss: 13529617.0000 - val_mae: 2768.0012\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3911656.3889 - mae: 1266.9737 - val_loss: 13439617.0000 - val_mae: 2764.1589\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3090576.7222 - mae: 1107.6162 - val_loss: 13994240.0000 - val_mae: 2806.5500\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4510096.2778 - mae: 1388.2042 - val_loss: 13839349.0000 - val_mae: 2796.6592\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3434327.0278 - mae: 1197.3358 - val_loss: 13724323.0000 - val_mae: 2787.9246\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3150944.6944 - mae: 1150.2827 - val_loss: 13792402.0000 - val_mae: 2792.1282\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4823652.1389 - mae: 1338.6074 - val_loss: 13436186.0000 - val_mae: 2765.0715\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3180925.4167 - mae: 1183.2694 - val_loss: 13264092.0000 - val_mae: 2751.8916\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3688627.6667 - mae: 1199.6392 - val_loss: 13421308.0000 - val_mae: 2756.3955\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3154548.9444 - mae: 1173.9173 - val_loss: 13649572.0000 - val_mae: 2770.4568\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3725164.7222 - mae: 1255.5741 - val_loss: 14039286.0000 - val_mae: 2796.5652\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3562405.9861 - mae: 1164.1304 - val_loss: 14425722.0000 - val_mae: 2830.0322\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2825816.6806 - mae: 1086.4345 - val_loss: 14603645.0000 - val_mae: 2849.9204\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4058265.9722 - mae: 1261.0710 - val_loss: 14336559.0000 - val_mae: 2829.8032\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3298387.1667 - mae: 1120.3234 - val_loss: 14114667.0000 - val_mae: 2818.0659\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4040207.2500 - mae: 1161.4833 - val_loss: 13564348.0000 - val_mae: 2780.6638\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2768183.3194 - mae: 1050.5327 - val_loss: 14085313.0000 - val_mae: 2810.0171\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3731152.4444 - mae: 1196.5085 - val_loss: 13394904.0000 - val_mae: 2761.2576\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4359166.5833 - mae: 1280.9271 - val_loss: 13524436.0000 - val_mae: 2770.8894\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4384924.3056 - mae: 1388.9185 - val_loss: 13660269.0000 - val_mae: 2776.2141\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3195394.4167 - mae: 1105.8102 - val_loss: 13376846.0000 - val_mae: 2755.8752\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3281014.6667 - mae: 1097.6170 - val_loss: 13991624.0000 - val_mae: 2796.4854\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3245035.2222 - mae: 1164.9931 - val_loss: 13721999.0000 - val_mae: 2783.3550\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2927217.5972 - mae: 1071.3858 - val_loss: 13992747.0000 - val_mae: 2800.3562\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4067896.0556 - mae: 1242.4105 - val_loss: 13836001.0000 - val_mae: 2791.5034\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2457576.8889 - mae: 1018.7163 - val_loss: 14045566.0000 - val_mae: 2799.8860\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3770267.4167 - mae: 1168.1001 - val_loss: 13788056.0000 - val_mae: 2781.8774\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2341148.0694 - mae: 952.2741 - val_loss: 14106284.0000 - val_mae: 2803.2307\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2522395.5833 - mae: 968.0866 - val_loss: 14443650.0000 - val_mae: 2833.7466\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2526253.8472 - mae: 1009.7904 - val_loss: 13835009.0000 - val_mae: 2791.2756\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2937612.8889 - mae: 1077.4439 - val_loss: 14321961.0000 - val_mae: 2823.7710\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3026999.6667 - mae: 1076.4160 - val_loss: 14363577.0000 - val_mae: 2823.7412\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3198316.1528 - mae: 1063.0504 - val_loss: 13712133.0000 - val_mae: 2782.1392\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4102731.6111 - mae: 1176.9315 - val_loss: 13713754.0000 - val_mae: 2778.2217\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3074767.5000 - mae: 1047.5016 - val_loss: 13683097.0000 - val_mae: 2774.0835\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3023663.3889 - mae: 1102.5874 - val_loss: 13478221.0000 - val_mae: 2758.1934\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2813469.6944 - mae: 1066.9743 - val_loss: 13673290.0000 - val_mae: 2775.4033\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2739232.5972 - mae: 1057.9304 - val_loss: 13721246.0000 - val_mae: 2782.9780\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3182586.7222 - mae: 1125.2950 - val_loss: 13793339.0000 - val_mae: 2785.9832\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3179334.0000 - mae: 998.3303 - val_loss: 13870758.0000 - val_mae: 2789.5085\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2767270.9167 - mae: 1061.9848 - val_loss: 14479252.0000 - val_mae: 2827.2141\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2879567.7778 - mae: 1027.2612 - val_loss: 13700899.0000 - val_mae: 2780.5276\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2411183.9722 - mae: 1001.4036 - val_loss: 13459403.0000 - val_mae: 2762.0647\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3588755.3889 - mae: 1131.1975 - val_loss: 13635027.0000 - val_mae: 2772.5444\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2738089.3333 - mae: 1015.8758 - val_loss: 13868006.0000 - val_mae: 2783.6033\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2974274.6806 - mae: 1029.6676 - val_loss: 14103250.0000 - val_mae: 2797.9475\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2433160.9028 - mae: 983.5162 - val_loss: 14231837.0000 - val_mae: 2808.4167\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2879690.0000 - mae: 1065.8106 - val_loss: 14150249.0000 - val_mae: 2800.8975\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2558954.0833 - mae: 968.1537 - val_loss: 13781916.0000 - val_mae: 2779.3574\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3756175.5833 - mae: 1191.0724 - val_loss: 13573553.0000 - val_mae: 2764.2495\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3227860.1111 - mae: 1034.5839 - val_loss: 13789758.0000 - val_mae: 2778.2283\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1859711.7500 - mae: 858.6008 - val_loss: 13691296.0000 - val_mae: 2768.8892\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3203296.5278 - mae: 1023.6845 - val_loss: 13908170.0000 - val_mae: 2784.2136\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2376824.0556 - mae: 956.1067 - val_loss: 14040530.0000 - val_mae: 2797.5264\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2234348.6806 - mae: 902.2525 - val_loss: 14191117.0000 - val_mae: 2805.8135\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3087719.8611 - mae: 1099.4462 - val_loss: 13891633.0000 - val_mae: 2788.9768\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2756558.3056 - mae: 915.7845 - val_loss: 13501765.0000 - val_mae: 2759.9253\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1944107.5556 - mae: 888.8701 - val_loss: 13466459.0000 - val_mae: 2756.6299\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3734148.7500 - mae: 1113.7342 - val_loss: 13897531.0000 - val_mae: 2780.5098\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3164311.0000 - mae: 1052.0021 - val_loss: 14294807.0000 - val_mae: 2813.0674\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2565879.8333 - mae: 994.2851 - val_loss: 14395893.0000 - val_mae: 2821.0271\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2930518.3333 - mae: 974.7305 - val_loss: 13990443.0000 - val_mae: 2794.6765\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2343057.6389 - mae: 921.8142 - val_loss: 14072820.0000 - val_mae: 2797.1204\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2363259.2083 - mae: 931.6217 - val_loss: 14039448.0000 - val_mae: 2798.3040\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2142621.7500 - mae: 918.5236 - val_loss: 14341031.0000 - val_mae: 2817.2273\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2057485.7778 - mae: 865.4631 - val_loss: 14253510.0000 - val_mae: 2812.9614\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2261270.4444 - mae: 894.8449 - val_loss: 14676502.0000 - val_mae: 2843.8215\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2089631.5833 - mae: 883.7021 - val_loss: 14363689.0000 - val_mae: 2822.2402\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2176224.4375 - mae: 851.1748 - val_loss: 14199281.0000 - val_mae: 2810.1355\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2148126.3333 - mae: 907.0660 - val_loss: 14275053.0000 - val_mae: 2815.8662\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2378262.5556 - mae: 919.8060 - val_loss: 13892870.0000 - val_mae: 2787.9890\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2050190.0556 - mae: 897.7582 - val_loss: 14487351.0000 - val_mae: 2828.1482\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2258148.0833 - mae: 899.4105 - val_loss: 14448524.0000 - val_mae: 2828.4500\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2192502.5486 - mae: 854.3391 - val_loss: 14410994.0000 - val_mae: 2825.9309\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2211708.1389 - mae: 865.7769 - val_loss: 14392444.0000 - val_mae: 2821.2234\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2136480.7083 - mae: 930.9341 - val_loss: 14477747.0000 - val_mae: 2831.3694\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2130682.3889 - mae: 892.2601 - val_loss: 14428192.0000 - val_mae: 2828.1902\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2812752.0556 - mae: 976.9876 - val_loss: 14065784.0000 - val_mae: 2803.7935\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2837694.6944 - mae: 981.2943 - val_loss: 14410692.0000 - val_mae: 2824.6516\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1657768.7396 - mae: 776.0708 - val_loss: 15105006.0000 - val_mae: 2870.0930\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1734898.0972 - mae: 808.5744 - val_loss: 14702824.0000 - val_mae: 2844.9292\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1913180.0486 - mae: 855.8725 - val_loss: 14435394.0000 - val_mae: 2830.0400\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1796906.1528 - mae: 815.7300 - val_loss: 14010431.0000 - val_mae: 2798.9111\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1914151.6458 - mae: 837.3923 - val_loss: 14437184.0000 - val_mae: 2824.1460\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1756091.2917 - mae: 824.2898 - val_loss: 15111494.0000 - val_mae: 2872.2959\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1619922.6458 - mae: 780.2856 - val_loss: 14924781.0000 - val_mae: 2860.8101\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1704499.5833 - mae: 828.9162 - val_loss: 14671463.0000 - val_mae: 2844.3037\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1680149.0694 - mae: 804.2088 - val_loss: 14567679.0000 - val_mae: 2837.4819\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1533066.1944 - mae: 750.0028 - val_loss: 14396066.0000 - val_mae: 2824.7646\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2675092.5000 - mae: 900.4569 - val_loss: 14345733.0000 - val_mae: 2825.9954\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1358966.3194 - mae: 737.0656 - val_loss: 14866777.0000 - val_mae: 2865.2332\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1510882.6042 - mae: 736.7209 - val_loss: 14526792.0000 - val_mae: 2837.8582\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2155008.9167 - mae: 756.8489 - val_loss: 14119350.0000 - val_mae: 2808.2222\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1573348.5972 - mae: 800.6854 - val_loss: 14486066.0000 - val_mae: 2837.5447\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1939776.5069 - mae: 805.3396 - val_loss: 14369284.0000 - val_mae: 2829.8811\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1981164.0139 - mae: 785.2860 - val_loss: 14728895.0000 - val_mae: 2853.9077\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1463593.7083 - mae: 788.9983 - val_loss: 15170519.0000 - val_mae: 2888.8848\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1591939.2500 - mae: 804.2539 - val_loss: 14646592.0000 - val_mae: 2857.0991\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1913478.0972 - mae: 888.1127 - val_loss: 14675202.0000 - val_mae: 2858.9465\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1679661.8681 - mae: 717.6151 - val_loss: 14449241.0000 - val_mae: 2839.3330\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1522196.2222 - mae: 778.4700 - val_loss: 15101248.0000 - val_mae: 2882.0186\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1422780.3090 - mae: 670.1120 - val_loss: 14943949.0000 - val_mae: 2869.5320\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1558636.2639 - mae: 778.2062 - val_loss: 14873087.0000 - val_mae: 2865.2913\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1502081.4167 - mae: 774.3355 - val_loss: 14390528.0000 - val_mae: 2828.4824\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2237409.1528 - mae: 838.2433 - val_loss: 15011457.0000 - val_mae: 2876.3052\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1335607.5625 - mae: 700.6006 - val_loss: 14889899.0000 - val_mae: 2868.6121\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2033702.0556 - mae: 769.5700 - val_loss: 14622263.0000 - val_mae: 2850.6575\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1652294.8750 - mae: 759.1848 - val_loss: 14565470.0000 - val_mae: 2847.5000\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1174819.6111 - mae: 701.7415 - val_loss: 14931382.0000 - val_mae: 2874.1885\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2237913.0417 - mae: 843.1019 - val_loss: 14831018.0000 - val_mae: 2870.0903\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1664192.2917 - mae: 719.6761 - val_loss: 14794316.0000 - val_mae: 2866.3267\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1654595.5694 - mae: 781.5460 - val_loss: 15208575.0000 - val_mae: 2896.9773\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1463659.8819 - mae: 715.9060 - val_loss: 15049318.0000 - val_mae: 2884.1277\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1394354.4306 - mae: 707.8430 - val_loss: 14978742.0000 - val_mae: 2884.6663\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1137779.1319 - mae: 666.7131 - val_loss: 14585410.0000 - val_mae: 2848.2153\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1317248.6389 - mae: 723.6743 - val_loss: 14726114.0000 - val_mae: 2854.5471\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1140267.1250 - mae: 675.5110 - val_loss: 15009529.0000 - val_mae: 2869.7849\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1901739.5556 - mae: 752.5750 - val_loss: 14377953.0000 - val_mae: 2834.7686\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1291996.7778 - mae: 704.2013 - val_loss: 15180823.0000 - val_mae: 2887.6809\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1581663.5556 - mae: 727.4699 - val_loss: 14691908.0000 - val_mae: 2849.9500\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1494151.2361 - mae: 745.0768 - val_loss: 14795985.0000 - val_mae: 2856.6118\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2145886.0278 - mae: 829.2414 - val_loss: 14789587.0000 - val_mae: 2858.0796\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1249466.4097 - mae: 698.2820 - val_loss: 14791923.0000 - val_mae: 2862.1812\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 981089.9444 - mae: 623.9728 - val_loss: 15402611.0000 - val_mae: 2897.7085\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1494477.5139 - mae: 768.1193 - val_loss: 14886268.0000 - val_mae: 2866.4375\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1241719.5972 - mae: 678.6519 - val_loss: 14715521.0000 - val_mae: 2856.6682\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1565869.3194 - mae: 690.4340 - val_loss: 14839658.0000 - val_mae: 2866.6050\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1252895.3333 - mae: 650.0523 - val_loss: 15400578.0000 - val_mae: 2897.1619\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1714178.0833 - mae: 711.3931 - val_loss: 14412810.0000 - val_mae: 2837.2222\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1185917.1111 - mae: 651.6161 - val_loss: 15030016.0000 - val_mae: 2874.0183\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1212939.9653 - mae: 658.8882 - val_loss: 15090083.0000 - val_mae: 2877.4558\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 987973.2778 - mae: 612.4538 - val_loss: 14852285.0000 - val_mae: 2865.5740\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1130444.8646 - mae: 612.3484 - val_loss: 14991315.0000 - val_mae: 2876.8604\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1842766.1944 - mae: 759.0573 - val_loss: 15028870.0000 - val_mae: 2878.5864\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1044951.7153 - mae: 651.9233 - val_loss: 15746688.0000 - val_mae: 2929.9790\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1787103.4861 - mae: 742.0847 - val_loss: 15394207.0000 - val_mae: 2910.3699\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1877179.6111 - mae: 809.0298 - val_loss: 15226460.0000 - val_mae: 2902.4417\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1216298.4653 - mae: 707.0486 - val_loss: 15167001.0000 - val_mae: 2896.1511\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1739519.8056 - mae: 691.8765 - val_loss: 15454818.0000 - val_mae: 2914.2979\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1246688.6111 - mae: 644.3453 - val_loss: 15206151.0000 - val_mae: 2896.3135\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 936593.1875 - mae: 603.0019 - val_loss: 15568426.0000 - val_mae: 2912.0469\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1327024.7812 - mae: 636.0202 - val_loss: 14937125.0000 - val_mae: 2879.9556\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1121260.5347 - mae: 603.6345 - val_loss: 14666484.0000 - val_mae: 2865.3970\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1796799.0556 - mae: 722.0663 - val_loss: 15359587.0000 - val_mae: 2905.9451\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1236928.1042 - mae: 618.7817 - val_loss: 15182964.0000 - val_mae: 2895.4424\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 969062.2639 - mae: 644.2736 - val_loss: 15229969.0000 - val_mae: 2900.0701\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1184270.6042 - mae: 636.4474 - val_loss: 15896757.0000 - val_mae: 2939.5142\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1055120.3194 - mae: 682.0721 - val_loss: 15543211.0000 - val_mae: 2923.6843\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1081056.0069 - mae: 616.2259 - val_loss: 15187634.0000 - val_mae: 2903.3308\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1332194.2083 - mae: 638.4847 - val_loss: 15307438.0000 - val_mae: 2904.8831\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1522176.7639 - mae: 612.6572 - val_loss: 15288812.0000 - val_mae: 2906.7295\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1644079.3750 - mae: 673.6760 - val_loss: 15600084.0000 - val_mae: 2930.0940\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1231067.7778 - mae: 679.9307 - val_loss: 15303296.0000 - val_mae: 2912.2822\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 820419.4653 - mae: 550.4435 - val_loss: 15140517.0000 - val_mae: 2908.1631\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1468048.8611 - mae: 587.2046 - val_loss: 15451487.0000 - val_mae: 2921.9626\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 835430.3125 - mae: 578.9926 - val_loss: 15169834.0000 - val_mae: 2904.8462\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1320879.9861 - mae: 638.4248 - val_loss: 15738077.0000 - val_mae: 2930.7458\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 961937.0972 - mae: 557.2591 - val_loss: 15130971.0000 - val_mae: 2898.4431\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 910825.1632 - mae: 543.8876 - val_loss: 14995268.0000 - val_mae: 2905.7493\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1579273.9722 - mae: 657.5651 - val_loss: 15587149.0000 - val_mae: 2928.3552\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1090871.6181 - mae: 605.2227 - val_loss: 15234230.0000 - val_mae: 2908.7327\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 976574.7743 - mae: 564.2000 - val_loss: 15445111.0000 - val_mae: 2915.2712\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1555062.9861 - mae: 702.4418 - val_loss: 15099624.0000 - val_mae: 2904.5212\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1584881.2917 - mae: 657.5148 - val_loss: 15059978.0000 - val_mae: 2903.3054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fXrRpcHbt4VF",
        "outputId": "eeee2cd6-4dc9-4366-d68e-aa0a89cb797a"
      },
      "source": [
        "history_dict = Model_Results2.history\n",
        "mae_values = history_dict['mae']\n",
        "val_mae_values = history_dict['val_mae']\n",
        "epoches = np.arange(1,len(history_dict['mae'])+1)\n",
        "plt.plot(epoches,mae_values,'r',label=\"Training Mae\")\n",
        "plt.plot(epoches,val_mae_values,'g',label=\"Validating Mae\")\n",
        "plt.title('Training and validation Mae')\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Mae\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kduZlTvtWD4C",
        "outputId": "15eeef1d-5ab8-4f8c-bdfb-2eed18b207fd"
      },
      "source": [
        "history_dict = Model_Results2.history\n",
        "val_acc_values = history_dict['val_mae']\n",
        "maxi = np.max(val_acc_values)\n",
        "mini = np.min(val_acc_values)\n",
        "avrg = (maxi+mini)/2\n",
        "print(f\"FOR MODEL1 Average Validation Absolute Error = {avrg}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOR MODEL1 Average Validation Absolute Error = 6619.280029296875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khmyamDgmgeN"
      },
      "source": [
        "# **MAE without K fold and with gelu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_prT5RtWuum",
        "outputId": "779fbbe1-366f-407e-f530-229ebd3aff13"
      },
      "source": [
        "Model_Results3 = Train_Me_with(activation_function=\"gelu\").fit(\n",
        "      train_data,train_labels,batch_size=20,epochs=500,validation_data=(test_data,test_labels)\n",
        "  )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 1s 38ms/step - loss: 285117532.4444 - mae: 14159.2065 - val_loss: 146566592.0000 - val_mae: 11351.2695\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 280125301.3333 - mae: 14116.0660 - val_loss: 146560704.0000 - val_mae: 11351.0410\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 298803484.4444 - mae: 14584.7168 - val_loss: 146552976.0000 - val_mae: 11350.7393\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 274249315.5556 - mae: 13929.5948 - val_loss: 146542176.0000 - val_mae: 11350.3193\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 255515159.1111 - mae: 13683.8050 - val_loss: 146529760.0000 - val_mae: 11349.8291\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 264177768.8889 - mae: 13827.3934 - val_loss: 146512368.0000 - val_mae: 11349.1543\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 273431909.3333 - mae: 13832.3866 - val_loss: 146498976.0000 - val_mae: 11348.6025\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 276821205.3333 - mae: 14167.5723 - val_loss: 146481296.0000 - val_mae: 11347.8926\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 303568042.6667 - mae: 14605.1274 - val_loss: 146458160.0000 - val_mae: 11346.9697\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 310286257.7778 - mae: 14814.5323 - val_loss: 146430816.0000 - val_mae: 11345.8828\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 265611431.1111 - mae: 13869.6051 - val_loss: 146396944.0000 - val_mae: 11344.5459\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 292634682.6667 - mae: 14420.7794 - val_loss: 146359824.0000 - val_mae: 11343.0664\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 245458676.4444 - mae: 13294.2346 - val_loss: 146312000.0000 - val_mae: 11341.1797\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 277414695.1111 - mae: 14209.4013 - val_loss: 146265376.0000 - val_mae: 11339.3105\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 280674371.5556 - mae: 14260.1019 - val_loss: 146201936.0000 - val_mae: 11336.8164\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 304641269.3333 - mae: 14447.5799 - val_loss: 146138928.0000 - val_mae: 11334.3125\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 292704792.8889 - mae: 14497.5329 - val_loss: 146072624.0000 - val_mae: 11331.6426\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 255307242.6667 - mae: 13504.6487 - val_loss: 145997008.0000 - val_mae: 11328.6162\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 273869841.7778 - mae: 14096.7141 - val_loss: 145914688.0000 - val_mae: 11325.3037\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 280146693.3333 - mae: 14010.9056 - val_loss: 145805920.0000 - val_mae: 11321.0098\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 285769296.0000 - mae: 14328.8649 - val_loss: 145698656.0000 - val_mae: 11316.7275\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 270573612.4444 - mae: 13917.5611 - val_loss: 145585264.0000 - val_mae: 11312.1836\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 325961806.2222 - mae: 15106.8541 - val_loss: 145462944.0000 - val_mae: 11307.2666\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 309509194.6667 - mae: 14668.5633 - val_loss: 145322096.0000 - val_mae: 11301.6250\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 283897388.4444 - mae: 14247.1197 - val_loss: 145167520.0000 - val_mae: 11295.4502\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 280475808.0000 - mae: 13996.0472 - val_loss: 144978768.0000 - val_mae: 11287.9961\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 293395018.6667 - mae: 14326.0705 - val_loss: 144789952.0000 - val_mae: 11280.4424\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 273367123.5556 - mae: 13946.7461 - val_loss: 144604608.0000 - val_mae: 11273.0107\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 271286808.8889 - mae: 13915.4224 - val_loss: 144366896.0000 - val_mae: 11263.6211\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 287316972.4444 - mae: 13998.2117 - val_loss: 144161744.0000 - val_mae: 11255.3066\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 266666355.5556 - mae: 13905.0001 - val_loss: 143915536.0000 - val_mae: 11245.4473\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 280834087.1111 - mae: 14191.0393 - val_loss: 143640000.0000 - val_mae: 11234.4570\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 289594645.3333 - mae: 14227.5357 - val_loss: 143343040.0000 - val_mae: 11222.6318\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 273804912.0000 - mae: 13844.1620 - val_loss: 143047040.0000 - val_mae: 11210.6904\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 251579176.8889 - mae: 13413.4536 - val_loss: 142700688.0000 - val_mae: 11196.9180\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 257016547.5556 - mae: 13765.1198 - val_loss: 142350384.0000 - val_mae: 11182.8691\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 257420088.8889 - mae: 13515.9240 - val_loss: 142022272.0000 - val_mae: 11169.4795\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 257157640.8889 - mae: 13591.5174 - val_loss: 141626224.0000 - val_mae: 11153.5225\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 263075109.3333 - mae: 13671.0654 - val_loss: 141229392.0000 - val_mae: 11137.4639\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 257060698.6667 - mae: 13772.5163 - val_loss: 140808912.0000 - val_mae: 11120.3799\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 261506469.3333 - mae: 13635.2039 - val_loss: 140316160.0000 - val_mae: 11100.4551\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 236116087.1111 - mae: 13021.4229 - val_loss: 139834736.0000 - val_mae: 11080.8730\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 320511445.3333 - mae: 14968.9980 - val_loss: 139343408.0000 - val_mae: 11060.7314\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 290107511.1111 - mae: 14139.3019 - val_loss: 138788960.0000 - val_mae: 11038.1875\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 266422856.8889 - mae: 13763.3435 - val_loss: 138175664.0000 - val_mae: 11013.4238\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 268297646.2222 - mae: 13698.7402 - val_loss: 137577712.0000 - val_mae: 10988.9307\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 247803873.7778 - mae: 13174.4674 - val_loss: 136946320.0000 - val_mae: 10963.0098\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 261679232.0000 - mae: 13438.9459 - val_loss: 136317648.0000 - val_mae: 10937.1123\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 248468366.2222 - mae: 13321.5825 - val_loss: 135558896.0000 - val_mae: 10906.0908\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 249224800.0000 - mae: 13362.4427 - val_loss: 134797184.0000 - val_mae: 10874.7012\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 220903025.7778 - mae: 12358.2963 - val_loss: 133993680.0000 - val_mae: 10841.7910\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 269406240.0000 - mae: 13861.1604 - val_loss: 133154344.0000 - val_mae: 10807.2021\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 254088663.1111 - mae: 13363.8057 - val_loss: 132438448.0000 - val_mae: 10776.8418\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 244534193.7778 - mae: 13042.0627 - val_loss: 131629856.0000 - val_mae: 10742.7822\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 236011358.2222 - mae: 12965.3143 - val_loss: 130734328.0000 - val_mae: 10705.1855\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 243897520.0000 - mae: 12908.8749 - val_loss: 129785872.0000 - val_mae: 10665.3496\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 261650522.6667 - mae: 13485.7108 - val_loss: 128789672.0000 - val_mae: 10623.4893\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 244610579.5556 - mae: 12979.2070 - val_loss: 127709376.0000 - val_mae: 10578.0830\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 263053504.0000 - mae: 13561.9349 - val_loss: 126552400.0000 - val_mae: 10529.2793\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 246197169.7778 - mae: 13172.3799 - val_loss: 125490504.0000 - val_mae: 10483.6191\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 235871639.1111 - mae: 12900.1944 - val_loss: 124381352.0000 - val_mae: 10435.8311\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 244492430.2222 - mae: 12985.4423 - val_loss: 123162400.0000 - val_mae: 10383.4434\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 255233411.5556 - mae: 13309.3883 - val_loss: 121995104.0000 - val_mae: 10332.5342\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 227640072.8889 - mae: 12332.3572 - val_loss: 120616872.0000 - val_mae: 10273.0254\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 235718254.2222 - mae: 12703.9005 - val_loss: 119362512.0000 - val_mae: 10217.6992\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 229963070.2222 - mae: 12845.0390 - val_loss: 118017544.0000 - val_mae: 10158.4170\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 230328504.8889 - mae: 12462.0329 - val_loss: 116611280.0000 - val_mae: 10095.9180\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 231126421.3333 - mae: 12626.9421 - val_loss: 115143328.0000 - val_mae: 10030.6582\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 233720270.2222 - mae: 12701.2416 - val_loss: 113690984.0000 - val_mae: 9965.4658\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 225340316.4444 - mae: 12582.9593 - val_loss: 112027816.0000 - val_mae: 9890.8955\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 231317882.6667 - mae: 12593.1879 - val_loss: 110499704.0000 - val_mae: 9821.0479\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 231605011.5556 - mae: 12684.8619 - val_loss: 108961768.0000 - val_mae: 9750.1758\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 211658478.2222 - mae: 12098.6480 - val_loss: 107364304.0000 - val_mae: 9675.8682\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 239183306.6667 - mae: 12650.9446 - val_loss: 105647848.0000 - val_mae: 9595.5596\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 216942128.0000 - mae: 12188.9608 - val_loss: 103733840.0000 - val_mae: 9505.7930\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 231896106.6667 - mae: 12590.8542 - val_loss: 102104984.0000 - val_mae: 9427.7705\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 198280234.6667 - mae: 11530.0995 - val_loss: 100178992.0000 - val_mae: 9335.6846\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 215718720.0000 - mae: 12258.8153 - val_loss: 98416808.0000 - val_mae: 9249.7812\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 179563104.8889 - mae: 11065.9003 - val_loss: 96300560.0000 - val_mae: 9146.8398\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 179096398.2222 - mae: 10858.8632 - val_loss: 94269000.0000 - val_mae: 9046.2842\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 217825384.8889 - mae: 11922.1266 - val_loss: 92293328.0000 - val_mae: 8947.2549\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 177603361.7778 - mae: 10980.4103 - val_loss: 90070544.0000 - val_mae: 8835.1689\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 202032947.5556 - mae: 11262.6376 - val_loss: 88182984.0000 - val_mae: 8737.2021\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 174023957.3333 - mae: 10853.0760 - val_loss: 86188856.0000 - val_mae: 8632.8174\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 189823406.2222 - mae: 11312.2631 - val_loss: 84054424.0000 - val_mae: 8520.5410\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 192448346.6667 - mae: 11255.7345 - val_loss: 81982864.0000 - val_mae: 8409.4258\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 204766725.3333 - mae: 11596.6387 - val_loss: 79803192.0000 - val_mae: 8290.8193\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 159594330.6667 - mae: 10360.8331 - val_loss: 77476632.0000 - val_mae: 8163.1826\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 146555097.7778 - mae: 9879.1364 - val_loss: 74878432.0000 - val_mae: 8019.0957\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 161402557.3333 - mae: 10187.2890 - val_loss: 72928208.0000 - val_mae: 7906.4316\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 140539503.1111 - mae: 9621.6029 - val_loss: 70527296.0000 - val_mae: 7767.2192\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 157326449.7778 - mae: 10010.9787 - val_loss: 68493352.0000 - val_mae: 7646.6338\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 132896952.0000 - mae: 9295.0476 - val_loss: 66305032.0000 - val_mae: 7514.7715\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 152880344.8889 - mae: 9901.5830 - val_loss: 63946376.0000 - val_mae: 7371.1924\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 158567498.6667 - mae: 10046.0516 - val_loss: 61652060.0000 - val_mae: 7226.8799\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 138346832.8889 - mae: 9417.1620 - val_loss: 59086292.0000 - val_mae: 7063.0127\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 126144411.5556 - mae: 8860.0464 - val_loss: 56825472.0000 - val_mae: 6914.9258\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 109295448.4444 - mae: 8300.8014 - val_loss: 54468976.0000 - val_mae: 6757.2788\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 124899057.7778 - mae: 8738.5723 - val_loss: 52149640.0000 - val_mae: 6596.5767\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 116347208.0000 - mae: 8543.4070 - val_loss: 49784992.0000 - val_mae: 6429.4341\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 100797928.8889 - mae: 7895.6739 - val_loss: 47309856.0000 - val_mae: 6250.1450\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 92774061.3333 - mae: 7478.7300 - val_loss: 45050716.0000 - val_mae: 6081.0645\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 108051607.1111 - mae: 7817.3566 - val_loss: 42810616.0000 - val_mae: 5907.4746\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 111502829.3333 - mae: 8141.8875 - val_loss: 40224040.0000 - val_mae: 5703.5908\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 96284758.2222 - mae: 7412.8717 - val_loss: 37909552.0000 - val_mae: 5512.1499\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 85815760.0000 - mae: 7014.6573 - val_loss: 35826708.0000 - val_mae: 5331.0059\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 98266030.2222 - mae: 7445.6562 - val_loss: 33772432.0000 - val_mae: 5148.8765\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 92256969.7778 - mae: 7205.2741 - val_loss: 31724060.0000 - val_mae: 4965.8457\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 83235436.4444 - mae: 6643.0872 - val_loss: 29497324.0000 - val_mae: 4760.4888\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 69372722.2222 - mae: 6105.8118 - val_loss: 27485668.0000 - val_mae: 4563.8379\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 73065791.1111 - mae: 6023.2385 - val_loss: 25457592.0000 - val_mae: 4356.1626\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 81874364.4444 - mae: 6394.4607 - val_loss: 23561860.0000 - val_mae: 4169.5918\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 65286040.8889 - mae: 5701.6518 - val_loss: 21502858.0000 - val_mae: 3954.0339\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 64352518.6667 - mae: 5548.1884 - val_loss: 19928486.0000 - val_mae: 3776.5605\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 44392469.6667 - mae: 4513.5780 - val_loss: 18452756.0000 - val_mae: 3600.5239\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 56107220.0000 - mae: 5100.9697 - val_loss: 16817262.0000 - val_mae: 3402.7876\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 50012189.7778 - mae: 4737.0114 - val_loss: 15632083.0000 - val_mae: 3260.1157\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 35989816.6667 - mae: 4002.8960 - val_loss: 14139963.0000 - val_mae: 3074.0972\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 45358121.3333 - mae: 4522.3285 - val_loss: 13195319.0000 - val_mae: 2955.6179\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 44613137.3333 - mae: 4451.1659 - val_loss: 12252635.0000 - val_mae: 2835.3845\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 44735862.2222 - mae: 4530.5079 - val_loss: 11159860.0000 - val_mae: 2692.3442\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 36765177.1111 - mae: 3846.4698 - val_loss: 10308829.0000 - val_mae: 2580.1382\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 32508495.3333 - mae: 3784.6787 - val_loss: 9602703.0000 - val_mae: 2483.2151\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 39949942.6667 - mae: 4077.4106 - val_loss: 9043921.0000 - val_mae: 2400.5291\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 25351625.6667 - mae: 3361.9701 - val_loss: 8424845.0000 - val_mae: 2303.6038\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25375068.8889 - mae: 3310.6920 - val_loss: 8139269.0000 - val_mae: 2250.4082\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 30170626.2222 - mae: 3610.5380 - val_loss: 7912761.0000 - val_mae: 2196.1917\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25899005.3333 - mae: 3386.7319 - val_loss: 7785389.0000 - val_mae: 2146.7886\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 29784907.1111 - mae: 3638.1441 - val_loss: 7762366.0000 - val_mae: 2128.2019\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 29374198.6667 - mae: 3560.8016 - val_loss: 7809310.0000 - val_mae: 2118.1018\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19597230.3333 - mae: 3033.1924 - val_loss: 7973900.0000 - val_mae: 2133.7566\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24855761.1111 - mae: 3429.9614 - val_loss: 8120972.5000 - val_mae: 2151.1912\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 21983567.5556 - mae: 3402.5732 - val_loss: 8523247.0000 - val_mae: 2192.1917\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19602671.5556 - mae: 3290.3202 - val_loss: 8977262.0000 - val_mae: 2236.9182\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19142208.1111 - mae: 3162.6577 - val_loss: 9184872.0000 - val_mae: 2266.9832\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18126061.4444 - mae: 3108.2776 - val_loss: 9130625.0000 - val_mae: 2263.4351\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19095813.8889 - mae: 3218.7850 - val_loss: 9337251.0000 - val_mae: 2295.3342\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16932917.2222 - mae: 3038.9012 - val_loss: 9233986.0000 - val_mae: 2283.9602\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17422974.0000 - mae: 3060.3308 - val_loss: 9345440.0000 - val_mae: 2301.4829\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 20598680.2222 - mae: 3316.3990 - val_loss: 9793963.0000 - val_mae: 2371.6101\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18065128.5556 - mae: 3118.3614 - val_loss: 9848329.0000 - val_mae: 2383.2102\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15997191.1111 - mae: 3069.6943 - val_loss: 10149998.0000 - val_mae: 2430.5767\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18329500.0000 - mae: 3212.3027 - val_loss: 10424744.0000 - val_mae: 2475.0593\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15671014.3333 - mae: 2900.2344 - val_loss: 10478601.0000 - val_mae: 2484.1152\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19889846.4444 - mae: 3360.1011 - val_loss: 10226779.0000 - val_mae: 2449.0525\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16536068.4444 - mae: 3061.6077 - val_loss: 9923269.0000 - val_mae: 2409.4014\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14811705.8889 - mae: 2890.9839 - val_loss: 10015108.0000 - val_mae: 2421.5161\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18734731.2222 - mae: 3121.0963 - val_loss: 9907560.0000 - val_mae: 2410.9167\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15952283.0000 - mae: 2943.9583 - val_loss: 9813271.0000 - val_mae: 2402.8459\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15608803.6111 - mae: 2871.5616 - val_loss: 10234106.0000 - val_mae: 2456.6714\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 20473938.4444 - mae: 3349.3233 - val_loss: 9982475.0000 - val_mae: 2426.8059\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19871901.7778 - mae: 3238.6323 - val_loss: 9819864.0000 - val_mae: 2405.0881\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15311625.4444 - mae: 2926.7942 - val_loss: 9783084.0000 - val_mae: 2400.0925\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15517868.4444 - mae: 2892.9184 - val_loss: 10208481.0000 - val_mae: 2456.4658\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 20303004.8889 - mae: 3171.8981 - val_loss: 10305835.0000 - val_mae: 2474.2300\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16073241.3333 - mae: 2896.6319 - val_loss: 10101099.0000 - val_mae: 2448.1465\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15473917.7778 - mae: 2902.5793 - val_loss: 9837186.0000 - val_mae: 2412.3562\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15419071.2222 - mae: 2933.1470 - val_loss: 10129939.0000 - val_mae: 2452.4077\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19074401.3333 - mae: 3152.4257 - val_loss: 9959128.0000 - val_mae: 2425.2266\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15987849.7778 - mae: 2978.5768 - val_loss: 10266849.0000 - val_mae: 2471.0986\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14750087.4444 - mae: 2840.2852 - val_loss: 10240556.0000 - val_mae: 2466.1987\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16635074.4444 - mae: 3122.6193 - val_loss: 10341161.0000 - val_mae: 2480.5161\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16150485.8889 - mae: 2885.8961 - val_loss: 10028907.0000 - val_mae: 2436.9968\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16415489.8889 - mae: 3033.3168 - val_loss: 10314766.0000 - val_mae: 2476.1619\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13481448.1111 - mae: 2762.7261 - val_loss: 10464292.0000 - val_mae: 2497.4939\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 15840745.5556 - mae: 3024.1542 - val_loss: 10949248.0000 - val_mae: 2563.6904\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13241027.5556 - mae: 2699.3173 - val_loss: 10874240.0000 - val_mae: 2551.8386\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12255223.4444 - mae: 2639.5112 - val_loss: 10601841.0000 - val_mae: 2513.2769\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15400373.1111 - mae: 2931.2944 - val_loss: 10690173.0000 - val_mae: 2523.0427\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14500350.7778 - mae: 2745.4293 - val_loss: 10348420.0000 - val_mae: 2476.9312\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13067004.1111 - mae: 2638.4533 - val_loss: 10153827.0000 - val_mae: 2450.6091\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16492207.7778 - mae: 2988.2281 - val_loss: 10035627.0000 - val_mae: 2435.8162\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13015019.5556 - mae: 2645.0643 - val_loss: 10187917.0000 - val_mae: 2452.6260\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12750692.1111 - mae: 2604.4120 - val_loss: 9953113.0000 - val_mae: 2422.8088\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14667978.4444 - mae: 2777.6086 - val_loss: 10036519.0000 - val_mae: 2431.6846\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12597200.5556 - mae: 2672.6712 - val_loss: 10238607.0000 - val_mae: 2453.9470\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12108286.2222 - mae: 2551.5275 - val_loss: 9977165.0000 - val_mae: 2429.3003\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12821430.1111 - mae: 2479.5976 - val_loss: 9710937.0000 - val_mae: 2406.4031\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11554834.7778 - mae: 2535.9380 - val_loss: 9858547.0000 - val_mae: 2419.5076\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11938287.6111 - mae: 2489.3621 - val_loss: 10233134.0000 - val_mae: 2465.0271\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12770815.6667 - mae: 2617.7589 - val_loss: 10325062.0000 - val_mae: 2475.4844\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11228727.5000 - mae: 2463.4766 - val_loss: 10686263.0000 - val_mae: 2509.7607\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10419828.3333 - mae: 2412.1504 - val_loss: 10711847.0000 - val_mae: 2512.2727\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11498522.1667 - mae: 2358.0476 - val_loss: 10237476.0000 - val_mae: 2470.8879\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13782246.4444 - mae: 2655.8487 - val_loss: 10315997.0000 - val_mae: 2477.4553\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12072570.7222 - mae: 2493.3420 - val_loss: 10149111.0000 - val_mae: 2463.5457\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9669408.8333 - mae: 2320.6295 - val_loss: 10810841.0000 - val_mae: 2532.1882\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11766454.1111 - mae: 2542.3619 - val_loss: 10720366.0000 - val_mae: 2526.8181\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9431191.3889 - mae: 2244.0662 - val_loss: 10540453.0000 - val_mae: 2514.6611\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 13187017.5556 - mae: 2658.8177 - val_loss: 10304204.0000 - val_mae: 2488.8284\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12096989.7778 - mae: 2495.1023 - val_loss: 10235634.0000 - val_mae: 2483.6033\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10032400.4444 - mae: 2308.1874 - val_loss: 10348525.0000 - val_mae: 2494.6770\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11750477.3333 - mae: 2511.5104 - val_loss: 11043890.0000 - val_mae: 2568.6592\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10901699.5556 - mae: 2443.8018 - val_loss: 11084699.0000 - val_mae: 2572.7651\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10062409.0556 - mae: 2294.8104 - val_loss: 10799161.0000 - val_mae: 2546.6104\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9073110.1667 - mae: 2186.5206 - val_loss: 10880817.0000 - val_mae: 2551.8835\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10846691.7778 - mae: 2439.4917 - val_loss: 10715977.0000 - val_mae: 2535.4839\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9754503.3333 - mae: 2324.0028 - val_loss: 10537803.0000 - val_mae: 2517.9990\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10583835.5556 - mae: 2344.2526 - val_loss: 11057140.0000 - val_mae: 2575.3621\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8578048.5000 - mae: 2119.5731 - val_loss: 11314648.0000 - val_mae: 2601.1147\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9933713.0000 - mae: 2239.5735 - val_loss: 10787678.0000 - val_mae: 2551.8503\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9944495.8889 - mae: 2288.2563 - val_loss: 10930219.0000 - val_mae: 2564.7112\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 10214084.5556 - mae: 2238.4983 - val_loss: 10650606.0000 - val_mae: 2538.5251\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8959393.2222 - mae: 2165.6057 - val_loss: 10459233.0000 - val_mae: 2518.9197\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9554629.3333 - mae: 2194.9464 - val_loss: 10539936.0000 - val_mae: 2528.5012\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10612986.7778 - mae: 2347.1665 - val_loss: 10478619.0000 - val_mae: 2520.8025\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9903593.3333 - mae: 2172.7371 - val_loss: 10581029.0000 - val_mae: 2533.0837\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7855408.2222 - mae: 2050.0887 - val_loss: 10780498.0000 - val_mae: 2549.8345\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8630186.3889 - mae: 2105.3868 - val_loss: 11381453.0000 - val_mae: 2613.5076\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7603751.5000 - mae: 1973.2175 - val_loss: 11240638.0000 - val_mae: 2601.3374\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7570651.5000 - mae: 1974.8588 - val_loss: 10841892.0000 - val_mae: 2562.5095\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7089352.6111 - mae: 1859.5670 - val_loss: 10825604.0000 - val_mae: 2558.5781\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9063546.7222 - mae: 2123.4579 - val_loss: 10704801.0000 - val_mae: 2549.8174\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6757241.3333 - mae: 1858.3377 - val_loss: 11245739.0000 - val_mae: 2596.0891\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7817920.1111 - mae: 1980.8541 - val_loss: 11172442.0000 - val_mae: 2589.7366\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9466690.5556 - mae: 2129.9492 - val_loss: 11502891.0000 - val_mae: 2623.8447\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7133954.4444 - mae: 1911.3302 - val_loss: 11498220.0000 - val_mae: 2625.1389\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7012139.7778 - mae: 1912.4897 - val_loss: 11467299.0000 - val_mae: 2624.1489\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6888266.7222 - mae: 1782.7201 - val_loss: 11058420.0000 - val_mae: 2587.9048\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8119797.8333 - mae: 1974.3915 - val_loss: 11005164.0000 - val_mae: 2586.4871\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8591340.0556 - mae: 2015.5394 - val_loss: 11459897.0000 - val_mae: 2630.4773\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7512325.3333 - mae: 1913.6867 - val_loss: 11366579.0000 - val_mae: 2624.5798\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8030818.8889 - mae: 1954.9833 - val_loss: 11731647.0000 - val_mae: 2660.7437\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7049430.9444 - mae: 1914.1303 - val_loss: 11459458.0000 - val_mae: 2636.1001\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7366416.2778 - mae: 1886.3929 - val_loss: 11436242.0000 - val_mae: 2634.7671\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8290216.8889 - mae: 1928.1059 - val_loss: 11742982.0000 - val_mae: 2665.9136\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7036664.4444 - mae: 1871.1250 - val_loss: 11728379.0000 - val_mae: 2666.5757\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5271782.5833 - mae: 1582.3164 - val_loss: 11507840.0000 - val_mae: 2647.6648\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8426197.8333 - mae: 1928.0341 - val_loss: 11433191.0000 - val_mae: 2640.0229\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6464719.5000 - mae: 1795.2724 - val_loss: 11978706.0000 - val_mae: 2690.0403\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6131469.5556 - mae: 1743.5031 - val_loss: 11947338.0000 - val_mae: 2690.5400\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5585774.8333 - mae: 1690.2047 - val_loss: 11374018.0000 - val_mae: 2642.1238\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7177807.2222 - mae: 1838.2230 - val_loss: 11445499.0000 - val_mae: 2649.0874\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6763180.7778 - mae: 1677.5875 - val_loss: 11634111.0000 - val_mae: 2662.7871\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6704302.8889 - mae: 1746.2121 - val_loss: 11738603.0000 - val_mae: 2672.5291\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5626957.8056 - mae: 1630.8568 - val_loss: 11817426.0000 - val_mae: 2682.1980\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6141682.4444 - mae: 1760.5961 - val_loss: 12064602.0000 - val_mae: 2704.2200\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5784341.2778 - mae: 1700.1002 - val_loss: 11620103.0000 - val_mae: 2673.2664\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6356278.0000 - mae: 1763.2141 - val_loss: 11624689.0000 - val_mae: 2673.5200\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5933936.2778 - mae: 1759.4362 - val_loss: 11509234.0000 - val_mae: 2667.3982\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6193246.0000 - mae: 1607.4754 - val_loss: 12085363.0000 - val_mae: 2715.7854\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5423737.5556 - mae: 1641.8909 - val_loss: 12067347.0000 - val_mae: 2718.3066\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5456229.0000 - mae: 1628.9233 - val_loss: 12255238.0000 - val_mae: 2731.8235\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6530251.5000 - mae: 1719.0318 - val_loss: 12117713.0000 - val_mae: 2725.1821\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6297900.8333 - mae: 1701.5381 - val_loss: 12264904.0000 - val_mae: 2737.2893\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5564714.0000 - mae: 1645.7450 - val_loss: 11719370.0000 - val_mae: 2693.4792\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6379494.8333 - mae: 1717.9971 - val_loss: 11953052.0000 - val_mae: 2707.8149\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5844669.6111 - mae: 1657.3306 - val_loss: 12366962.0000 - val_mae: 2744.6077\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6260631.9444 - mae: 1643.1423 - val_loss: 11859431.0000 - val_mae: 2706.6213\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6449858.3333 - mae: 1745.8651 - val_loss: 11939264.0000 - val_mae: 2714.9480\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4946959.8333 - mae: 1516.5411 - val_loss: 11922322.0000 - val_mae: 2712.3457\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5851061.5556 - mae: 1569.7762 - val_loss: 12197161.0000 - val_mae: 2732.3750\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5104866.3889 - mae: 1570.5581 - val_loss: 12895086.0000 - val_mae: 2785.5020\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4382626.6944 - mae: 1482.8141 - val_loss: 12104883.0000 - val_mae: 2728.0972\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5701699.5556 - mae: 1582.5874 - val_loss: 12212005.0000 - val_mae: 2742.4705\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4119307.6667 - mae: 1419.6661 - val_loss: 12126035.0000 - val_mae: 2740.9204\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5046044.1944 - mae: 1502.2542 - val_loss: 12316216.0000 - val_mae: 2759.7178\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4873195.5278 - mae: 1475.4934 - val_loss: 12367220.0000 - val_mae: 2766.1980\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4027069.9444 - mae: 1406.5461 - val_loss: 12974701.0000 - val_mae: 2811.8074\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4428958.4722 - mae: 1458.6533 - val_loss: 12991683.0000 - val_mae: 2814.0737\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4939570.3333 - mae: 1470.9582 - val_loss: 13498540.0000 - val_mae: 2860.8367\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5364364.7500 - mae: 1558.8795 - val_loss: 12916645.0000 - val_mae: 2815.9629\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3865650.3889 - mae: 1328.8055 - val_loss: 13549389.0000 - val_mae: 2866.9771\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3414616.8056 - mae: 1309.4474 - val_loss: 13814875.0000 - val_mae: 2890.9868\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4407775.0000 - mae: 1418.0759 - val_loss: 13531009.0000 - val_mae: 2866.4829\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4451633.2222 - mae: 1440.3466 - val_loss: 13389951.0000 - val_mae: 2851.0933\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3743409.0278 - mae: 1366.7757 - val_loss: 12950688.0000 - val_mae: 2817.2598\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4824187.3333 - mae: 1432.1927 - val_loss: 12606315.0000 - val_mae: 2795.4045\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4248726.9722 - mae: 1418.1453 - val_loss: 13208254.0000 - val_mae: 2837.1655\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3902695.0556 - mae: 1351.9427 - val_loss: 13745054.0000 - val_mae: 2881.4341\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4420441.0278 - mae: 1369.4087 - val_loss: 13484825.0000 - val_mae: 2861.0945\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3965708.2222 - mae: 1363.0502 - val_loss: 13662397.0000 - val_mae: 2878.8650\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3768651.6111 - mae: 1339.2520 - val_loss: 13968760.0000 - val_mae: 2904.1094\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3792998.9444 - mae: 1301.0664 - val_loss: 12933707.0000 - val_mae: 2825.5894\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5271840.8611 - mae: 1492.4345 - val_loss: 13025536.0000 - val_mae: 2832.9141\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4051708.1944 - mae: 1353.1790 - val_loss: 12982151.0000 - val_mae: 2827.7334\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3643028.1389 - mae: 1339.4075 - val_loss: 13311617.0000 - val_mae: 2848.7856\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3487361.5278 - mae: 1276.8164 - val_loss: 13866222.0000 - val_mae: 2895.4824\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4167783.4167 - mae: 1333.4837 - val_loss: 13875460.0000 - val_mae: 2892.9292\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4325049.5833 - mae: 1356.3689 - val_loss: 13831411.0000 - val_mae: 2892.4141\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3304734.0694 - mae: 1160.7948 - val_loss: 13468386.0000 - val_mae: 2865.1514\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3285140.3194 - mae: 1225.3923 - val_loss: 13802802.0000 - val_mae: 2893.2861\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3453060.9722 - mae: 1280.5562 - val_loss: 13167193.0000 - val_mae: 2841.2703\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4030550.6389 - mae: 1358.2926 - val_loss: 13521335.0000 - val_mae: 2869.3987\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3301821.9722 - mae: 1216.5050 - val_loss: 13064173.0000 - val_mae: 2835.2922\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3613894.7778 - mae: 1276.2634 - val_loss: 13030718.0000 - val_mae: 2835.6780\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3272891.9167 - mae: 1294.7439 - val_loss: 13486432.0000 - val_mae: 2873.6348\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2993389.6667 - mae: 1140.7149 - val_loss: 14058158.0000 - val_mae: 2921.4399\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3417119.3611 - mae: 1182.3492 - val_loss: 14331805.0000 - val_mae: 2944.3784\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3451446.5278 - mae: 1248.5779 - val_loss: 13789696.0000 - val_mae: 2901.6956\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2741022.4306 - mae: 1163.2787 - val_loss: 13974514.0000 - val_mae: 2919.0857\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3236892.0972 - mae: 1135.2498 - val_loss: 14543402.0000 - val_mae: 2968.8083\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3120701.0278 - mae: 1188.4068 - val_loss: 14040598.0000 - val_mae: 2933.7471\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4217865.3056 - mae: 1391.4187 - val_loss: 14130515.0000 - val_mae: 2935.2341\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3105922.9722 - mae: 1119.5738 - val_loss: 13913566.0000 - val_mae: 2920.8811\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2706047.1389 - mae: 1125.1903 - val_loss: 13695327.0000 - val_mae: 2901.3931\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2580813.0556 - mae: 1050.7535 - val_loss: 13923439.0000 - val_mae: 2918.5454\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2954170.8056 - mae: 1212.3549 - val_loss: 14352376.0000 - val_mae: 2955.2896\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2751893.3333 - mae: 1089.7418 - val_loss: 14666431.0000 - val_mae: 2982.7939\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2854951.2778 - mae: 1126.8071 - val_loss: 14472863.0000 - val_mae: 2964.6187\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3648702.3056 - mae: 1242.3532 - val_loss: 13752000.0000 - val_mae: 2908.4619\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3232986.8889 - mae: 1217.0274 - val_loss: 14046200.0000 - val_mae: 2926.6870\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2929304.5278 - mae: 1126.5062 - val_loss: 14020307.0000 - val_mae: 2928.4607\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3158117.9444 - mae: 1177.3859 - val_loss: 14668188.0000 - val_mae: 2977.8640\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2561812.8611 - mae: 1028.0252 - val_loss: 13930140.0000 - val_mae: 2918.9067\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3274315.0833 - mae: 1171.1892 - val_loss: 14270212.0000 - val_mae: 2943.0059\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2933928.3889 - mae: 1133.2365 - val_loss: 14075224.0000 - val_mae: 2926.6653\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2511777.7500 - mae: 1019.7665 - val_loss: 13517909.0000 - val_mae: 2876.7476\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3650099.4444 - mae: 1191.8799 - val_loss: 13327355.0000 - val_mae: 2858.4260\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2479026.1389 - mae: 1030.1815 - val_loss: 13422153.0000 - val_mae: 2865.9968\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2731561.1111 - mae: 1066.0114 - val_loss: 14471906.0000 - val_mae: 2953.3525\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2554664.9306 - mae: 1007.9715 - val_loss: 14030708.0000 - val_mae: 2919.8982\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2092209.7500 - mae: 967.8197 - val_loss: 14614425.0000 - val_mae: 2970.9812\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2611642.5694 - mae: 1040.5876 - val_loss: 14897742.0000 - val_mae: 2997.8269\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2929576.9583 - mae: 1081.7237 - val_loss: 14612444.0000 - val_mae: 2972.1699\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2377837.8750 - mae: 980.5332 - val_loss: 14237817.0000 - val_mae: 2940.2600\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2475852.2778 - mae: 1075.5751 - val_loss: 13638867.0000 - val_mae: 2886.8721\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2439674.0556 - mae: 1022.1674 - val_loss: 13865249.0000 - val_mae: 2908.4863\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2146688.1389 - mae: 969.7171 - val_loss: 14234390.0000 - val_mae: 2939.5459\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3035115.4167 - mae: 1104.1952 - val_loss: 14433607.0000 - val_mae: 2956.1987\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1953936.6806 - mae: 953.2032 - val_loss: 14564740.0000 - val_mae: 2966.8987\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3191069.4167 - mae: 1108.6660 - val_loss: 13565800.0000 - val_mae: 2881.4214\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2591751.6944 - mae: 1075.4696 - val_loss: 14684926.0000 - val_mae: 2975.7336\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2393483.0556 - mae: 978.0650 - val_loss: 14420299.0000 - val_mae: 2957.6511\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1988111.8056 - mae: 966.2747 - val_loss: 14654074.0000 - val_mae: 2973.7795\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2444162.6528 - mae: 1009.9354 - val_loss: 14582773.0000 - val_mae: 2972.4600\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2395948.6528 - mae: 993.5843 - val_loss: 14448905.0000 - val_mae: 2958.5969\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2188447.2500 - mae: 928.1513 - val_loss: 14437896.0000 - val_mae: 2956.5437\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2133061.3750 - mae: 959.7929 - val_loss: 14209353.0000 - val_mae: 2937.6831\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2356523.4444 - mae: 1023.2720 - val_loss: 13758598.0000 - val_mae: 2895.6606\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2367594.1806 - mae: 1008.0610 - val_loss: 14382283.0000 - val_mae: 2948.8250\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2877979.1667 - mae: 1048.6739 - val_loss: 14798146.0000 - val_mae: 2977.0276\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2477511.2778 - mae: 1021.1310 - val_loss: 14396430.0000 - val_mae: 2951.2239\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2269145.0278 - mae: 949.8221 - val_loss: 14539144.0000 - val_mae: 2963.2373\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2036398.0799 - mae: 888.9828 - val_loss: 13689579.0000 - val_mae: 2892.7141\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2250290.5972 - mae: 924.2404 - val_loss: 13525570.0000 - val_mae: 2873.3799\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1798852.2083 - mae: 898.6298 - val_loss: 14570601.0000 - val_mae: 2961.0925\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1787639.6111 - mae: 851.3183 - val_loss: 14474405.0000 - val_mae: 2951.2876\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2207888.8056 - mae: 984.1328 - val_loss: 15241000.0000 - val_mae: 3008.8401\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2742411.9167 - mae: 1046.7977 - val_loss: 14327895.0000 - val_mae: 2945.7332\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2532731.3333 - mae: 995.2570 - val_loss: 14315775.0000 - val_mae: 2943.5183\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2129895.7083 - mae: 902.9090 - val_loss: 13982564.0000 - val_mae: 2911.7712\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1793212.5139 - mae: 920.0233 - val_loss: 14034243.0000 - val_mae: 2913.3906\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1862618.7778 - mae: 943.6000 - val_loss: 15028999.0000 - val_mae: 2996.5452\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2073348.6111 - mae: 933.2656 - val_loss: 15056517.0000 - val_mae: 2996.2424\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1969554.2222 - mae: 933.7936 - val_loss: 14514986.0000 - val_mae: 2952.8596\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2078513.4583 - mae: 941.2665 - val_loss: 15273693.0000 - val_mae: 3015.0718\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1971467.6667 - mae: 910.5586 - val_loss: 14107958.0000 - val_mae: 2923.5227\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2820109.3611 - mae: 1022.3157 - val_loss: 14836345.0000 - val_mae: 2979.3892\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1657720.3889 - mae: 850.7342 - val_loss: 14794495.0000 - val_mae: 2977.7183\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2169207.0833 - mae: 924.3767 - val_loss: 14746631.0000 - val_mae: 2976.8552\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1614082.2500 - mae: 820.6983 - val_loss: 14998673.0000 - val_mae: 2986.3015\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1578907.4583 - mae: 853.2222 - val_loss: 14872068.0000 - val_mae: 2978.6099\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1656397.9028 - mae: 809.5452 - val_loss: 14775086.0000 - val_mae: 2968.1968\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1851701.8403 - mae: 841.3015 - val_loss: 14241858.0000 - val_mae: 2932.5110\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1661823.0903 - mae: 839.4755 - val_loss: 15216425.0000 - val_mae: 3003.7354\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1559058.4167 - mae: 818.9002 - val_loss: 15162586.0000 - val_mae: 3000.1152\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2377485.4444 - mae: 973.4817 - val_loss: 14883228.0000 - val_mae: 2976.6689\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1601586.6944 - mae: 812.6347 - val_loss: 15301687.0000 - val_mae: 3000.4255\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1508696.3750 - mae: 835.4961 - val_loss: 15777042.0000 - val_mae: 3041.2798\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1510063.3194 - mae: 816.3869 - val_loss: 15242044.0000 - val_mae: 3011.8923\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2172278.5000 - mae: 884.7735 - val_loss: 14819775.0000 - val_mae: 2979.9448\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1406632.7778 - mae: 746.1702 - val_loss: 15049944.0000 - val_mae: 2992.0923\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1927675.5000 - mae: 878.2123 - val_loss: 14743650.0000 - val_mae: 2973.8411\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1367760.0625 - mae: 766.6454 - val_loss: 15362658.0000 - val_mae: 3016.5112\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1686087.7083 - mae: 821.5001 - val_loss: 14809387.0000 - val_mae: 2980.2627\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1466331.1389 - mae: 799.9830 - val_loss: 15007119.0000 - val_mae: 2988.7166\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1301199.7431 - mae: 746.6607 - val_loss: 14857969.0000 - val_mae: 2984.4561\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1186582.5556 - mae: 699.0878 - val_loss: 16175672.0000 - val_mae: 3084.7207\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1608160.8750 - mae: 833.3582 - val_loss: 15653234.0000 - val_mae: 3053.2009\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1378273.7986 - mae: 775.4780 - val_loss: 15327226.0000 - val_mae: 3028.1060\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1270031.1701 - mae: 719.4084 - val_loss: 14709354.0000 - val_mae: 2983.8809\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1452779.0972 - mae: 771.7896 - val_loss: 14562463.0000 - val_mae: 2966.5769\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2071858.5972 - mae: 844.9102 - val_loss: 14129960.0000 - val_mae: 2937.9133\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1293380.9861 - mae: 743.0051 - val_loss: 14756221.0000 - val_mae: 2982.7104\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1427897.6979 - mae: 728.8060 - val_loss: 14887665.0000 - val_mae: 2987.6848\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1450009.3958 - mae: 719.5766 - val_loss: 15165262.0000 - val_mae: 3006.1748\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1474996.5903 - mae: 776.9921 - val_loss: 15502518.0000 - val_mae: 3026.5583\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1502261.5000 - mae: 759.7074 - val_loss: 15058334.0000 - val_mae: 3008.7244\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1168112.6667 - mae: 709.7347 - val_loss: 15781918.0000 - val_mae: 3046.9390\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1814702.3472 - mae: 801.4903 - val_loss: 14608698.0000 - val_mae: 2964.5518\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1217559.3056 - mae: 697.8547 - val_loss: 14417448.0000 - val_mae: 2954.0286\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1605295.2639 - mae: 805.7309 - val_loss: 14921511.0000 - val_mae: 2992.5369\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1494924.0694 - mae: 733.5505 - val_loss: 15038149.0000 - val_mae: 2996.3608\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1560632.4722 - mae: 754.2798 - val_loss: 14418509.0000 - val_mae: 2963.4578\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1341889.9306 - mae: 741.9278 - val_loss: 14684435.0000 - val_mae: 2982.7708\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1417516.8889 - mae: 755.5537 - val_loss: 15447361.0000 - val_mae: 3028.4529\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1839819.2778 - mae: 779.6913 - val_loss: 14534107.0000 - val_mae: 2973.2188\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1148074.8924 - mae: 665.8432 - val_loss: 15007073.0000 - val_mae: 3003.7947\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1373251.6319 - mae: 694.9755 - val_loss: 15099606.0000 - val_mae: 3013.8037\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1378454.1111 - mae: 771.1399 - val_loss: 15315207.0000 - val_mae: 3025.2495\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1140062.7222 - mae: 638.8702 - val_loss: 15362243.0000 - val_mae: 3025.3984\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1782933.2361 - mae: 769.0801 - val_loss: 14940968.0000 - val_mae: 3001.9219\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1253055.8229 - mae: 679.2698 - val_loss: 15145086.0000 - val_mae: 3013.2627\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 985062.3750 - mae: 622.4112 - val_loss: 14893587.0000 - val_mae: 3008.7893\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1394689.7639 - mae: 740.1039 - val_loss: 15373575.0000 - val_mae: 3030.8799\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1451279.4097 - mae: 694.2997 - val_loss: 15657629.0000 - val_mae: 3040.2339\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1210718.3958 - mae: 717.5180 - val_loss: 15828903.0000 - val_mae: 3048.3694\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1160277.4653 - mae: 676.9929 - val_loss: 16030760.0000 - val_mae: 3068.2456\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1188053.0694 - mae: 670.2464 - val_loss: 15128124.0000 - val_mae: 3020.3726\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1463798.6389 - mae: 690.1439 - val_loss: 14942371.0000 - val_mae: 3008.1492\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 918924.9028 - mae: 593.2314 - val_loss: 15939379.0000 - val_mae: 3066.3210\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1003252.7431 - mae: 624.4374 - val_loss: 16210712.0000 - val_mae: 3097.0183\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1079344.8403 - mae: 646.3291 - val_loss: 14925819.0000 - val_mae: 3013.6062\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1031103.7500 - mae: 627.6227 - val_loss: 14876588.0000 - val_mae: 3004.8784\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1297046.4792 - mae: 673.7269 - val_loss: 15389454.0000 - val_mae: 3034.2114\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1364245.0139 - mae: 658.6297 - val_loss: 15512544.0000 - val_mae: 3053.2510\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 964362.2292 - mae: 590.7353 - val_loss: 14928773.0000 - val_mae: 3011.7344\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 823196.0764 - mae: 580.6208 - val_loss: 16449743.0000 - val_mae: 3113.1079\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 969082.3958 - mae: 650.1918 - val_loss: 16144481.0000 - val_mae: 3099.2275\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 929121.2986 - mae: 616.6370 - val_loss: 15792380.0000 - val_mae: 3080.0972\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1155327.6667 - mae: 632.4966 - val_loss: 16289501.0000 - val_mae: 3108.7693\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1056610.2153 - mae: 635.8305 - val_loss: 15697226.0000 - val_mae: 3072.8770\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1135857.1042 - mae: 661.8004 - val_loss: 15845043.0000 - val_mae: 3081.1848\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1340085.4167 - mae: 677.0174 - val_loss: 15689672.0000 - val_mae: 3068.3081\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 847272.1285 - mae: 552.9707 - val_loss: 16181763.0000 - val_mae: 3098.5603\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1377644.1667 - mae: 661.1480 - val_loss: 14987132.0000 - val_mae: 3020.9907\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1092348.8646 - mae: 614.2678 - val_loss: 15305490.0000 - val_mae: 3050.1582\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 832387.4688 - mae: 561.3813 - val_loss: 15815744.0000 - val_mae: 3078.3125\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 857951.4097 - mae: 569.3506 - val_loss: 16346422.0000 - val_mae: 3114.9360\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1450486.1528 - mae: 700.2737 - val_loss: 15101541.0000 - val_mae: 3031.9392\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 881843.3819 - mae: 603.9834 - val_loss: 16629135.0000 - val_mae: 3137.6594\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1005026.9792 - mae: 641.4740 - val_loss: 16330210.0000 - val_mae: 3123.4048\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1009930.8333 - mae: 606.9328 - val_loss: 16433147.0000 - val_mae: 3129.2124\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 859402.2639 - mae: 550.0502 - val_loss: 15554871.0000 - val_mae: 3072.5208\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 900971.8403 - mae: 543.0471 - val_loss: 15280708.0000 - val_mae: 3051.9758\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1057069.5972 - mae: 616.2172 - val_loss: 15682333.0000 - val_mae: 3071.6951\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1028467.5833 - mae: 611.4095 - val_loss: 15730410.0000 - val_mae: 3076.0208\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 917183.2257 - mae: 553.5440 - val_loss: 15835123.0000 - val_mae: 3079.7405\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 837091.4931 - mae: 546.2112 - val_loss: 15952818.0000 - val_mae: 3098.9517\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 877399.8958 - mae: 570.8954 - val_loss: 16065155.0000 - val_mae: 3102.4187\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 836318.5417 - mae: 525.0422 - val_loss: 15910132.0000 - val_mae: 3096.7629\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1332454.6319 - mae: 628.9181 - val_loss: 16240726.0000 - val_mae: 3115.8550\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1243599.9931 - mae: 604.5000 - val_loss: 15902621.0000 - val_mae: 3081.5769\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1032127.4097 - mae: 589.7028 - val_loss: 16387469.0000 - val_mae: 3119.0981\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1065146.6806 - mae: 610.4470 - val_loss: 16413102.0000 - val_mae: 3126.9866\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 913191.3889 - mae: 545.1842 - val_loss: 16089889.0000 - val_mae: 3108.1335\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1079850.4618 - mae: 578.4770 - val_loss: 15727744.0000 - val_mae: 3072.1870\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 798418.8889 - mae: 529.2171 - val_loss: 16283791.0000 - val_mae: 3114.4829\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 750208.1493 - mae: 485.5052 - val_loss: 15685440.0000 - val_mae: 3070.7629\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 636203.0069 - mae: 482.1019 - val_loss: 17179852.0000 - val_mae: 3179.7439\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 903203.0208 - mae: 615.5199 - val_loss: 17087328.0000 - val_mae: 3178.7703\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1270922.0347 - mae: 660.5891 - val_loss: 16752883.0000 - val_mae: 3157.8892\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 766429.2569 - mae: 517.9647 - val_loss: 16549233.0000 - val_mae: 3146.1907\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 625979.6979 - mae: 467.2649 - val_loss: 16233640.0000 - val_mae: 3125.0867\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 811754.7014 - mae: 514.0002 - val_loss: 16019599.0000 - val_mae: 3114.2913\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 678674.3524 - mae: 455.1209 - val_loss: 15641699.0000 - val_mae: 3082.9968\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1078928.9826 - mae: 588.6414 - val_loss: 15912754.0000 - val_mae: 3102.0220\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 903118.8958 - mae: 567.1104 - val_loss: 16397987.0000 - val_mae: 3128.0969\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 797749.4792 - mae: 528.7284 - val_loss: 16846472.0000 - val_mae: 3159.3608\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 817822.9375 - mae: 533.3955 - val_loss: 16893012.0000 - val_mae: 3166.4050\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 774155.1250 - mae: 482.0876 - val_loss: 16359337.0000 - val_mae: 3114.3882\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 665529.2986 - mae: 486.2000 - val_loss: 17467128.0000 - val_mae: 3205.9387\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1205803.8611 - mae: 655.6238 - val_loss: 16738798.0000 - val_mae: 3167.3347\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 741852.7639 - mae: 496.5010 - val_loss: 16775668.0000 - val_mae: 3164.7393\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 707112.7257 - mae: 481.2707 - val_loss: 16135549.0000 - val_mae: 3120.4885\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 846909.4514 - mae: 501.2505 - val_loss: 16634051.0000 - val_mae: 3149.7754\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 690460.4392 - mae: 456.6146 - val_loss: 16481768.0000 - val_mae: 3142.0750\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 770274.4167 - mae: 487.6828 - val_loss: 16414057.0000 - val_mae: 3127.2786\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 736878.8194 - mae: 476.0478 - val_loss: 17038624.0000 - val_mae: 3189.2793\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 678331.5139 - mae: 445.5789 - val_loss: 16586911.0000 - val_mae: 3150.5859\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 874470.4514 - mae: 526.8515 - val_loss: 16306759.0000 - val_mae: 3128.9978\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 800156.2569 - mae: 510.9256 - val_loss: 15633609.0000 - val_mae: 3077.7041\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1296772.7500 - mae: 630.9300 - val_loss: 16379577.0000 - val_mae: 3128.1260\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 575854.8507 - mae: 452.0773 - val_loss: 16597305.0000 - val_mae: 3142.4578\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1110202.1042 - mae: 577.7368 - val_loss: 16215239.0000 - val_mae: 3107.3367\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 791625.0972 - mae: 518.3023 - val_loss: 16896154.0000 - val_mae: 3151.9963\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1042065.9514 - mae: 571.6751 - val_loss: 16456618.0000 - val_mae: 3131.4099\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 837241.7049 - mae: 518.0224 - val_loss: 17000772.0000 - val_mae: 3161.1482\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 694554.2014 - mae: 487.2387 - val_loss: 16826004.0000 - val_mae: 3165.4343\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 834158.5139 - mae: 521.5660 - val_loss: 16431398.0000 - val_mae: 3134.5957\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 662167.6250 - mae: 478.0672 - val_loss: 17550674.0000 - val_mae: 3209.1406\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 670601.0781 - mae: 479.3924 - val_loss: 16598497.0000 - val_mae: 3146.5383\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 674656.6458 - mae: 455.3148 - val_loss: 16796330.0000 - val_mae: 3159.2971\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 575046.5764 - mae: 442.1918 - val_loss: 17916344.0000 - val_mae: 3237.3625\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 864301.3889 - mae: 550.9990 - val_loss: 16257967.0000 - val_mae: 3136.5356\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 632229.7917 - mae: 495.7104 - val_loss: 16293641.0000 - val_mae: 3130.4355\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 958520.6389 - mae: 493.7810 - val_loss: 17049476.0000 - val_mae: 3171.9390\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 682007.1181 - mae: 484.3427 - val_loss: 16877960.0000 - val_mae: 3164.0679\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 806928.1389 - mae: 493.7261 - val_loss: 17264254.0000 - val_mae: 3189.3567\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 627323.3125 - mae: 463.8530 - val_loss: 16756761.0000 - val_mae: 3158.3513\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 717080.9653 - mae: 467.5040 - val_loss: 16532372.0000 - val_mae: 3147.8408\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 795516.3785 - mae: 477.2988 - val_loss: 16643584.0000 - val_mae: 3157.3372\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 564306.1285 - mae: 446.8325 - val_loss: 16581542.0000 - val_mae: 3148.8892\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 790361.4653 - mae: 514.1396 - val_loss: 16780002.0000 - val_mae: 3161.6038\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 760520.4688 - mae: 455.9232 - val_loss: 16750087.0000 - val_mae: 3158.5549\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 685008.1458 - mae: 468.0145 - val_loss: 17832632.0000 - val_mae: 3229.6038\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 789844.6736 - mae: 547.7146 - val_loss: 16574261.0000 - val_mae: 3139.6565\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 869640.7153 - mae: 511.7382 - val_loss: 17533716.0000 - val_mae: 3203.1062\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 696872.3264 - mae: 486.6105 - val_loss: 16335799.0000 - val_mae: 3127.7908\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 582048.8090 - mae: 425.2260 - val_loss: 16649506.0000 - val_mae: 3144.0706\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 858261.1250 - mae: 479.5257 - val_loss: 16724334.0000 - val_mae: 3157.8406\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 945851.2014 - mae: 503.9850 - val_loss: 16783046.0000 - val_mae: 3160.9163\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 942995.2014 - mae: 522.6060 - val_loss: 16024989.0000 - val_mae: 3105.4675\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 609396.1910 - mae: 446.5142 - val_loss: 16856688.0000 - val_mae: 3168.9148\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 806765.0486 - mae: 516.3193 - val_loss: 16822676.0000 - val_mae: 3161.8206\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 586335.7500 - mae: 400.2781 - val_loss: 16560501.0000 - val_mae: 3140.4238\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 583857.1858 - mae: 395.0079 - val_loss: 16828682.0000 - val_mae: 3164.0320\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 973911.5208 - mae: 501.2342 - val_loss: 17221404.0000 - val_mae: 3183.0371\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 842162.2847 - mae: 481.3213 - val_loss: 17035058.0000 - val_mae: 3173.2722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fzuwjOMYuAIU",
        "outputId": "d6ad3b17-c146-4f45-d542-a66dc18a6a40"
      },
      "source": [
        "history_dict = Model_Results3.history\n",
        "mae_values = history_dict['loss']\n",
        "val_mae_values = history_dict['val_loss']\n",
        "epoches = np.arange(1,len(history_dict['mae'])+1)\n",
        "plt.plot(epoches,mae_values,'r',label=\"Training Mae\")\n",
        "plt.plot(epoches,val_mae_values,'g',label=\"Validating Mae\")\n",
        "plt.title('Training and validation Mae')\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Mae\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFaViWzJmvfJ",
        "outputId": "1cbfedbd-674a-497a-ccb9-6785485ef5b7"
      },
      "source": [
        "history_dict = Model_Results3.history\n",
        "val_acc_values = history_dict['val_mae']\n",
        "maxi = np.max(val_acc_values)\n",
        "mini = np.min(val_acc_values)\n",
        "avrg = (maxi+mini)/2\n",
        "print(f\"FOR MODEL1 Average Validation Absolute Error = {avrg}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOR MODEL1 Average Validation Absolute Error = 6734.6856689453125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqyyNAtQm0b6"
      },
      "source": [
        "# **MAE without K fold and with relu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWcYjZKlm9ow",
        "outputId": "adbd6e46-c47c-4d7a-acfa-31ca33227410"
      },
      "source": [
        "Model_Results4 = Train_Me_with(activation_function=\"relu\").fit(\n",
        "      train_data,train_labels,batch_size=20,epochs=500,validation_data=(test_data,test_labels)\n",
        "  )"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 1s 31ms/step - loss: 252162622.2222 - mae: 13469.3167 - val_loss: 146566144.0000 - val_mae: 11351.2012\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 254405998.2222 - mae: 13584.1366 - val_loss: 146559936.0000 - val_mae: 11350.9199\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 241502316.4444 - mae: 13099.2630 - val_loss: 146550432.0000 - val_mae: 11350.5098\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 271994584.8889 - mae: 13925.0264 - val_loss: 146538592.0000 - val_mae: 11349.9980\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 282560464.0000 - mae: 14119.1910 - val_loss: 146522592.0000 - val_mae: 11349.3145\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 317277863.1111 - mae: 15058.6993 - val_loss: 146505920.0000 - val_mae: 11348.6025\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 242725370.6667 - mae: 13389.4128 - val_loss: 146486112.0000 - val_mae: 11347.7627\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 266575960.8889 - mae: 13903.4062 - val_loss: 146463984.0000 - val_mae: 11346.8184\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 292219936.0000 - mae: 14072.1776 - val_loss: 146434928.0000 - val_mae: 11345.6162\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 281788824.8889 - mae: 14409.7426 - val_loss: 146400688.0000 - val_mae: 11344.2090\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 274893896.8889 - mae: 13950.5777 - val_loss: 146363952.0000 - val_mae: 11342.6895\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 296777063.1111 - mae: 14489.0150 - val_loss: 146316016.0000 - val_mae: 11340.7451\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 262360183.1111 - mae: 13728.1759 - val_loss: 146265968.0000 - val_mae: 11338.6885\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 262305232.0000 - mae: 13566.1334 - val_loss: 146207824.0000 - val_mae: 11336.3154\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 325710990.2222 - mae: 15015.4634 - val_loss: 146137616.0000 - val_mae: 11333.4717\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 270189032.8889 - mae: 13875.3633 - val_loss: 146065904.0000 - val_mae: 11330.5107\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 286242112.0000 - mae: 14320.3249 - val_loss: 145979264.0000 - val_mae: 11326.9795\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 270641600.0000 - mae: 14024.0718 - val_loss: 145871984.0000 - val_mae: 11322.6826\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 270878990.2222 - mae: 13846.8446 - val_loss: 145767024.0000 - val_mae: 11318.4189\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 291622867.5556 - mae: 14280.5280 - val_loss: 145644672.0000 - val_mae: 11313.4863\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 267298321.7778 - mae: 13937.2705 - val_loss: 145511872.0000 - val_mae: 11308.0986\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 276187079.1111 - mae: 13876.2344 - val_loss: 145359808.0000 - val_mae: 11301.9824\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 272390248.8889 - mae: 13963.0390 - val_loss: 145190256.0000 - val_mae: 11295.2217\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 305525272.8889 - mae: 14755.1357 - val_loss: 145013312.0000 - val_mae: 11288.0752\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 302552423.1111 - mae: 14544.5456 - val_loss: 144828464.0000 - val_mae: 11280.5488\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 270521909.3333 - mae: 13993.7537 - val_loss: 144616736.0000 - val_mae: 11271.9834\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 263229454.2222 - mae: 13606.6668 - val_loss: 144397488.0000 - val_mae: 11263.1436\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 276250112.0000 - mae: 13874.6547 - val_loss: 144150352.0000 - val_mae: 11253.1689\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 253482680.8889 - mae: 13569.0073 - val_loss: 143877744.0000 - val_mae: 11242.2334\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 281776202.6667 - mae: 14228.6203 - val_loss: 143590400.0000 - val_mae: 11230.6973\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 266061132.4444 - mae: 13868.0193 - val_loss: 143275344.0000 - val_mae: 11218.0801\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 298349440.0000 - mae: 14589.2859 - val_loss: 142959968.0000 - val_mae: 11205.2979\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 245066316.4444 - mae: 13376.7801 - val_loss: 142589616.0000 - val_mae: 11190.4678\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 240055688.8889 - mae: 13097.4052 - val_loss: 142207648.0000 - val_mae: 11175.1484\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 282584344.8889 - mae: 13998.9500 - val_loss: 141801440.0000 - val_mae: 11158.8086\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 281647831.1111 - mae: 13857.2842 - val_loss: 141382256.0000 - val_mae: 11141.8623\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 258081303.1111 - mae: 13430.7588 - val_loss: 140948416.0000 - val_mae: 11124.2383\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 251939594.6667 - mae: 13319.0512 - val_loss: 140420288.0000 - val_mae: 11102.8867\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 277631733.3333 - mae: 14073.9008 - val_loss: 139942256.0000 - val_mae: 11083.4209\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 292613393.7778 - mae: 14351.9459 - val_loss: 139395920.0000 - val_mae: 11061.2812\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 277384547.5556 - mae: 13881.1250 - val_loss: 138873904.0000 - val_mae: 11039.9561\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 260573607.1111 - mae: 13516.5217 - val_loss: 138280896.0000 - val_mae: 11015.7852\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 254224869.3333 - mae: 13528.1742 - val_loss: 137697584.0000 - val_mae: 10991.7490\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 272155550.2222 - mae: 13734.4827 - val_loss: 137044432.0000 - val_mae: 10964.9834\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 249999244.4444 - mae: 13355.7952 - val_loss: 136355040.0000 - val_mae: 10936.6738\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 306130483.5556 - mae: 14441.3939 - val_loss: 135649104.0000 - val_mae: 10907.5254\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 231928104.8889 - mae: 12879.3499 - val_loss: 134755648.0000 - val_mae: 10871.1992\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 265407029.3333 - mae: 13683.4129 - val_loss: 134049944.0000 - val_mae: 10841.6387\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 233565648.0000 - mae: 12846.9281 - val_loss: 133229912.0000 - val_mae: 10807.4395\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 260277130.6667 - mae: 13372.7021 - val_loss: 132337136.0000 - val_mae: 10770.3682\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 287221340.4444 - mae: 14236.9831 - val_loss: 131504856.0000 - val_mae: 10735.4238\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 283459776.0000 - mae: 14091.1452 - val_loss: 130529984.0000 - val_mae: 10694.6953\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 275330968.8889 - mae: 13862.5363 - val_loss: 129652888.0000 - val_mae: 10657.4316\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 265932179.5556 - mae: 13625.2132 - val_loss: 128658232.0000 - val_mae: 10615.2061\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 264494901.3333 - mae: 13435.5913 - val_loss: 127493168.0000 - val_mae: 10566.1152\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 256839230.2222 - mae: 13352.7979 - val_loss: 126446624.0000 - val_mae: 10521.1240\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 244004101.3333 - mae: 13244.2500 - val_loss: 125173840.0000 - val_mae: 10467.1748\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 249722314.6667 - mae: 13246.0509 - val_loss: 124084320.0000 - val_mae: 10419.8838\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 252710359.1111 - mae: 13332.1860 - val_loss: 122817296.0000 - val_mae: 10365.1602\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 242144851.5556 - mae: 12914.4348 - val_loss: 121502136.0000 - val_mae: 10308.3535\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 256232711.1111 - mae: 13342.5026 - val_loss: 120201288.0000 - val_mae: 10251.4209\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 221717829.3333 - mae: 12283.9842 - val_loss: 118960584.0000 - val_mae: 10196.5801\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 254410954.6667 - mae: 13174.6662 - val_loss: 117571272.0000 - val_mae: 10135.2832\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 210226033.7778 - mae: 12200.3107 - val_loss: 116053800.0000 - val_mae: 10068.4512\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 195020733.3333 - mae: 11556.0587 - val_loss: 114607768.0000 - val_mae: 10003.2842\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 226857216.0000 - mae: 12586.5239 - val_loss: 113099048.0000 - val_mae: 9935.3779\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 222047632.0000 - mae: 12385.9809 - val_loss: 111537696.0000 - val_mae: 9864.3213\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 211515326.2222 - mae: 12096.8721 - val_loss: 109918400.0000 - val_mae: 9790.2764\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 202989715.5556 - mae: 11901.7904 - val_loss: 108269408.0000 - val_mae: 9714.1240\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 210981262.2222 - mae: 11996.4085 - val_loss: 106540336.0000 - val_mae: 9633.6836\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 202856759.1111 - mae: 11990.7692 - val_loss: 104696000.0000 - val_mae: 9547.2080\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 231765532.4444 - mae: 12595.8398 - val_loss: 103046304.0000 - val_mae: 9468.3613\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 167433818.6667 - mae: 10807.5487 - val_loss: 101122896.0000 - val_mae: 9376.4248\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 219541992.8889 - mae: 12264.7208 - val_loss: 99351448.0000 - val_mae: 9290.1689\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 200903745.7778 - mae: 11545.5128 - val_loss: 97411976.0000 - val_mae: 9195.0205\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 192476627.5556 - mae: 11459.4059 - val_loss: 95415808.0000 - val_mae: 9096.6426\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 195053463.1111 - mae: 11519.7330 - val_loss: 93351872.0000 - val_mae: 8993.8145\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 193412016.0000 - mae: 11500.6942 - val_loss: 91379984.0000 - val_mae: 8893.8730\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 158022248.8889 - mae: 10431.1309 - val_loss: 89119928.0000 - val_mae: 8779.2910\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 167913260.4444 - mae: 10616.5768 - val_loss: 87102136.0000 - val_mae: 8674.4561\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 188040657.7778 - mae: 11006.1748 - val_loss: 84744216.0000 - val_mae: 8550.5371\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 176845950.2222 - mae: 10848.1424 - val_loss: 82736136.0000 - val_mae: 8443.3896\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 158998295.1111 - mae: 10332.4512 - val_loss: 80594944.0000 - val_mae: 8327.7168\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 142775696.8889 - mae: 9725.5428 - val_loss: 78284272.0000 - val_mae: 8201.1885\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 169870760.8889 - mae: 10529.3070 - val_loss: 75729056.0000 - val_mae: 8060.2183\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 151586312.8889 - mae: 9873.7651 - val_loss: 73372280.0000 - val_mae: 7926.7666\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 179077434.6667 - mae: 10781.7021 - val_loss: 71207160.0000 - val_mae: 7801.1479\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 131588929.7778 - mae: 9367.5512 - val_loss: 68707960.0000 - val_mae: 7655.3462\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 138489906.6667 - mae: 9331.2734 - val_loss: 66329244.0000 - val_mae: 7512.6265\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 146758791.1111 - mae: 9724.1897 - val_loss: 63813120.0000 - val_mae: 7358.7783\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 151772039.1111 - mae: 9685.4731 - val_loss: 61806632.0000 - val_mae: 7231.6606\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 141135885.3333 - mae: 9402.8702 - val_loss: 59567448.0000 - val_mae: 7087.5684\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 120117384.0000 - mae: 8816.7583 - val_loss: 57262940.0000 - val_mae: 6936.1685\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 110458666.6667 - mae: 8326.5797 - val_loss: 54720084.0000 - val_mae: 6765.9546\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 119634288.0000 - mae: 8467.3090 - val_loss: 52131260.0000 - val_mae: 6589.3491\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 126286888.0000 - mae: 8660.5054 - val_loss: 49621596.0000 - val_mae: 6412.6948\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 107326306.6667 - mae: 7977.2373 - val_loss: 47336776.0000 - val_mae: 6244.7256\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 91487369.7778 - mae: 7493.8701 - val_loss: 44902944.0000 - val_mae: 6062.0981\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 84458795.5556 - mae: 7242.2976 - val_loss: 42759696.0000 - val_mae: 5893.6055\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 86694674.2222 - mae: 7239.1089 - val_loss: 40617888.0000 - val_mae: 5721.1030\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 102935159.1111 - mae: 7673.8848 - val_loss: 38225596.0000 - val_mae: 5522.2568\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 90789495.1111 - mae: 7022.4235 - val_loss: 35826644.0000 - val_mae: 5316.2100\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 103945780.4444 - mae: 7476.8614 - val_loss: 33922536.0000 - val_mae: 5150.7446\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 78039610.6667 - mae: 6646.6255 - val_loss: 31605586.0000 - val_mae: 4944.9272\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 86088096.8889 - mae: 6623.1399 - val_loss: 29755846.0000 - val_mae: 4770.2334\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 74813913.7778 - mae: 6293.3988 - val_loss: 27632144.0000 - val_mae: 4564.2148\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 74015456.8889 - mae: 6182.1181 - val_loss: 25558362.0000 - val_mae: 4359.1816\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 78543340.4444 - mae: 6243.6035 - val_loss: 23867912.0000 - val_mae: 4190.3110\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 74139457.7778 - mae: 5850.4393 - val_loss: 21857238.0000 - val_mae: 3980.3035\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 58013601.3333 - mae: 5180.9733 - val_loss: 20074000.0000 - val_mae: 3779.8408\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 59521286.6667 - mae: 5153.7294 - val_loss: 18610320.0000 - val_mae: 3604.1365\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 51019826.2222 - mae: 4723.7962 - val_loss: 16957428.0000 - val_mae: 3414.8835\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 49354597.3333 - mae: 4745.5571 - val_loss: 15533958.0000 - val_mae: 3241.5759\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 50262528.8889 - mae: 4697.1646 - val_loss: 14205915.0000 - val_mae: 3073.9167\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 44359931.1111 - mae: 4338.5557 - val_loss: 12918666.0000 - val_mae: 2915.1909\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 36748764.8889 - mae: 3924.5770 - val_loss: 11869320.0000 - val_mae: 2784.8047\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 35829076.0000 - mae: 3903.7415 - val_loss: 11013044.0000 - val_mae: 2675.2537\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 45663037.3333 - mae: 4338.7293 - val_loss: 10155883.0000 - val_mae: 2556.4724\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 36516693.1111 - mae: 3969.5352 - val_loss: 9592151.0000 - val_mae: 2474.2893\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 28721391.1111 - mae: 3422.1382 - val_loss: 8991095.0000 - val_mae: 2378.6223\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 29366432.4444 - mae: 3591.3748 - val_loss: 8725912.0000 - val_mae: 2326.0942\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 30927270.6667 - mae: 3633.8234 - val_loss: 8499493.0000 - val_mae: 2278.8877\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 29729782.8889 - mae: 3493.4911 - val_loss: 8319252.5000 - val_mae: 2228.8831\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 26387557.1111 - mae: 3475.5561 - val_loss: 8241725.5000 - val_mae: 2194.8806\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 21455994.2778 - mae: 3159.9791 - val_loss: 8347526.0000 - val_mae: 2186.2073\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 27232758.8889 - mae: 3581.0410 - val_loss: 8426571.0000 - val_mae: 2199.4988\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 27211976.8889 - mae: 3483.4850 - val_loss: 8586407.0000 - val_mae: 2223.9531\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 25034022.2222 - mae: 3555.7903 - val_loss: 8682653.0000 - val_mae: 2237.8350\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 20525321.8889 - mae: 3219.2365 - val_loss: 9023753.0000 - val_mae: 2270.5520\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 22920197.7778 - mae: 3401.4228 - val_loss: 9169039.0000 - val_mae: 2284.8708\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 27717579.5556 - mae: 3811.2816 - val_loss: 9177496.0000 - val_mae: 2287.1670\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19266029.3333 - mae: 3191.4202 - val_loss: 9240698.0000 - val_mae: 2295.4302\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 22551422.0000 - mae: 3350.4564 - val_loss: 9632600.0000 - val_mae: 2339.5261\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 20135675.5556 - mae: 3286.0234 - val_loss: 9585438.0000 - val_mae: 2337.9895\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19674150.7778 - mae: 3317.7542 - val_loss: 10023524.0000 - val_mae: 2398.9004\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 20912679.5556 - mae: 3337.1588 - val_loss: 10061960.0000 - val_mae: 2406.9912\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16609014.2778 - mae: 3014.9155 - val_loss: 10372414.0000 - val_mae: 2453.9058\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18827997.0000 - mae: 3335.6038 - val_loss: 10236736.0000 - val_mae: 2437.2566\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17803608.6667 - mae: 3168.8766 - val_loss: 10342209.0000 - val_mae: 2452.5771\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16154592.6667 - mae: 2996.2627 - val_loss: 10600621.0000 - val_mae: 2491.8767\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19097167.5556 - mae: 3330.0647 - val_loss: 10372316.0000 - val_mae: 2457.6338\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19762024.2222 - mae: 3401.5573 - val_loss: 10550838.0000 - val_mae: 2484.4685\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19708077.7778 - mae: 3453.1797 - val_loss: 10503546.0000 - val_mae: 2477.8040\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17902602.0000 - mae: 3118.7859 - val_loss: 10611669.0000 - val_mae: 2493.5894\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18181489.7778 - mae: 3177.7337 - val_loss: 10561757.0000 - val_mae: 2487.4495\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 21785544.4444 - mae: 3526.9632 - val_loss: 10497681.0000 - val_mae: 2478.5225\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16968204.8889 - mae: 3078.0189 - val_loss: 10307652.0000 - val_mae: 2455.3813\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17707667.7778 - mae: 3247.0519 - val_loss: 10406775.0000 - val_mae: 2468.1287\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17039925.3333 - mae: 3118.7847 - val_loss: 10420489.0000 - val_mae: 2472.2249\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16574908.5556 - mae: 3092.6927 - val_loss: 10672201.0000 - val_mae: 2508.0132\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19900736.2222 - mae: 3479.4416 - val_loss: 10649725.0000 - val_mae: 2504.4517\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 15611727.2222 - mae: 2928.5666 - val_loss: 10638550.0000 - val_mae: 2505.6511\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 21938295.5556 - mae: 3427.9436 - val_loss: 10534240.0000 - val_mae: 2489.3716\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15698406.4444 - mae: 2877.4376 - val_loss: 10503732.0000 - val_mae: 2485.4954\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15933048.1111 - mae: 3063.7324 - val_loss: 10332298.0000 - val_mae: 2464.8569\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16372943.6667 - mae: 3057.7349 - val_loss: 10216682.0000 - val_mae: 2454.1345\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15361005.4444 - mae: 2989.3672 - val_loss: 10271843.0000 - val_mae: 2459.9197\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19190793.6667 - mae: 3209.2322 - val_loss: 10124238.0000 - val_mae: 2442.5059\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15140414.5556 - mae: 2917.3321 - val_loss: 10127890.0000 - val_mae: 2443.9155\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16490785.0000 - mae: 3178.4134 - val_loss: 10193233.0000 - val_mae: 2451.0520\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14715015.0000 - mae: 2893.1321 - val_loss: 10193595.0000 - val_mae: 2449.1907\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15829565.8889 - mae: 2977.2167 - val_loss: 10189507.0000 - val_mae: 2448.3208\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14377541.5556 - mae: 2777.8755 - val_loss: 10072484.0000 - val_mae: 2434.8252\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18891040.0000 - mae: 3208.3433 - val_loss: 10092190.0000 - val_mae: 2437.3965\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15046477.3333 - mae: 2968.4856 - val_loss: 10397919.0000 - val_mae: 2477.5334\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18725407.6667 - mae: 3090.6830 - val_loss: 10241570.0000 - val_mae: 2456.2795\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 17699327.7778 - mae: 3102.5330 - val_loss: 10208270.0000 - val_mae: 2452.7510\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14129439.8889 - mae: 2917.7489 - val_loss: 10105618.0000 - val_mae: 2441.1292\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15609496.4444 - mae: 2942.4894 - val_loss: 10516071.0000 - val_mae: 2499.0735\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14653167.0000 - mae: 2896.9041 - val_loss: 10454685.0000 - val_mae: 2490.5850\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13491180.1111 - mae: 2775.4792 - val_loss: 10600284.0000 - val_mae: 2510.7034\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14727721.2222 - mae: 2759.9062 - val_loss: 10403327.0000 - val_mae: 2479.2039\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12861404.3333 - mae: 2637.0946 - val_loss: 10678242.0000 - val_mae: 2517.6372\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16841552.1111 - mae: 3032.7423 - val_loss: 10771072.0000 - val_mae: 2530.5950\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13450941.7778 - mae: 2821.5643 - val_loss: 10596306.0000 - val_mae: 2506.2161\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13736911.2778 - mae: 2698.0238 - val_loss: 10632711.0000 - val_mae: 2511.5417\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12933552.3333 - mae: 2721.0940 - val_loss: 10376222.0000 - val_mae: 2478.1357\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13067590.0000 - mae: 2698.6962 - val_loss: 10423603.0000 - val_mae: 2482.9556\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16465378.7778 - mae: 3025.9272 - val_loss: 10492614.0000 - val_mae: 2490.5779\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14817943.2222 - mae: 2907.6581 - val_loss: 10553480.0000 - val_mae: 2497.7236\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13926622.7778 - mae: 2832.2710 - val_loss: 10543590.0000 - val_mae: 2496.3481\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15185223.7778 - mae: 2885.2532 - val_loss: 10576740.0000 - val_mae: 2500.7791\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15973500.4444 - mae: 2929.5790 - val_loss: 10559308.0000 - val_mae: 2497.4375\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12166250.5000 - mae: 2645.6619 - val_loss: 10850632.0000 - val_mae: 2533.4221\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11468904.3333 - mae: 2555.3244 - val_loss: 10791598.0000 - val_mae: 2526.7676\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13417982.7778 - mae: 2717.6850 - val_loss: 10758600.0000 - val_mae: 2523.1543\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12946873.7778 - mae: 2560.9770 - val_loss: 10579071.0000 - val_mae: 2500.7219\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12727442.1111 - mae: 2541.6295 - val_loss: 10450222.0000 - val_mae: 2485.7437\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12825914.5556 - mae: 2611.9136 - val_loss: 10250263.0000 - val_mae: 2463.4272\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11976438.2222 - mae: 2578.1684 - val_loss: 10463229.0000 - val_mae: 2487.9131\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12815601.0000 - mae: 2646.9936 - val_loss: 10294189.0000 - val_mae: 2469.6208\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11988211.1111 - mae: 2536.0145 - val_loss: 10231658.0000 - val_mae: 2462.2510\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10385064.3889 - mae: 2382.1616 - val_loss: 10125302.0000 - val_mae: 2451.5969\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12540267.2222 - mae: 2579.3286 - val_loss: 10182651.0000 - val_mae: 2458.5369\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11643476.8889 - mae: 2534.3956 - val_loss: 10414826.0000 - val_mae: 2484.8594\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11066318.4444 - mae: 2462.9497 - val_loss: 10252917.0000 - val_mae: 2467.3110\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15154467.3333 - mae: 2817.6840 - val_loss: 10092071.0000 - val_mae: 2448.5881\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12101644.1111 - mae: 2595.5517 - val_loss: 10365341.0000 - val_mae: 2476.8306\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10442857.3889 - mae: 2420.9221 - val_loss: 10398069.0000 - val_mae: 2478.5156\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12221843.1111 - mae: 2502.8509 - val_loss: 10562705.0000 - val_mae: 2499.9917\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9820091.0278 - mae: 2193.1053 - val_loss: 10370617.0000 - val_mae: 2479.6284\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11408410.5556 - mae: 2462.7111 - val_loss: 10201491.0000 - val_mae: 2462.2625\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10939671.3333 - mae: 2410.0401 - val_loss: 10656866.0000 - val_mae: 2511.6450\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12727921.3333 - mae: 2471.8298 - val_loss: 10654646.0000 - val_mae: 2511.4470\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12499886.1667 - mae: 2595.4617 - val_loss: 10721871.0000 - val_mae: 2517.3271\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9779977.7778 - mae: 2358.2410 - val_loss: 11143944.0000 - val_mae: 2561.8655\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11573827.7778 - mae: 2508.9022 - val_loss: 10954109.0000 - val_mae: 2546.9929\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11481788.8889 - mae: 2417.0611 - val_loss: 11176007.0000 - val_mae: 2570.8079\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14048282.3333 - mae: 2658.4907 - val_loss: 10948409.0000 - val_mae: 2551.7507\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10980348.8889 - mae: 2505.2448 - val_loss: 10859121.0000 - val_mae: 2542.5542\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13500654.3333 - mae: 2643.9637 - val_loss: 11004557.0000 - val_mae: 2554.0769\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10504249.7778 - mae: 2412.3593 - val_loss: 10976475.0000 - val_mae: 2550.3997\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12863357.1111 - mae: 2580.3319 - val_loss: 10819096.0000 - val_mae: 2534.7292\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8999230.3889 - mae: 2219.5249 - val_loss: 10621357.0000 - val_mae: 2515.2959\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10744635.7222 - mae: 2387.1651 - val_loss: 10650046.0000 - val_mae: 2515.8201\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9939669.5556 - mae: 2295.2198 - val_loss: 10899342.0000 - val_mae: 2540.9263\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9912175.1111 - mae: 2253.1140 - val_loss: 10671624.0000 - val_mae: 2515.1960\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9682435.1667 - mae: 2286.0075 - val_loss: 10602588.0000 - val_mae: 2512.1436\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9528685.6667 - mae: 2237.6920 - val_loss: 10717759.0000 - val_mae: 2526.7202\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9612184.7778 - mae: 2234.1680 - val_loss: 10846689.0000 - val_mae: 2540.8508\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9952423.6111 - mae: 2268.5536 - val_loss: 10691628.0000 - val_mae: 2525.3035\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8001846.6111 - mae: 2020.3699 - val_loss: 10952159.0000 - val_mae: 2548.9202\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9618577.5000 - mae: 2142.3350 - val_loss: 10727394.0000 - val_mae: 2524.7009\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8775575.0000 - mae: 2153.0463 - val_loss: 10562368.0000 - val_mae: 2506.3796\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11616458.4444 - mae: 2448.1930 - val_loss: 10896266.0000 - val_mae: 2542.0164\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10457933.5556 - mae: 2332.9926 - val_loss: 10583730.0000 - val_mae: 2511.1331\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8342838.2778 - mae: 2054.3811 - val_loss: 11048371.0000 - val_mae: 2559.9294\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10647757.1111 - mae: 2310.3260 - val_loss: 11032919.0000 - val_mae: 2554.8999\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11675677.2222 - mae: 2353.2704 - val_loss: 10917300.0000 - val_mae: 2544.4368\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9710716.3333 - mae: 2194.5230 - val_loss: 11049654.0000 - val_mae: 2556.0891\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8992199.6111 - mae: 2135.4408 - val_loss: 11354014.0000 - val_mae: 2587.1279\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8680124.1111 - mae: 2208.4118 - val_loss: 11653681.0000 - val_mae: 2618.0310\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7755180.3889 - mae: 2043.7479 - val_loss: 11275797.0000 - val_mae: 2582.7632\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7449567.2778 - mae: 1917.6348 - val_loss: 11396581.0000 - val_mae: 2594.9387\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8677293.2778 - mae: 2177.4003 - val_loss: 11237027.0000 - val_mae: 2577.7207\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9317476.6667 - mae: 2151.7593 - val_loss: 11282024.0000 - val_mae: 2579.5752\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8166806.5556 - mae: 2017.1881 - val_loss: 11283345.0000 - val_mae: 2579.0730\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7936200.7222 - mae: 1993.8024 - val_loss: 11523010.0000 - val_mae: 2601.8315\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7352966.2222 - mae: 1867.0024 - val_loss: 11540726.0000 - val_mae: 2604.7632\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7269049.7778 - mae: 1957.4708 - val_loss: 11386060.0000 - val_mae: 2590.5378\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7858880.2222 - mae: 1999.9098 - val_loss: 11290146.0000 - val_mae: 2580.1206\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8193960.3333 - mae: 1995.2015 - val_loss: 10980182.0000 - val_mae: 2550.9114\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6995410.8611 - mae: 1866.5086 - val_loss: 10991930.0000 - val_mae: 2552.3223\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8072410.1111 - mae: 2009.8288 - val_loss: 10767417.0000 - val_mae: 2529.0073\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8351375.4444 - mae: 2065.3286 - val_loss: 11235063.0000 - val_mae: 2574.8574\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8343540.5556 - mae: 1963.9456 - val_loss: 11319721.0000 - val_mae: 2579.6265\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8026532.0000 - mae: 2012.8436 - val_loss: 11430650.0000 - val_mae: 2590.8716\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7527305.1111 - mae: 1873.9559 - val_loss: 11145829.0000 - val_mae: 2562.8188\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7100610.3333 - mae: 1879.8767 - val_loss: 11399912.0000 - val_mae: 2587.7336\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6255448.0833 - mae: 1710.5141 - val_loss: 11236867.0000 - val_mae: 2574.2576\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7342597.3889 - mae: 1900.7647 - val_loss: 11549129.0000 - val_mae: 2603.0564\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6519300.4444 - mae: 1875.2998 - val_loss: 11734780.0000 - val_mae: 2620.4983\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7058467.8889 - mae: 1910.2904 - val_loss: 11419671.0000 - val_mae: 2590.6008\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6354267.1667 - mae: 1680.7190 - val_loss: 11422302.0000 - val_mae: 2589.4863\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7263511.1111 - mae: 1866.1103 - val_loss: 11476305.0000 - val_mae: 2592.7207\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9220369.5000 - mae: 2013.7718 - val_loss: 11322400.0000 - val_mae: 2575.4548\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7000762.1667 - mae: 1738.3710 - val_loss: 10975527.0000 - val_mae: 2541.5723\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6498854.8056 - mae: 1682.2777 - val_loss: 10808356.0000 - val_mae: 2524.9817\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7390123.8889 - mae: 1816.9089 - val_loss: 10704531.0000 - val_mae: 2513.5264\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6484661.9167 - mae: 1786.6440 - val_loss: 10796230.0000 - val_mae: 2522.2610\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6854873.2778 - mae: 1882.7193 - val_loss: 10854549.0000 - val_mae: 2528.2261\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6405804.9444 - mae: 1692.4465 - val_loss: 11157949.0000 - val_mae: 2558.8638\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5685350.2500 - mae: 1651.0865 - val_loss: 11593845.0000 - val_mae: 2601.3420\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6240960.6111 - mae: 1795.9471 - val_loss: 11443407.0000 - val_mae: 2588.9497\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6238463.8889 - mae: 1711.1446 - val_loss: 11828492.0000 - val_mae: 2626.7051\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7197416.6667 - mae: 1799.9027 - val_loss: 11539774.0000 - val_mae: 2601.8469\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5779657.1111 - mae: 1636.0410 - val_loss: 11497250.0000 - val_mae: 2597.6670\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6731533.8333 - mae: 1741.7087 - val_loss: 11261421.0000 - val_mae: 2572.8059\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4848953.1667 - mae: 1538.7525 - val_loss: 11621157.0000 - val_mae: 2607.8438\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4982976.2500 - mae: 1520.1717 - val_loss: 11533001.0000 - val_mae: 2600.2644\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5473904.4722 - mae: 1639.6788 - val_loss: 11319679.0000 - val_mae: 2581.3967\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6770396.3333 - mae: 1747.5747 - val_loss: 11423693.0000 - val_mae: 2590.1492\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5654422.0000 - mae: 1586.4778 - val_loss: 11291960.0000 - val_mae: 2578.6833\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5963738.5000 - mae: 1756.7500 - val_loss: 11074506.0000 - val_mae: 2558.8560\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5744697.9444 - mae: 1732.0046 - val_loss: 11605702.0000 - val_mae: 2605.4187\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5840895.3889 - mae: 1644.8315 - val_loss: 11415961.0000 - val_mae: 2592.4419\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5599912.3056 - mae: 1658.8823 - val_loss: 11615030.0000 - val_mae: 2610.1189\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5281849.1667 - mae: 1632.4551 - val_loss: 11901754.0000 - val_mae: 2634.1787\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5986932.4167 - mae: 1684.7038 - val_loss: 11577937.0000 - val_mae: 2610.5972\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4986736.6667 - mae: 1572.1194 - val_loss: 11908681.0000 - val_mae: 2638.0386\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6847126.8889 - mae: 1766.9965 - val_loss: 11893336.0000 - val_mae: 2635.5735\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6966823.0000 - mae: 1735.5761 - val_loss: 12082185.0000 - val_mae: 2651.7202\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6348624.9444 - mae: 1784.6954 - val_loss: 11818402.0000 - val_mae: 2629.0994\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5870558.9444 - mae: 1681.8511 - val_loss: 11754353.0000 - val_mae: 2623.9189\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6693845.6111 - mae: 1726.3318 - val_loss: 11620765.0000 - val_mae: 2614.0503\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4659964.7778 - mae: 1467.7666 - val_loss: 11796724.0000 - val_mae: 2629.3142\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6853580.8333 - mae: 1738.4331 - val_loss: 11640930.0000 - val_mae: 2617.5723\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6938632.0000 - mae: 1789.2507 - val_loss: 11469234.0000 - val_mae: 2601.8645\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5808986.5278 - mae: 1601.6904 - val_loss: 11314174.0000 - val_mae: 2585.1069\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5472732.2778 - mae: 1556.5589 - val_loss: 11297895.0000 - val_mae: 2583.5906\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5137390.4444 - mae: 1561.0503 - val_loss: 11237253.0000 - val_mae: 2578.5342\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5701397.8333 - mae: 1548.7059 - val_loss: 11194921.0000 - val_mae: 2574.0957\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5306536.8889 - mae: 1541.8722 - val_loss: 11491528.0000 - val_mae: 2600.3831\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4688839.8889 - mae: 1471.5557 - val_loss: 11612977.0000 - val_mae: 2611.1304\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4416343.8333 - mae: 1420.3617 - val_loss: 11598870.0000 - val_mae: 2610.5364\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4380095.3056 - mae: 1502.4117 - val_loss: 11443323.0000 - val_mae: 2597.1238\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4634767.3194 - mae: 1463.8894 - val_loss: 11634871.0000 - val_mae: 2611.9897\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5092700.0000 - mae: 1535.4882 - val_loss: 11783663.0000 - val_mae: 2624.8113\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5549075.7222 - mae: 1657.5484 - val_loss: 11781819.0000 - val_mae: 2624.0693\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5956091.0556 - mae: 1649.2689 - val_loss: 11693800.0000 - val_mae: 2616.3647\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5024893.5556 - mae: 1488.7778 - val_loss: 11565778.0000 - val_mae: 2606.5212\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4041985.7361 - mae: 1375.9446 - val_loss: 11824284.0000 - val_mae: 2628.9128\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4201845.6250 - mae: 1395.0844 - val_loss: 11844147.0000 - val_mae: 2631.5774\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4408240.9444 - mae: 1462.5780 - val_loss: 11594731.0000 - val_mae: 2609.5657\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5958674.6667 - mae: 1628.9415 - val_loss: 11597494.0000 - val_mae: 2610.3120\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5040934.8611 - mae: 1487.1835 - val_loss: 11489787.0000 - val_mae: 2601.8977\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4088649.5000 - mae: 1369.8620 - val_loss: 11556359.0000 - val_mae: 2607.8318\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4026502.7778 - mae: 1373.6641 - val_loss: 11724949.0000 - val_mae: 2621.9238\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4135676.0556 - mae: 1419.3067 - val_loss: 11923801.0000 - val_mae: 2639.1350\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5446894.6111 - mae: 1483.6080 - val_loss: 11909754.0000 - val_mae: 2636.0330\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5336418.5000 - mae: 1473.6750 - val_loss: 12052454.0000 - val_mae: 2648.5837\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5118648.0000 - mae: 1547.4340 - val_loss: 11777564.0000 - val_mae: 2623.9331\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5002330.1667 - mae: 1520.7161 - val_loss: 12060510.0000 - val_mae: 2649.3015\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5797561.6667 - mae: 1567.8182 - val_loss: 11896418.0000 - val_mae: 2635.7917\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4753700.2500 - mae: 1420.0683 - val_loss: 12228639.0000 - val_mae: 2666.9780\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5378127.5556 - mae: 1546.1503 - val_loss: 12168154.0000 - val_mae: 2662.1160\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3448446.8958 - mae: 1224.9101 - val_loss: 12014514.0000 - val_mae: 2647.8994\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5554552.7222 - mae: 1515.2217 - val_loss: 11653385.0000 - val_mae: 2614.5642\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4662829.6389 - mae: 1500.1803 - val_loss: 11657798.0000 - val_mae: 2616.5715\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3893257.0000 - mae: 1325.5895 - val_loss: 11520809.0000 - val_mae: 2604.7117\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5026751.8889 - mae: 1491.0383 - val_loss: 11741058.0000 - val_mae: 2621.2646\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3720677.1944 - mae: 1323.7959 - val_loss: 11436149.0000 - val_mae: 2594.2104\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4978106.8611 - mae: 1523.8817 - val_loss: 11860209.0000 - val_mae: 2632.5327\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3703870.5556 - mae: 1327.4463 - val_loss: 12020851.0000 - val_mae: 2647.9985\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3723550.4444 - mae: 1296.3512 - val_loss: 11843838.0000 - val_mae: 2634.0339\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4534459.1667 - mae: 1479.0597 - val_loss: 11881238.0000 - val_mae: 2636.0779\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5355559.0556 - mae: 1537.2795 - val_loss: 11578645.0000 - val_mae: 2609.7261\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4547460.3611 - mae: 1456.6805 - val_loss: 11843762.0000 - val_mae: 2631.7449\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4164320.4167 - mae: 1379.7025 - val_loss: 11830569.0000 - val_mae: 2632.5103\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4088278.5278 - mae: 1410.3487 - val_loss: 11836707.0000 - val_mae: 2634.8154\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4350353.3333 - mae: 1388.6953 - val_loss: 11647844.0000 - val_mae: 2617.0747\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4005594.6944 - mae: 1434.1944 - val_loss: 11888210.0000 - val_mae: 2638.2666\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4462404.7500 - mae: 1362.6957 - val_loss: 11900778.0000 - val_mae: 2640.8835\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4444577.3333 - mae: 1434.9221 - val_loss: 12267505.0000 - val_mae: 2671.7236\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3698391.1389 - mae: 1263.7027 - val_loss: 12128104.0000 - val_mae: 2660.3882\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3528103.0000 - mae: 1282.4439 - val_loss: 12124597.0000 - val_mae: 2662.0000\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4837071.1389 - mae: 1406.4169 - val_loss: 11767001.0000 - val_mae: 2632.3203\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3455498.2500 - mae: 1333.2327 - val_loss: 12064025.0000 - val_mae: 2656.3940\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4353742.0000 - mae: 1318.9447 - val_loss: 11879055.0000 - val_mae: 2640.9028\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4790804.4722 - mae: 1462.3262 - val_loss: 11828699.0000 - val_mae: 2637.1765\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3867625.8611 - mae: 1292.6766 - val_loss: 11861497.0000 - val_mae: 2639.3628\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4319134.1944 - mae: 1354.1062 - val_loss: 12273233.0000 - val_mae: 2675.8848\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3691450.3889 - mae: 1318.1975 - val_loss: 12612234.0000 - val_mae: 2704.6311\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3976598.0000 - mae: 1370.0118 - val_loss: 12552727.0000 - val_mae: 2698.7634\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4501690.2222 - mae: 1409.2574 - val_loss: 12260958.0000 - val_mae: 2676.5686\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3010772.4722 - mae: 1139.8210 - val_loss: 12076885.0000 - val_mae: 2657.3745\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4989131.5556 - mae: 1479.2613 - val_loss: 11899750.0000 - val_mae: 2642.3127\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4323851.8056 - mae: 1372.5632 - val_loss: 11982888.0000 - val_mae: 2646.7969\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3594492.1667 - mae: 1289.7354 - val_loss: 12009032.0000 - val_mae: 2651.1736\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3818559.7361 - mae: 1290.1812 - val_loss: 11918367.0000 - val_mae: 2644.0278\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4050898.0833 - mae: 1336.6820 - val_loss: 11577797.0000 - val_mae: 2614.0034\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3614527.6667 - mae: 1243.0135 - val_loss: 11510603.0000 - val_mae: 2609.1995\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3751836.7778 - mae: 1280.5435 - val_loss: 11583490.0000 - val_mae: 2615.2615\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3210339.3889 - mae: 1239.2364 - val_loss: 11900675.0000 - val_mae: 2642.7444\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3919344.6389 - mae: 1238.3037 - val_loss: 11744567.0000 - val_mae: 2630.6199\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2806603.7361 - mae: 1167.2742 - val_loss: 11955014.0000 - val_mae: 2648.2373\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3923561.7778 - mae: 1272.6769 - val_loss: 12233658.0000 - val_mae: 2673.9309\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3263857.3889 - mae: 1214.7969 - val_loss: 12190449.0000 - val_mae: 2668.3059\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4171993.0278 - mae: 1357.6593 - val_loss: 12157130.0000 - val_mae: 2665.7439\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3570067.8333 - mae: 1275.4501 - val_loss: 11904410.0000 - val_mae: 2645.1472\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3722009.8333 - mae: 1245.7754 - val_loss: 11998594.0000 - val_mae: 2655.6279\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3522457.2778 - mae: 1236.3247 - val_loss: 11853671.0000 - val_mae: 2644.1753\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3303103.6111 - mae: 1225.2261 - val_loss: 11737439.0000 - val_mae: 2633.3933\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3087441.9861 - mae: 1189.8914 - val_loss: 11911818.0000 - val_mae: 2646.8901\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3095164.8472 - mae: 1165.1710 - val_loss: 11998611.0000 - val_mae: 2653.6455\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2644679.4444 - mae: 1095.3959 - val_loss: 11776691.0000 - val_mae: 2633.6873\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3536769.0833 - mae: 1238.7889 - val_loss: 11902489.0000 - val_mae: 2644.0176\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3541343.5000 - mae: 1283.6905 - val_loss: 12098020.0000 - val_mae: 2660.6848\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3409382.9722 - mae: 1276.9486 - val_loss: 12169693.0000 - val_mae: 2666.3875\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2915424.6944 - mae: 1180.7310 - val_loss: 12195022.0000 - val_mae: 2670.9878\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3199748.5417 - mae: 1212.1381 - val_loss: 12113118.0000 - val_mae: 2662.1038\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3385599.0556 - mae: 1217.4663 - val_loss: 12069355.0000 - val_mae: 2658.4243\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2815710.6250 - mae: 1158.5927 - val_loss: 12296491.0000 - val_mae: 2676.7705\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2837022.6528 - mae: 1118.3633 - val_loss: 12192064.0000 - val_mae: 2668.3657\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3197551.5833 - mae: 1199.2933 - val_loss: 12141640.0000 - val_mae: 2666.5850\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4213489.1667 - mae: 1321.8663 - val_loss: 12300269.0000 - val_mae: 2678.0610\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3191436.9167 - mae: 1145.4756 - val_loss: 12336269.0000 - val_mae: 2680.4890\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3283798.1944 - mae: 1205.4487 - val_loss: 12398634.0000 - val_mae: 2683.2529\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3503426.0833 - mae: 1225.6726 - val_loss: 12165395.0000 - val_mae: 2667.0168\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3281135.1389 - mae: 1196.3700 - val_loss: 12231102.0000 - val_mae: 2672.0017\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3527179.0278 - mae: 1237.5447 - val_loss: 12604357.0000 - val_mae: 2702.7200\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2582712.9444 - mae: 1095.4470 - val_loss: 12463419.0000 - val_mae: 2691.8032\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2853586.4444 - mae: 1130.5450 - val_loss: 12622274.0000 - val_mae: 2705.2322\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3646477.5000 - mae: 1201.0470 - val_loss: 12576847.0000 - val_mae: 2702.7449\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3177186.3333 - mae: 1142.9452 - val_loss: 12317595.0000 - val_mae: 2685.4609\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2597061.0556 - mae: 1113.9230 - val_loss: 12307158.0000 - val_mae: 2684.4800\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2970831.1667 - mae: 1136.2654 - val_loss: 12130302.0000 - val_mae: 2665.5732\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3761255.4722 - mae: 1232.4550 - val_loss: 11956125.0000 - val_mae: 2652.5120\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2663984.9722 - mae: 1161.5809 - val_loss: 12182422.0000 - val_mae: 2671.7856\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3098412.9444 - mae: 1141.5833 - val_loss: 12233412.0000 - val_mae: 2671.4133\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3525945.9444 - mae: 1174.1505 - val_loss: 12402385.0000 - val_mae: 2680.0437\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2595185.8056 - mae: 1093.7951 - val_loss: 12372918.0000 - val_mae: 2681.0000\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2741113.5139 - mae: 1072.7776 - val_loss: 12074494.0000 - val_mae: 2658.2488\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2664322.3194 - mae: 1097.0459 - val_loss: 11938764.0000 - val_mae: 2646.4019\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2997225.8333 - mae: 1122.3823 - val_loss: 12264344.0000 - val_mae: 2668.6804\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2661609.5000 - mae: 1122.4987 - val_loss: 12287996.0000 - val_mae: 2671.0784\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2906735.1111 - mae: 1118.8701 - val_loss: 12358215.0000 - val_mae: 2672.3584\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3203392.7222 - mae: 1135.7502 - val_loss: 12620684.0000 - val_mae: 2693.2671\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2678856.3333 - mae: 1038.1208 - val_loss: 12355935.0000 - val_mae: 2678.4004\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2159393.1806 - mae: 984.1363 - val_loss: 12013538.0000 - val_mae: 2651.4199\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3353106.9444 - mae: 1222.3642 - val_loss: 12606147.0000 - val_mae: 2695.6736\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3612340.6111 - mae: 1176.4829 - val_loss: 12689255.0000 - val_mae: 2700.9858\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3057653.8611 - mae: 1132.6233 - val_loss: 12550414.0000 - val_mae: 2694.1511\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2712304.1944 - mae: 1090.4680 - val_loss: 12253178.0000 - val_mae: 2671.6753\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3932585.6111 - mae: 1258.2771 - val_loss: 12452315.0000 - val_mae: 2685.6846\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2397551.1250 - mae: 1044.9164 - val_loss: 12442770.0000 - val_mae: 2687.4812\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2367968.6389 - mae: 1043.4767 - val_loss: 12556610.0000 - val_mae: 2697.9326\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2908783.9444 - mae: 1108.6380 - val_loss: 12261516.0000 - val_mae: 2677.5864\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2585340.0694 - mae: 1079.8080 - val_loss: 12413404.0000 - val_mae: 2689.0662\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2811166.3056 - mae: 1116.2786 - val_loss: 12634680.0000 - val_mae: 2710.4612\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2233140.2500 - mae: 1011.0266 - val_loss: 12686271.0000 - val_mae: 2711.2007\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3588636.8889 - mae: 1179.2148 - val_loss: 12636508.0000 - val_mae: 2709.0830\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2766264.1944 - mae: 1109.7936 - val_loss: 12947775.0000 - val_mae: 2733.6497\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2997231.9167 - mae: 1092.6165 - val_loss: 13134305.0000 - val_mae: 2749.7412\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2681947.4167 - mae: 1071.6329 - val_loss: 12580481.0000 - val_mae: 2705.5852\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1923264.6250 - mae: 930.2259 - val_loss: 12724885.0000 - val_mae: 2717.9390\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2357318.7083 - mae: 966.6437 - val_loss: 12553661.0000 - val_mae: 2703.9980\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3064044.5278 - mae: 1074.3170 - val_loss: 12534270.0000 - val_mae: 2698.9004\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3027021.8889 - mae: 1100.9392 - val_loss: 12694321.0000 - val_mae: 2713.2656\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2825494.4722 - mae: 1004.2220 - val_loss: 12206658.0000 - val_mae: 2676.2761\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2726756.9861 - mae: 1081.3934 - val_loss: 12292395.0000 - val_mae: 2683.4792\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2635273.0972 - mae: 1067.6569 - val_loss: 12586004.0000 - val_mae: 2704.1787\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2243024.9861 - mae: 993.0329 - val_loss: 12462912.0000 - val_mae: 2694.8223\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3282944.8611 - mae: 1099.9604 - val_loss: 12414413.0000 - val_mae: 2695.2236\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2116439.8750 - mae: 964.8424 - val_loss: 12899071.0000 - val_mae: 2735.8274\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3086262.3056 - mae: 1112.4701 - val_loss: 13180578.0000 - val_mae: 2760.8193\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2188923.8472 - mae: 979.4236 - val_loss: 13006033.0000 - val_mae: 2748.5125\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3380950.6944 - mae: 1132.0950 - val_loss: 13066094.0000 - val_mae: 2754.1494\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2272679.2778 - mae: 1027.1041 - val_loss: 12670940.0000 - val_mae: 2718.6714\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2427013.1111 - mae: 1037.7973 - val_loss: 12505133.0000 - val_mae: 2704.4863\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2053032.8472 - mae: 955.0151 - val_loss: 12827948.0000 - val_mae: 2731.6975\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3037295.5556 - mae: 1067.0139 - val_loss: 12544872.0000 - val_mae: 2707.0835\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1756147.6458 - mae: 860.2938 - val_loss: 12767362.0000 - val_mae: 2721.7603\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2502401.7222 - mae: 1040.3092 - val_loss: 12801748.0000 - val_mae: 2721.9497\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2077481.9097 - mae: 942.1565 - val_loss: 12819172.0000 - val_mae: 2719.8303\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2770404.6389 - mae: 1070.3548 - val_loss: 12943583.0000 - val_mae: 2735.0623\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2725309.2639 - mae: 1078.7680 - val_loss: 13036519.0000 - val_mae: 2740.9089\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2191828.3750 - mae: 989.9404 - val_loss: 12822154.0000 - val_mae: 2726.1270\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2161513.0000 - mae: 970.8852 - val_loss: 12372431.0000 - val_mae: 2688.5366\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2246721.2361 - mae: 987.6163 - val_loss: 12545745.0000 - val_mae: 2705.2126\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2613700.8611 - mae: 1031.4939 - val_loss: 12539418.0000 - val_mae: 2702.9604\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1846619.4583 - mae: 896.6498 - val_loss: 13240779.0000 - val_mae: 2764.3374\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2124296.4722 - mae: 936.6734 - val_loss: 12885513.0000 - val_mae: 2738.4128\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2423754.2500 - mae: 1006.4412 - val_loss: 12799075.0000 - val_mae: 2733.4067\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2320290.2222 - mae: 965.5964 - val_loss: 12753159.0000 - val_mae: 2726.8403\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2226077.3194 - mae: 944.7648 - val_loss: 12876627.0000 - val_mae: 2740.2715\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2557845.4167 - mae: 1051.7454 - val_loss: 13335992.0000 - val_mae: 2780.7363\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1924820.6111 - mae: 886.6125 - val_loss: 13226204.0000 - val_mae: 2769.6621\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2388226.0417 - mae: 1064.3943 - val_loss: 13075173.0000 - val_mae: 2757.7246\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1765539.4167 - mae: 861.0928 - val_loss: 13301838.0000 - val_mae: 2780.2898\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2083516.5972 - mae: 966.7534 - val_loss: 13025853.0000 - val_mae: 2757.4907\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2475060.5000 - mae: 1002.5017 - val_loss: 13048714.0000 - val_mae: 2760.8550\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2195514.5556 - mae: 981.4439 - val_loss: 13070405.0000 - val_mae: 2756.9270\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1820872.5556 - mae: 863.3405 - val_loss: 12854509.0000 - val_mae: 2737.2378\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2838797.4167 - mae: 1058.1363 - val_loss: 12910359.0000 - val_mae: 2743.1797\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2760171.9444 - mae: 994.5942 - val_loss: 12677081.0000 - val_mae: 2724.0774\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2164243.2778 - mae: 959.8412 - val_loss: 12785593.0000 - val_mae: 2733.0000\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2068310.4028 - mae: 955.1410 - val_loss: 13010568.0000 - val_mae: 2752.4426\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2192636.9028 - mae: 984.2884 - val_loss: 13156985.0000 - val_mae: 2766.0337\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1573679.0347 - mae: 845.2510 - val_loss: 12859993.0000 - val_mae: 2738.5242\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2176249.8333 - mae: 973.3946 - val_loss: 12963478.0000 - val_mae: 2750.6477\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2290483.4722 - mae: 939.2207 - val_loss: 12888697.0000 - val_mae: 2747.3220\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2444373.5556 - mae: 972.0330 - val_loss: 13208329.0000 - val_mae: 2775.5376\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2155496.1250 - mae: 892.6434 - val_loss: 13554598.0000 - val_mae: 2805.2375\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2539589.8333 - mae: 1043.8733 - val_loss: 13372092.0000 - val_mae: 2789.4531\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2006126.6389 - mae: 905.7892 - val_loss: 13330666.0000 - val_mae: 2784.0425\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2059415.9028 - mae: 951.5447 - val_loss: 12843094.0000 - val_mae: 2740.8911\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2592787.0556 - mae: 947.9976 - val_loss: 12867167.0000 - val_mae: 2742.2913\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2070081.9861 - mae: 896.1880 - val_loss: 12933107.0000 - val_mae: 2749.0547\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2071189.0694 - mae: 935.4034 - val_loss: 13287750.0000 - val_mae: 2781.2686\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2306395.5417 - mae: 911.3978 - val_loss: 13166990.0000 - val_mae: 2771.6287\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1969519.6667 - mae: 916.2403 - val_loss: 12826269.0000 - val_mae: 2740.5093\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1590621.5833 - mae: 832.8327 - val_loss: 13344963.0000 - val_mae: 2787.4175\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1872516.0000 - mae: 853.9260 - val_loss: 13173231.0000 - val_mae: 2773.4092\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2015214.2917 - mae: 917.6945 - val_loss: 12789182.0000 - val_mae: 2739.8862\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1314249.0833 - mae: 724.4755 - val_loss: 13197713.0000 - val_mae: 2775.6057\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1991151.0694 - mae: 901.1224 - val_loss: 13177450.0000 - val_mae: 2771.9277\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2389761.6806 - mae: 950.8550 - val_loss: 13045369.0000 - val_mae: 2757.7759\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2201902.0278 - mae: 837.6182 - val_loss: 12787654.0000 - val_mae: 2733.2112\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1741059.5972 - mae: 894.9482 - val_loss: 13036078.0000 - val_mae: 2755.6484\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2447393.4583 - mae: 926.1758 - val_loss: 13021798.0000 - val_mae: 2756.2205\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1779008.0972 - mae: 872.2745 - val_loss: 13082165.0000 - val_mae: 2764.1812\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1831739.9375 - mae: 809.5276 - val_loss: 13522979.0000 - val_mae: 2803.6516\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1848856.0833 - mae: 887.3521 - val_loss: 13363275.0000 - val_mae: 2792.2776\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1599827.9167 - mae: 843.5219 - val_loss: 13152999.0000 - val_mae: 2775.3909\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2617280.7222 - mae: 979.4054 - val_loss: 12971523.0000 - val_mae: 2758.2429\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1423626.2222 - mae: 787.5948 - val_loss: 12860237.0000 - val_mae: 2747.2217\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2213823.5556 - mae: 934.3882 - val_loss: 13126039.0000 - val_mae: 2770.6904\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1909519.8472 - mae: 915.8609 - val_loss: 12988379.0000 - val_mae: 2758.9341\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1946354.7014 - mae: 850.1903 - val_loss: 13270034.0000 - val_mae: 2783.7585\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1732540.6528 - mae: 853.8201 - val_loss: 13245966.0000 - val_mae: 2781.9558\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1922029.8194 - mae: 852.7231 - val_loss: 13173682.0000 - val_mae: 2779.3418\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1606552.3472 - mae: 849.7509 - val_loss: 13301775.0000 - val_mae: 2791.0979\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2088706.5556 - mae: 907.7907 - val_loss: 12987157.0000 - val_mae: 2761.6570\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2214424.4028 - mae: 948.1800 - val_loss: 13218883.0000 - val_mae: 2783.0247\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1683641.6250 - mae: 848.2741 - val_loss: 13306203.0000 - val_mae: 2789.7979\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1701129.7153 - mae: 765.0304 - val_loss: 12947699.0000 - val_mae: 2760.5071\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2195822.4306 - mae: 869.6191 - val_loss: 13157025.0000 - val_mae: 2780.5449\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1587825.4583 - mae: 810.0849 - val_loss: 12954790.0000 - val_mae: 2762.1677\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1917659.5694 - mae: 829.4719 - val_loss: 13479947.0000 - val_mae: 2808.5022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "QdOcvV5puIU3",
        "outputId": "43a2d0ac-e195-4d6e-ec08-0e02d98549dc"
      },
      "source": [
        "history_dict = Model_Results4.history\n",
        "mae_values = history_dict['mae']\n",
        "val_mae_values = history_dict['val_mae']\n",
        "epoches = np.arange(1,len(history_dict['mae'])+1)\n",
        "plt.plot(epoches,mae_values,'r',label=\"Training Mae\")\n",
        "plt.plot(epoches,val_mae_values,'g',label=\"Validating Mae\")\n",
        "plt.title('Training and validation Mae')\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Mae\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJzju7v2mzCw",
        "outputId": "32c528fb-8ae9-475d-b59b-062e2b7e1cb1"
      },
      "source": [
        "history_dict = Model_Results4.history\n",
        "val_acc_values = history_dict['val_mae']\n",
        "maxi = np.max(val_acc_values)\n",
        "mini = np.min(val_acc_values)\n",
        "avrg = (maxi+mini)/2\n",
        "print(f\"FOR MODEL1 Average Validation Absolute Error = {avrg}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOR MODEL1 Average Validation Absolute Error = 6768.7042236328125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8BL5nKnnZbs"
      },
      "source": [
        "# **MAE with K fold and with relu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2wVTPJFnNjD",
        "outputId": "d07f1a11-b0e1-4fe5-eda6-61adf5f4fd54"
      },
      "source": [
        "k =  4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores_relu = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  partial_train_targets = np.concatenate([train_labels[:i * num_val_samples],train_labels[(i + 1) * num_val_samples:]],axis=0)\n",
        "  model = Train_Me_with('relu')\n",
        "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores_relu.append(val_mae)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "WARNING:tensorflow:6 out of the last 2009 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6a3089a3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 1\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6a2cd8ed40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 2\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6a30d42a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 3\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6a5006f0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJhBSUxdoNVZ"
      },
      "source": [
        "# **MAE with K fold and with gelu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3qlJfxinD9A",
        "outputId": "7d0abb90-4528-4f8e-eb1b-902b3574d0cb"
      },
      "source": [
        "k =  4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores_gelu = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  partial_train_targets = np.concatenate([train_labels[:i * num_val_samples],train_labels[(i + 1) * num_val_samples:]],axis=0)\n",
        "  model = Train_Me_with('gelu')\n",
        "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores_gelu.append(val_mae)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6a3e0be830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 1\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6a2cdb1cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 2\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6a30cbf830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 3\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6a2cdb1c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5i7tx8moUEE"
      },
      "source": [
        "# **MAE with K fold and with selu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EGHxt2eoI1W",
        "outputId": "04e219fd-2934-400a-d633-97755c4cedce"
      },
      "source": [
        "k =  4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores_selu = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  partial_train_targets = np.concatenate([train_labels[:i * num_val_samples],train_labels[(i + 1) * num_val_samples:]],axis=0)\n",
        "  model = Train_Me_with('selu')\n",
        "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores_selu.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f55c20c5170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 1\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f55a2892170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 2\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f55a6af6560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 3\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f55a6af63b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xug1wYVDoLNd"
      },
      "source": [
        "# **MAE with K fold and with tanh**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju2_Av5soKF2",
        "outputId": "05d46667-13ba-4573-c377-9f4027a8031c"
      },
      "source": [
        "k =  4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores_tanh = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  partial_train_targets = np.concatenate([train_labels[:i * num_val_samples],train_labels[(i + 1) * num_val_samples:]],axis=0)\n",
        "  model = Train_Me_with('tanh')\n",
        "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores_tanh.append(val_mae)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6a2900e8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 1\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6a3089a710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 2\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6a30d42cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 3\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6a30cbf170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_iPCkrkqYdu"
      },
      "source": [
        "# **Averages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC80FyDAo2KO",
        "outputId": "4deecdd7-2c51-412d-a1fb-068450a55358"
      },
      "source": [
        "print(f\"Using activation function relu {np.average(all_scores_relu)}\")\n",
        "print(f\"Using activation function tanh {np.average(all_scores_tanh)}\")\n",
        "print(f\"Using activation function gelu {np.average(all_scores_gelu)}\")\n",
        "print(f\"Using activation function selu {np.average(all_scores_selu)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using activation function relu 2615.3230895996094\n",
            "Using activation function tanh 14131.87890625\n",
            "Using activation function gelu 2685.805450439453\n",
            "Using activation function selu 2792.7562561035156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoAUInuCuyJw"
      },
      "source": [
        "# **So Outcome of after all struggle**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MQGTMT8vQue"
      },
      "source": [
        "Relu functions give better results amoung all other //\\\\\\ Now paying with epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRUW0XEWulvA",
        "outputId": "53067574-0084-49b9-fb98-d5207c80df17"
      },
      "source": [
        "k =  4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 200\n",
        "all_scores_K_relu = []\n",
        "model = Train_Me_with('relu')\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  partial_train_targets = np.concatenate([train_labels[:i * num_val_samples],train_labels[(i + 1) * num_val_samples:]],axis=0)\n",
        "  Model_Results = model.fit(partial_train_data, partial_train_targets,epochs = num_epochs, batch_size=1,verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores_K_relu.append(val_mae)\n",
        "  history_dict = Model_Results.history\n",
        "  mae_values = history_dict['mae']\n",
        "print(f\"On Eveluation Average using RELU and having {num_epochs} epoches is {np.average(all_scores_K_relu)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f559e1497a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n",
            "On Eveluation Average using RELU and having 200 epoches is 1451.5171813964844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIjfr6kehmwU"
      },
      "source": [
        "# **Prediction obtained**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcRk_ZkZxqNV"
      },
      "source": [
        "Predicted_val = model.predict(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P78vfdpV_V8M"
      },
      "source": [
        "y_pred = Predicted_val.flatten()\n",
        "y_true = test_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "yUVNtVz68bam",
        "outputId": "785f5885-e073-4c00-d8df-53bb4fb7b337"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "coef = np.polyfit(y_true,y_pred,1)\n",
        "poly1d_fn = np.poly1d(coef) \n",
        "# poly1d_fn is now a function which takes in x and returns an estimate for y\n",
        "plt.figure()\n",
        "plt.plot(y_true,y_pred, 'yo', y_true, poly1d_fn(y_true), '--k')\n",
        "plt.title('MAE with K fold and with relu')\n",
        "plt.xlabel('Thousand Dollar True' )\n",
        "plt.ylabel('Thousand Dollar Predictions' )\n",
        "plt.xlim(500, 30000)\n",
        "plt.ylim(500, 30000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500.0, 30000.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEWCAYAAADPZygPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwU1bn/8c93BhxREUUUCShLRETjEsWFaBA0Ki5RicaXylVcEk2ikXhj4nqNG/eniVs0US9eNYi4xesed2VcQQPRuCFKAAUCqMiuIjPz/P6o0zM1Q3dPz0x3V/fM8369+jVdp6urTvVAP3POeeocmRnOOedcEiqSroBzzrmOy4OQc865xHgQcs45lxgPQs455xLjQcg551xiPAg555xLjAch125I2lrSKkmVWfYxSdsU6PyDJL0laaWks5rZ9yRJr2R5vVrST/Jfy3XO0y98Jp3aeJxVkgZkeX2upB+05RxZjj1c0vxCHNsVngch1yLhy+QbST2alL8Zvsz6NSm/JJTv2aT8JEm14csr/vhWa+tmZp+Y2UZmVhvO0aYv8lD3u2LbvSV9IOkGSUrzlt8Ck82sq5nd0NrzlqPwuc8GkPQXSVckXSdXHjwIudaYAxyX2pC0I7BB053CF/WJwBfhZ1NTwpdX/PHvQlW6LST1BV4CHjWzsyz9Xd59gfeKW7P2r62tNFfaPAi51phI46AyBrgzzX7fB3oBZwHHSlqvNSeTdKmkG8PzzpJWS/pD2O4i6WtJ3eNdS5LGhfP/KbSw/hQ75A8kfSRpmaQ/Z2jVxM//baIANMnMfpthnxeAEbHzbSupm6Q7JX0m6WNJF0lK+39O0gGhlbU81DVjnSTtIWlKqP9CSX+Kf7bhM/hZumuUVCnpakmfS5oNHJrlPCdLeiy2/ZGkv8a250naJXbObSSdBowGfhs+h8dih9xF0tvhGu+TtH6G854k6VVJ10laAlwiqSrU+xNJiyXdIqlLhvc36nL1lllp8yDkWmMqsLGkwYrGX44F7kqz3xjgMeD+sP3DVp7vRWB4eL47sAgYFraHAjPN7Iv4G8zsQuBl4MzQwjoz9vJh4Tg7AccAB2U59wCiAPQ/ZnZxpp3MbL8m5/sQuBHoFo6xL1HgPrnpe0PX5oPARUAP4F/A3lnqVAucHfYdCuwP/KLJPpmu8afhte8CQ4Cjs5znReD7kipCN+l64XyE8Z+NgLebfA7jgUnA78PnEP+dHwOMBPqHep2U5dx7ArOBnsA44EpgW2AXYBugN5Dx9+HKhwch11qp1tABwAxgQfxFSRsAPwbuNrO1wAOs2yW3V/hLPfX4V4ZzTQEGStqMKPjcBvSWtBHRl/uLLaz7lWa2zMw+ASYTfbFl8h1gQ+C+lpwgFpzPN7OVZjYXuAY4Ic3uhwDvmdkD4bO6nijQpmVm081sqpnVhOP+D9HnEJfpGo8BrjezeSFw/78s55kNrAzvHQY8Dfxb0nbhfC+bWV3WD6KxG8zs3+G8j5H9c/+3md1oZjXA18BpwNlm9oWZrQT+m+jzdWXO+1pda00kaiH0J31X3CigBngibE8CnpO0uZl9Fsqmmtk+zZ3IzL6SNI3oi28Y0V/GuxC1FvYlanG0RPwL/kuiv+gzeRT4FHhB0jAz+zjHc/QAOgPx/T8m+gu+qW8B81IbZmaS5qXZDwBJ2wLXErVkNiD6fzy9yW6ZrrHRuZrUL51UK3Sb8HwZ0Wc+lJYH/6Z1ypaEEq/j5kTXOT3WcyogYxakKx/eEnKtEr6M5xD9Ff9gml3GEH3xfSJpEfBXoi/l41t5yheB/Yi6kf4etg8C9iAKhmmr2cpzNT6I2X8CjxMFonRBJJ3PgbVEyQopW9OkxRgsBLZKbYTxm63S7JdyM/ABMNDMNgYuIMsYUrZzhTplkwpC3w/PXyQKQtlaoPn43OPH+Bz4CtjBzDYJj25mlumPhy9pnCizZR7q4wrEg5Bri1OB/cxsdbwwfFHvTzT2sEt47AxcRfosuVy8GN77vpl9A1QDPwHmxFpWTS0mGo/JhzOJurWel9SzuZ1Dmvj9wDhJXUN23X+Sfuzsb8AOkn4UMsHOIvsXZ1dgBbAqdI39vAXXcT9wlqQ+kjYFzmtm/xeJEi66mNl8onGvkcBmwJsZ3pPPz53Q5XcrcJ2kLaA+XT7TWN5bwPEhCWMk63ZVuhLiQci1mpn9y8ympXnpBOAtM3vGzBalHsANwE6SvhP2G6p17xPaPcPpXgO60NDqeZ9orCBTKwjgj8DRkpZKatN9OyEl+zTgDaJuxR7NvAXgl8BqogH2V4C7gdvTHPtzovGzK4ElwEDg1SzHPYeoRbmS6Mu5JeNVtxKN7fwT+AfpW7Hxun0IrCIKPpjZinA9r6bux0rjNmD7MM73cAvqls25wCxgqqQVwHPAoAz7jiVKgllGlKmXrzq4ApAvaueccy4p3hJyzjmXmIIFIUnrS3pD0j8lvSfp0lDeX9LrkmaFG9bWC+VVYXtWeL1f7Fjnh/KZ8X5gSSND2SxJzfVtO+ecKzGFbAmtIRq03ploYHqkpL2IBqevM7NtgKVEg9uEn0tD+XVhPyRtT3Q/wA5EA6I3hQHHSuDPwMHA9sBxYV/nnHNlomBByCKrwmbn8DCiNNsHQvkE4Mjw/IiwTXh9/5CqegRwr5mtMbM5RIOTe4THLDObHbKl7g37OuecKxMFvVk1tFamE93o9mei6UiWhbugAebTcPNeb8INamZWI2k5URpob6JpYkjznnlNyhvN1Byrx2lEmU1suOGGu2233XZtuzDnnOtgpk+f/rmZbZ7v4xY0CIUUzl0kbQI8BCTy7R/msxoPMGTIEJs2LV1WsXPOuUwk5TpbSIsUJTvOzJYR3eg3FNhEDVOz96HhDvIFhDu5w+vdiO6ZqC9v8p5M5c4558pEIbPjNg8tIMKU66mJLifTMHPvGOCR8PzRsE14/YVwg+CjRMsAVEnqT3Qj3xtEU7cMDNl26xElLzxaqOtxzjmXf4XsjusFTAjjQhXA/Wb2uKT3gXvD+h5vEt1dTfg5UdIsokXQjgUws/ck3U90h3wNcEZs5cwzie7+rgRuNzNfUMw558pIh5sxwceEnHOu5SRNN7Mh+T6uz5jgnHMuMR6EnHPOJcaDkHPOucR4EHLOtSs1NTV0tLHucuZByDnXbqxYsYLDDjuMyy67LOmquBx5EHLOtQsLFixg2LBhPPfcc/Tunesq7C5pBZ22xznniuHtt9/m0EMPZfny5fztb3/joIMyrfztSo0HIedcWVu+fDkjRoygS5cuvPzyy+y8885JV8m1gAch51xZ69atG+PHj2fPPfekT58+SVfHtZCPCTnnyo6ZcfHFF/PQQw8BcNRRR3kAKlMehJwrQYsXT2LKlH5UV1cwZUo/Fi+elHSVSsY333zDiSeeyOWXX87zzz+fdHVcG3l3nHMlZvHiScyceRp1dV8CsGbNx8yceRoAPXuOTrJqiVu6dCk/+tGPqK6u5oorruCCCy5IukqujTwIOVdiZs++sD4ApdTVfcns2Rd26CC0YsUK9t57b2bNmsVdd93F6NEd97NoTzwIOVdi1qz5pEXlHUXXrl0ZNWoUBxxwAMOHD0+6Oi5PPAg5V2KqqrZmzZp1V1Kuqto6gdok7/HHH6dv377suOOOjBs3LunquDzzxATnSsyAAeOoqNigUVlFxQYMGNDxvoBvuukmjjjiCC6++OKkq+IKxIOQcyWmZ8/RDBo0nqqqvoCoqurLoEHjO9R4UF1dHeeccw5nnHEGhx56KHfddVfSVXIF4t1xzpWgnj1Hd6igE/f1119zwgkn8MADD3DmmWdy/fXXU1lZmXS1XIF4S8g5V1IqKipYtmwZ11xzDTfccIMHoHbOW0LOuZLw0Ucfsemmm9KjRw+eeuopDz4dhLeEnHOJe/XVVxk6dCg/+clPADwAdSAehJxzifrrX//K/vvvT/fu3bn66quTro4rMg9CzrlEmBl/+MMfOOaYYxgyZAivvfYa22yzTdLVckXmQcg5l7N8Tqy6atUqbrnlFn784x/z3HPP0aNHj5KpmyseT0xwzuUkXxOrrl69mvXWW4+uXbvy6quvssUWW1BR0ba/h33S1/LlLSHnXE6yTayaq4ULFzJs2DDOOOMMALbccss2B6B81c0lw4OQc2WgFLqa2jqx6nvvvcdee+3FzJkzOfLII/NZNZ/0tYx5d5xzJS5bVxNErYA1az6hqmprBgwYV7Dup7ZMrDp58mRGjRpFly5deOmll9h1111Lpm4uWQVrCUnaStJkSe9Lek/S2FB+iaQFkt4Kj0Ni7zlf0ixJMyUdFCsfGcpmSTovVt5f0uuh/D5J6xXqepxLSqaupo8+GsvMmaeFL1+rD06FaiW1dmLVlStXcvTRR9O7d2+mTp2a9wDUlrq55BWyO64G+LWZbQ/sBZwhafvw2nVmtkt4PAEQXjsW2AEYCdwkqVJSJfBn4GBge+C42HGuCsfaBlgKnFrA63EuEZm6lGpqlhR1HKSlE6uaGRCtA/TYY4/x6quv0rdv35KomysdBeuOM7OFwMLwfKWkGUDvLG85ArjXzNYAcyTNAvYIr80ys9kAku4FjgjH2w84PuwzAbgEuDnf1+JckjJ1NWVSyHGQXCdWXbt2Laeffjrf/e53+eUvf8n3vve9gtWppXVzpaUoiQmS+gHfBV4PRWdKelvS7ZI2DWW9gXmxt80PZZnKNwOWmVlNk/J05z9N0jRJ0z777LM8XJFzxZOpq6mycrO0+yc9DrJ8+XIOOeQQ7rjjDpYuXZpoXVzpK3gQkrQR8H/Ar8xsBVFL5dvALkQtpWsKXQczG29mQ8xsyOabb17o0zmXV5m6mrbd9o8lNw4yb9489tlnH6qrq7njjjt8MTrXrIJmx0nqTBSAJpnZgwBmtjj2+q3A42FzAbBV7O19QhkZypcAm0jqFFpD8f2dK3uLF0/KKfOtWNlxzVm5ciVDhw5l5cqVPPnkk/zgBz9IpB6uvBQsCEkScBsww8yujZX3CuNFAKOAd8PzR4G7JV0LfAsYCLwBCBgoqT9RkDkWON7MTNJk4GjgXmAM8Eihrse5Ysp1BoBSGgfp2rUrF198MUOHDmXHHXdMujquTCiVwZJxB2lD4Cszq5O0LbAd8KSZrW3mffsALwPvAHWh+ALgOKKuOAPmAqengpKkC4FTiDLrfmVmT4byQ4DrgUrgdjMbF8oHEAWg7sCbwH+ExIaMhgwZYtOmTct6zc4lbcqUfhnue+nL0KFzi1+hLG699VYGDBjA/vvvn3RVXAFJmm5mQ/J+3ByC0HTg+8CmwKvA34FvzKw0/vxqIQ9CrhxUV1cQ/Z3WlBg+vC5NefHV1dVx4YUXcuWVV3Lsscdyzz33JF0lV0CFCkK5JCbIzL4EfgTcZGY/JrqXxzlXIJky3JLOfEtZs2YNo0eP5sorr+T0009n4sSJSVfJlamcgpCkocBo4G+hzJc9dK6ASnkGgFWrVnHAAQdw7733cuWVV3LzzTfTqVNhhpdLYc48V1i5/MsZC5wPPGRm74VxmMmFrZZzHVsq2aBUMt/iNtxwQ7bddlt+8YtfcOyxxxbsPL48Q8fQ7JhQe+NjQq69yjWlu7WuvfZaDj30UAYNGpS3Y2ZTTskZHUGhxoSabQmFjLhzgH7x/c1sv3xXxjnXOoVuNXTr1o0VK1bw61//mmL94erLM3QMuXTH/RW4BfhfoLaw1XHOtUa2Rd3aGoSiW/4iL7zwQpuO1RK+PEPHkEsQqjEznxTUuRJWiFbD119/TZcuXeq3582bR58+fVp9vJYaMGBco9YdlE5yhsufXLLjHpP0C0m9JHVPPQpeM+dczgqR0n3ppZfWP//666+LGoDAl2foKHK5WXVOmmIzswGFqVJheWKCa4+ajglB1GpozZf23Llz6d69O127duWGG25g7Nix+a6uK0OJ3axqZv3TPMoyADnXXuWr1fCHP/yB/v37061bNySVZQDye4vKSy7ZcZ2BnwPDQlE18D/NzR3nnCuutk5mevDBB/PUU08BMGbMmHxVq6j83qLyk0tiws1AZ+CmsH1CKPtJoSrlnGtQ6Pt/oHEG3K233spPflKe/70LmSXoCiOXILS7me0c235B0j8LVSHnXINi/GV/0UUX1T9/44032H333fNy3CT4vUXlJ5fsuFpJ305thGl7/H4h1+6VwthCtr/s26qmpoa6ujouuugiNt54Yz799FN23333krju1ir1iV/dunIJQr8BJkuqlvQi8ALw68JWy7lkpVog0c2SVt8CKfYXcqH+sv/www/p3LkzgwcPZv3112f58uVsvvnmJXPdrVXKE7+69HLJjnueaJXTs4BfAoPMzCcwde1aIVsgLVGIv+z/67/+q37+tw8//LDRa6Vy3a3l9xaVn4z3CUnaz8xekPSjdK+b2YMFrVmB+H1CLheZF5WLJtAs1szW2e7/gZbPsr3TTjvxzjvvANFy3CtWrGj0erbF9AYPnliSs3q74khiAtN9ibrefpjmNQPKMgg5l4tM85aB6suLkf6baUkHoMUJC0ceeWR9AOrevTtLlixZZ59M111Z2d1Tn11B5DJjQn8zm9NcWbnwlpDLRboWCIh0rYQklhZo6TIH9957L59++iljx47l2muv5eyzz0573Ewtr4qKLtTUpAtavqxCR5HYUg7A/wG7Nil7ANgt35VxrlSka4Gkbxklk/6ba8JCTU0NnTt3BuDss8+mrq6u0T1BTWVqec2YcUKL6uFcrjIGIUnbATsA3ZqMC20MrF/oijmXtKYzEGRufRQ//TeXZQ7mzZvH1ls3bF911VVZA1BKupkXoqBUGtfu2pds2XGDgMOATYjGhVKPXYGfFr5qzpWWUkr/ba4ujzzySKMAVFtbW98ias19QKV07a59ydgSMrNHgEckDTWzKUWsk3MlKVNXVRID89nqcttttzWadic+7tvaGRhK6dpd+5JLYsIEYKyZLQvbmwLXmNkpRahf3nligmvP3nvvPcaNG8c999wDsM5S3C1NaHAuJbGlHICdUgEIwMyWAt/Nd0Wcc20zZswYvvOd7/Ctb32LefPmrROAwOdWc6Unl+y4CkmbhuBDWFU1l/c554oknnBwzjnnsOWWW6bdL5eEBueKKZeW0DXAFEmXS7oCeA34fWGr5ZzLxdq1axsFoNmzZ2cMQOAJBq70NNuiMbM7JU0D9gtFPzKz9wtbLedcc+bMmcOAAQ2LHK9evZoNNtggyzs8wcCVnmz3CW1sZitC99si4O7Ya93N7ItsB5a0FXAn0JPoNvPxZvbHcLz7gH7AXOAYM1uq6M+5PwKHAF8CJ5nZP8KxxgCpRU+uMLMJoXw34C9AF+AJogSK7JkWzrUD06ZNa7TuT3M3oca1dQVW5/IpW3dcKuhMB6bFHqnt5tQAvzaz7YG9gDMkbQ+cBzxvZgOB58M2wMFEs3UPBE4jWr01NQb1O2BPYA/gdyFDj7DPT2PvG5lDvZwra+eff359ANpwww0xs5wDkHOlJtt9QoeFn/1bc2AzWwgsDM9XSpoB9AaOAIaH3SYA1cC5ofzO0JKZKmkTSb3Cvs+mWl6SngVGSqoGNjazqaH8TuBI4MnW1Ne5chAPNkcddRQPPPBAgrVxru2ydcc1nS+ukVRXWS4k9SNK634d6BkCFETdfD3D897AvNjb5oeybOXz05SnO/9pRK2rRneRO1dOUjMeABx22GEegFy7kC0x4Zrwc31gCPBPommEdyLqjhuaywkkbUQ0CeqvwhhT/WtmZpIKPoZjZuOB8RDdrFro8zmXT2ZGRUVDz/kLL7zAiBEjEqyRc/mTcUzIzEaY2QiiLrVdzWyIme1G1KJZkMvBJXUmCkCTYovgLQ7dbISfn4byBcBWsbf3CWXZyvukKXeu3fjmm28aBaB///vfHoBcu5LLfUKDzOyd1IaZvQsMbu5NIdvtNmCGmV0be+lRYEx4PgZ4JFZ+oiJ7ActDt93TwIGSNg0JCQcCT4fXVkjaK5zrxNixnCt7r732GlVVVfXbX3/9Nb169UqwRs7lXy4zH7wt6X+Bu8L2aODtHN63N3AC8I6kt0LZBcCVwP2STgU+Bo4Jrz1BlJ49iyhF+2QAM/tC0uXA38N+l8XSw39BQ4r2k3hSgmsnJkyYwEknnVS/7XceuPYqlwlM1wd+DgwLRS8BN5vZ1wWuW0H4BKau1J1yyinccccd9dsegFwpSGxlVTP7WtItwBNmNjPfFXDONYgn7owePZq77rory97Olb9mx4QkHQ68BTwVtneR9GihK+ZcRxMPQFdccYUHINch5DIm9DuimQqqAczsLUmtuoHVObeuuro6Kisr67erq6vZd999E6yRc8WTSxBaa2bLm0wL4p3UruQsXjyp7CbmXLJkCT169KjfXrlyJRtttFGCNXKuuHJJ0X5P0vFApaSBkm4kWs7BuXUsXjyJKVP6UV1dwZQp/Vi8eFLRzjtz5mlhrRyrX7a6WOdvjTfffLNRAKqpqfEA5DqcXILQL4EdgDVEk5ouB35VyEq58tTaQJCPwDV79oXU1X3ZqKyu7ktmz76wxccqhuuuu45dd22YGcvMGnXJOddRZO2Ok1QJ/C3MnFCa/5tdycgWCDJ1i6UCV+p9qcAFtKgrrZyWrR41ahQPP/xw/banYLuOLGtLyMxqgTpJ3YpUH1fGWhMI8tWCybQ8daktW73LLrvUB6DDDjvMA5Dr8HJJTFhFNOvBs8DqVKGZnVWwWrmyVFW1deiKW7c8k3y1YAYMGNeoRQWlt2x1PLnnlVdeYe+9906wNs6VhlyC0IPh4VxWrQkErQlc6ZTystU1NTWNlmGYOXMm2267bYI1cq50NDcmdCSwOfCOmT1dnCq5ctWaQJDPFkwpLls9f/58ttqqYRL4pUuXsskmmyRYI+dKS7ZF7W4iyop7Dbhc0h5mdnnRaubKUksDQSm3YNrqmWee4aCDDqrfrqur82W4nWsiW0toGLCzmdVK2gB4GfAg5PKuFFswbTVx4kROPPHE+m1PQHAuvWzZcd+E7DjM7EuiVVWdc80YMWJEfQA64YQTPAA5l0W2ltB2klLrBgn4dtgW0crcOxW8ds6VmXh32+9//3t+85vfJFgb50pftiDU7OqpzrkG8QB0zz33cOyxxyZYG+fKQ8YgZGbr5s0659axYsUKunVruJ/7k08+aZQR55zLLJe545xzGcyZM6dRAFq9erUHIOdawIOQc630+OOPM2DAgPptM2ODDTZIsEbOlZ+sQUhSpaTSnQvfuYSMGDGCH/7wh/XbngHnXOtknTEh3CPUV9J6ZvZNsSrlXCmLJyBst912zJgxI8HaOFfecpk7bjbwqqRHaTyB6bUFq5VzJSoegEaPHs1dd92VYG2cK3+5BKF/hUcF0LWw1XGuNJkZFRUNvdc33ngjZ555ZoI1cq59aDYImdmlxaiIc6Vq1apVdO3a8PfXu+++yw477JBgjZxrP5oNQpI2B35LNJnp+qlyM9uvgPVy7dzixZPKYtLSl19+mWHDhtVvf/PNN42WZXDOtU0uKdqTgA+A/sClwFzg7wWsk2vnUkt6R+sIWf2S3osXl1Yi5plnntkoAJmZByDn8iyXMaHNzOw2SWPN7EXgRUkehFyrZVvSu1RaQ02XXPAUbOcKI5cgtDb8XCjpUODfQPfCVcm1d/la0rtQPAA5Vzy5dMddIakb8GvgHOB/gbObe5Ok2yV9KundWNklkhZIeis8Dom9dr6kWZJmSjooVj4ylM2SdF6svL+k10P5fZLWy/GaXcIyLd3d0iW9CyEegEaNGuUByLkCazYImdnjZrbczN41sxFmtpuZPZrDsf8CjExTfp2Z7RIeTwBI2h44lij5YSRwU5itoRL4M3AwsD1wXNgX4KpwrG2ApcCpOdTJlYABA8ZRUdF4epvWLumdLzU1NY0C0CuvvMKDDz6YWH2c6yiyLe99I5Dxz0AzOyvbgc3sJUn9cqzHEcC9ZrYGmCNpFrBHeG2Wmc0OdboXOELSDGA/4PiwzwTgEuDmHM/nElSsJb1zzcCbN28eW2/d0ApbunQpm2yySV7r4pxLL9uY0LQCnfNMSSeG4//azJYCvYGpsX3mhzKAeU3K9wQ2A5aZWU2a/dch6TTgNKDRl41LTqGX9E5l4KUSIFIZeKlzp7zwwgvsv//+9ds1NTVUVlYWrF7OucayrSc0oQDnuxm4nKiFdTlwDXBKAc7TiJmNB8YDDBkyxDv5O4BcMvD++7//mwsvvLD+dR//ca74snXHPUb27rjDW3oyM1scO/6twONhcwEQX4SlTygjQ/kSYBNJnUJrKL6/K3P5uJG1uQy8s846ixtvvLG+3AOQc8nI1h13db5PJqmXmS0Mm6OAVObco8Ddkq4FvgUMBN4ABAyU1J8oyBwLHG9mJmkycDRwLzAGeCTf9XXFl2s3WnOqqrYON8OuW7777rszbVrU2/yrX/2K6667Lg81d861RrbuuBdTz0P687Zhc6aZrU3/rgaS7gGGAz0kzQd+BwyXtAtRC2sucHo413uS7gfeB2qAM8ysNhznTOBpoBK43czeC6c4F7hX0hXAm8BtOV6zK2H5upF1wIBxjYIZRBl43/vex0AUnJ544gkOPvjgvNTbOdc6aq4bQtJwouyzuUQtk62AMWb2UqErVwhDhgyx1F/BrvRUV1eQvhdYDB9e16Jjxbv1pK0YPryhi+6DDz5g0KBBbauscx2IpOlmNiTfx81lxoRrgAPNbGaoyLbAPcBu+a6Mc9m60VoqlYH3wQcfMHjw4Pry1atX+zLczpWIXGZM6JwKQABm9iHgszi6gsj3jaxPPfVUowBUV1fnAci5EpJLS2iapP8FUktIjqZw9xC5Di6fN7L26tWLRYsW1W97BpxzpSeXIPRz4AwgNUPCy8BNBauR6/DycSOrT0LqXHnIZWXVNZImAhPN7LMi1Mm5NilUACqXhficKycZx4QUuUTS58BMYKakzyRdXLzqOZc7M2sUgC666KK8BqByWIjPuXKTLTHhbGBvYHcz625m3YnmbdtbUrNLOTiXi8WLJzFlSj+qqyuYMqVfq7/UV61aRUVFwz/nxx57jMsvvzxv58h2/5JzrvWyBaETgBdERxEAABiMSURBVOPMbE6qIMxm/R/AiYWumGv/8tW6eOyxx+jatWv99rJlyzjssMPyeo5SX4jPuXKVLQh1NrPPmxaGcSFP0XZtlql18eGHY3Nuuey8884cfnjDNIZmRrdu3Zo9R0tbMKW8EJ9z5SxbYsI3rXzNuZxkakXU1i6htnZJ2Cfz3HHpEhCaJg+ku/E127kzyTQNUJIL8TnXHmRrCe0saUWax0pgx2JV0LVfubYi0rVcMgWgpl1v0UxTrT93Ss+eoxk0aDxVVX0BUVXVl0GDxnt2nHNtlG0CU1/ZyxVUutZFJvGWS6YU7HRdb9E8dCI+H11rWzCFXojPuY4ol2l7nCuIdK2LTp02S7tvVdXW1NbWNgpAY8aMaZSCnbmLzbwF41yJymXGBOcKpmnroul6QhC1XNas+RmdOjX8c/3www8ZOHBgo2NlHgOq9BtMnStR3hJyJSVd6+jhhw9gxIjz6/f56quv1glAkH7y00gtfoOpc6Wp2fWE2htfT6i8tHQKnnh2XPQ3Vu06+1RV9WXo0Ln5q6RzHUDR1xMKWXAZ/8eb2cb5rowrf/mcX601c8DFu/eiBfLW5TeYOlc6smXHdQWQdDmwEJhIlGY0GuhVlNq5stJ0PCfbPT7NycckpPlcIM85Vxi5jAkdbmY3mdlKM1thZjcDRxS6Yq58pOZmmzHjP/IyO0E8AO27776tnoQ03wvkOefyL5cgtFrSaEmVkiokjQZWF7pirjw0vkE0vVy7v7788stGAeiaa66hurq61XXzG0ydK325pGgfD/wxPAx4NZS5Dm7x4knMmDGGdIP/cbl0fz311FMcfPDB9dvpUrBbw28wda605bKo3Vy8+801kWoBNReApPWoqVlFdXVFxkSF8ePHc/rpp9dv19bWNlqWoZB8oTrnktVsEJK0OfBToF98fzM7pXDVcqUu/RQ5jXXqtBk1NSuyTka61VZbMX/+/Pr3FPOWgXwlUnggc671cvlz8xGgG/Ac8LfYw3Vg2cZ5Kio2YPDgu6is3AhY2+i1eKKCpMQCEORnmQdfcdW5tsllTGgDMzu34DVxZSXbFDmpwf8ZM05I+941az7JSwp2W+VjobpsgcxbQ841L5eW0OOSDil4TVxZyZT+PHjwhPov30wJCSNGNASc9ddfP5EABPlZqM5XXHWubXIJQmOJAtFXqfWEJK0odMVcaevZczRbbjkGSK34UcmWW45p9Nd/00C1ciWMGNFwjKuuOpmvvvqqOBVOIx/3EfmKq861TbNByMy6mlmFmXUxs43Dtk/Z08EtXjyJRYsm0JAdV8uiRRMajYWk7tOBSqZPh9gq3Nx/P3z/+y8Us8rryMd9RH5DrHNtk9MEppI2BQYC66fKzOylZt5zO3AY8KmZfSeUdQfuI8q0mwscY2ZLFQ0Q/BE4BPgSOMnM/hHeMwa4KBz2CjObEMp3A/4CdAGeAMZaDhfjE5jmx5Qp/TJMibPu5KC77y7iH/nkyalnYvjwujbVoxQy00qhDs4VWtEnMI2d+CdEXXJ9gLeAvYApwH7NvPUvwJ+AO2Nl5wHPm9mVks4L2+cCBxMFuYHAnsDNwJ4haP0OGEJ0o+x0SY+a2dKwz0+B14mC0EjgyeYv2eVDrmMhTRMQGgJQ27us8jlXXVv4DbHOtV6uY0K7Ax+b2Qjgu8Cy5t4UWkpfNCk+ApgQnk8AjoyV32mRqcAmknoBBwHPmtkXIfA8C4wMr21sZlND6+fO2LFcEeQyFpItAGXrskrNRVddXcGUKf0ypjvnI8XaOZesXILQ12b2NYCkKjP7ABjUyvP1NLOF4fkioGd43huYF9tvfijLVj4/TXlakk6TNE3StM8++6yVVXdxzY2FNA1AixbdldPYS0vuu/HMNOfKXy73Cc2XtAnwMPCspKVA5tkqc2RmJqkoublmNh4YD9GYUDHO2d6lAkjTsZAttji+UQAaOXIkTz75ZKP3xDUdT6mpWZXzfTe+VINz5S+XueNGhaeXSJpMNHvCU60832JJvcxsYehS+zSULwC2iu3XJ5QtAIY3Ka8O5X3S7O+KqOlYyNy5cxvN+fbwww9zxBGZpx1MN6aTSbrWzYAB4xq9Hzwzzbly02x3nKRvS6pKbRJltm2Q+R1ZPQqMCc/HEE0JlCo/UZG9gOWh2+5p4EBJm4YMvQOBp8NrKyTtFTLrTowdyxVJfOzm3HM3o3///vWvrVq1KmsAgtzmn0tJ17rxpRqcK3+5dMf9HzBE0jZEXVqPAHcTpVNnJOkeolZMD0nzibLcrgTul3QqUZfeMWH3J8LxZhGlaJ8MYGZfhJVd/x72u8zMUskOv6AhRftJPDOuqOKtmOOPh4ULG3JQmsuUb+iCy61XN1vrxjPTnCtvuQShOjOrkTQKuNHMbpT0ZnNvMrPjMry0f5p9DTgjw3FuB25PUz4N+E5z9XCFkWrFxGdAAHjttb5Z39e0Cy6dTp02o7JyI7/vxrkOIJfsuLWSjiPqPns8lHUuXJVcOViz5uN1AtDkydnHdaD5LriKig3YYotj6rdra1fx4YdjG6VrZ0vhzjW92zlXGnJpCZ0M/AwYZ2ZzJPUHJha2Wq5UpbrS4gGoVy+4++7UVmW6t9XLlj5dVdWXzTY7hEWLJtQHqpqaJbH3fsyMGScjCbNv6stSN6gCJXHzqnMud7lkx70PnBXbngNcVchKudK0ePEk3n//ZPbbr2GNoAsugAMOiO/V/FLf2ab7mTKlXzPJCmtpOuQUv0HVl1VwrrzkMm3PHKIpcxoxswEFqZErWW+88UsOP7whAE2cCH36NN4nylTLrLm06tbeaJrtfX7zqnOlK5fuuPiEdesDPwa6F6Y6LknZJuJ85ZVXOPzwpfX7Pv88VDQZUczlHp1MN7nG1yDKNWsuLpXC7TevOldecumOW9Kk6HpJ04GLC1Mll4Rsk4F+9FFfvv/979fvG58DroHWWU8ok2xp1elaSo11bjQmBI2Dn9+86lx5yaU7btfYZgVRyyiXFpQrI5kmA73++rO48sqGe4DSByAAY8mSJ9pcj6YtpU6dumMGtbVf1Lea4q+nS+H2ZRWcKx/NricUpupJqSFaB+hqM5tZwHoVjK8nlF51dQVNh/7iGXD33Xcf++67lhkzTgbWkpn8y9+5diix9YTC8g2unWs6FhMPQA899BBHHtmwUsaMGWPInAVnbU6N9kXinOs4cpk7rpuka1NLIUi6RlK3YlTOFU9qaYba2sYB6PnnxzUKQD17jmbw4AnrLOPQVGvX9WnJUg7OufKXy4wJtwMrieZ5OwZYAdxRyEq54uvZczR9+/6JH/ygoWzOnNvZb78L0u4bnzg0k9akRvtCdc51LLkkGHzbzI6KbV8q6a1CVcglY8mSJYwefVv9dl1d3ToL08XFM9ymTOmXt9RoX6jOuY4ll5bQV5L2SW1I2hv4qnBVcsX2zDPP0KNHD6ZNe4PLL+/B5Mli6tT+OXeBNbfKakvksmy4c679yCUI/Qz4s6S5kj4G/hTKXDtw/fXXc9BBBwFwwQVin30+p6VjMflc1yefAc05V/qaTdGu31HaGMDMVhS0RgXmKdoNHnzwQY46KuppvfrqLdhtt0/X2aeqqi8DBowraraaZ8c5V3oKlaKdy31CVcBRRCuq1o8hmdll+a5MMXgQihadu+yyy7j00ksZMmQIEydOZOHCwaSZIhCIWiJNZyFoywqmHmScKz+FCkK5dMc9AhxBdKPq6tjDlaHa2lrGjh3LJZdcwvDhw3nxxRcZNGhQljGXyrxmq3kKtnMuLpfsuD5mNrLgNXEF99lnn9G/f39Wr17N2WefzdVXX01FmIU00+zWmeZwa222WrYUbG8NOdfx5NISek3SjgWviSuot99+my222ILVq1dzwQUXcO65u/H66wPqVyAF0iYXZFqaobXZap6C7ZyLy9gSkvQuUBf2OVnSbGAN0d2JZmY7FaeKrq1mzJjBzjvvDMCpp57KWWdtn3bG7EGDxjN06FwgPm7zMeFXXn+8tmSrZV7UzlOwneuIsnXH9QZ2KVZFXOtlG+ivrq5m1KhRrLfeetxwww0ceeRGaed+i3eJNV3WIQpAUSBKZcu1tuusuUXtnHMdS7YgNMfMWr66mCuqbOsAPf+8GD16NP379+fNN9+kS5dXw2vpJx9NdYmlG7dJBaBUS6m1mlvUzjnXsWQLQltI+s9ML5rZtQWoj2uhdAGjtvZLfv7zn/HQQ6sYNmwYkyZNok+fPkyZMjzLYnHx1Ukzj9s07qarBGrrW0ep+jQXXLItauec61iyBaFKYCOyzVDpEtc0YKxZAyNHAqxiv/3244knnqCqqirtvnHxLrFM4zaVld2bdKXVhuN+zIwZJzda8bStyzk45zqGbEFoYbnekNqRxAPG6tVw2GENrz377LP1KdhN922sstHNp5nGbaSolZXeWpre9+yp18655mRL0fYWUBlIzbX22Wdw1llR2Y47VrBo0V2NAlB837iKig0YPHhCo0CRaS64mpovaClPvXbOZZOtJbR/0WrhWq1nz9GYGQcddCIVFcZ1123Bccddm3EsBlo/btMwFpQ7T712zmWTMQiZWcv/7M2RpLlEC+XVAjVmNkRSd+A+ojnq5gLHmNlSRYva/BE4BPgSOMnM/hGOMwa4KBz2CjObUKg6l7Itt/wPbrmllu23357dd989675tSQpI103XoHOjMSHw1GvnXPNymTGhUEaY2S6xCfHOA543s4HA82Eb4GBgYHicBtwMEILW74A9gT2A30natIj1LyljxoxpNgC1VeNuOohyV6KZtgcPvoPttrs9L8s5OOc6jlzmjiuWI4Dh4fkEoBo4N5TfadF031MlbSKpV9j32VSLTdKzwEjgnuJWu2NpriXlQcc51xJJtYQMeEbSdEmnhbKeZrYwPF8E9AzPewPzYu+dH8oylTvnnCsTSbWE9jGzBZK2AJ6V9EH8RTMzSbmttpeDEOhOA9h6ax8od865UpFIS8jMFoSfnwIPEY3pLA7dbISfqWU+FwBbxd7eJ5RlKk93vvFmNsTMhmy++eb5vBTnnHNtUPQgJGlDSV1Tz4EDgXeBR4ExYbcxRIvpEcpPVGQvYHnotnsaOFDSpiEh4cBQ5pxzrkwk0R3XE3goyrymE3C3mT0l6e/A/ZJOBT4Gjgn7P0GUnj2LKEX7ZIhSyCVdDvw97HdZIdPKnXPO5Z+s6Vwr7dyQIUNs2rRpSVfDOefKiqTpsVtq8ibJ+4Scc851cB6EnHPOJcaDkHPOucR4EHLOOZcYD0LOOecS40HIOedcYjwIOeecS4wHIeecc4nxIOSccy4xHoScc84lxoOQc865xHgQcs45lxgPQs455xLjQcg551xiPAg555xLjAch55xzifEg5JxzLjEehJxzziXGg5BzzrnEeBByzjmXGA9CzjnnEuNByDnnXGI8CDnnnEuMByHnnHOJ8SDknHMuMR6EnHPOJcaDkHPOucR4EHLOOZcYmVnSdSgqSZ8BHyddjzzpAXyedCUKrL1fY3u/PvBrbC8GmVnXfB+0U74PWOrMbPOk65AvkqaZ2ZCk61FI7f0a2/v1gV9jeyFpWiGO691xzjnnEuNByDnnXGI8CJW38UlXoAja+zW29+sDv8b2oiDX2OESE5xzzpUObwk555xLjAch55xzifEgVGIkzZX0jqS3UimRkrpLelbSR+HnpqFckm6QNEvS25J2jR1nTNj/I0ljkrqeUJfbJX0q6d1YWd6uSdJu4TObFd6r4l5hxmu8RNKC8Lt8S9IhsdfOD/WdKemgWPnIUDZL0nmx8v6SXg/l90lar3hXB5K2kjRZ0vuS3pM0NpS3m99jlmtsT7/H9SW9Iemf4RovzVYvSVVhe1Z4vV/sWC269ozMzB8l9ADmAj2alP0eOC88Pw+4Kjw/BHgSELAX8Hoo7w7MDj83Dc83TfCahgG7Au8W4pqAN8K+Cu89uESu8RLgnDT7bg/8E6gC+gP/AirD41/AAGC9sM/24T33A8eG57cAPy/y9fUCdg3PuwIfhutoN7/HLNfYnn6PAjYKzzsDr4fPPG29gF8At4TnxwL3tfbaMz28JVQejgAmhOcTgCNj5XdaZCqwiaRewEHAs2b2hZktBZ4FRha70ilm9hLwRZPivFxTeG1jM5tq0f+OO2PHKpoM15jJEcC9ZrbGzOYAs4A9wmOWmc02s2+Ae4EjQotgP+CB8P7451UUZrbQzP4Rnq8EZgC9aUe/xyzXmEk5/h7NzFaFzc7hYVnqFf/9PgDsH66jRdeerU4ehEqPAc9Imi7ptFDW08wWhueLgJ7heW9gXuy980NZpvJSkq9r6h2eNy0vFWeG7qjbU11VtPwaNwOWmVlNk/JEhC6Z7xL9Fd0uf49NrhHa0e9RUqWkt4BPif4I+FeWetVfS3h9OdF15O27x4NQ6dnHzHYFDgbOkDQs/mL4K7Fd5dW3x2sKbga+DewCLASuSbY6bSdpI+D/gF+Z2Yr4a+3l95jmGtvV79HMas1sF6APUctluyTr40GoxJjZgvDzU+Ahon8ki0N3BeHnp2H3BcBWsbf3CWWZyktJvq5pQXjetDxxZrY4/IevA24l+l1Cy69xCVF3Vqcm5UUlqTPRl/MkM3swFLer32O6a2xvv8cUM1sGTAaGZqlX/bWE17sRXUfevns8CJUQSRtK6pp6DhwIvAs8CqSyiMYAj4TnjwInhkykvYDloWvkaeBASZuGroMDQ1kpycs1hddWSNor9FWfGDtWolJfzsEoot8lRNd4bMg86g8MJBqU/zswMGQqrUc0EPxoaGFMBo4O749/XkURPtvbgBlmdm3spXbze8x0je3s97i5pE3C8y7AAURjX5nqFf/9Hg28EK6jRdeetVKFysLwR6syVwYQZZP8E3gPuDCUbwY8D3wEPAd0t4ZMlz8T9em+AwyJHesUosHCWcDJCV/XPUTdGGuJ+ohPzec1AUOIvhj+BfyJMBNICVzjxHANb4f/iL1i+18Y6juTWBYYUVbZh+G1C5v823gjXPtfgaoiX98+RF1tbwNvhcch7en3mOUa29PvcSfgzXAt7wIXZ6sXsH7YnhVeH9Daa8/08Gl7nHPOJca745xzziXGg5BzzrnEeBByzjmXGA9CzjnnEuNByDnnXGI8CLmyJGkzNcxqvEgNsxwvk/R+0vXLRtKqDOW14RreC7Mc/1pS1v+jkoZLejw8P0nSn1pZpx1jn+cXkuaE58+15njO5apT87s4V3rMbAnRNCpIugRYZWZXhzm/Hk+uZm3ylUXTqSBpC+BuYGPgd4U4maROFuYLM7N3aPg8/wI8bmYPZNrfuXzxlpBrjyol3RpaFM+EO8ORtIukqWEiyofUsPZNtaQh4XkPSXPD8x0Urb3yVnjPwFD+sKIJZt9TwySzSFolaVxoxUyV1DOU95c0RdFaOVfkcgEWTdt0GtHEmVK0Dswd4RhvShqR7f2Sfqho/Zc3JT0Xq8slkiZKepXoJsyswmdzvaK1rcZK+ouko2Ovr4o9/42kv4fP6tJcrtM5D0KuPRoI/NnMdgCWAUeF8juBc81sJ6I74JtrYfwM+GNonQyhYZbnU8xst1B2lqTNQvmGwFQz2xl4CfhpKP8jcLOZ7Ug0q0JOzGw20fosWwBnREW2I3AcMEHS+lne/gqwl5l9l2g6/d/GXtse+IGZHZdjVdYzsyFmlnHiTkkHEn3uexC1qHZTk8l3nUvHg5Brj+aY2Vvh+XSgn6RuwCZm9mIon0C0EF02U4ALJJ0L9DWzr0L5WZL+CUwlmqxxYCj/hoauwOlAv/B8b6JpfSCH1kcG+wB3AZjZB8DHwLZZ9u8DPC3pHeA3wA6x1x6NXUsu7sthnwPD403gH0QzMw/M+g7n8DEh1z6tiT2vBbo0s38NDX+Q1bcuzOxuSa8DhwJPSDodqAN+AAw1sy8lVcfes9Ya5sGqpfH/rxbPjyVpQDjOp83tm8aNwLVm9qik4USrg6asbuGx4vvXf1YhaSK1PLWA/2dm/9OKuroOzFtCrkMws+XAUknfD0UnAKlW0Vxgt/A8Pt4xAJhtZjcQzSq8E9FU9ktDANqOaGnk5rxKNJswwOhc6itpc6Jllv8UAtvLqfdK2hbYmmjiyEy60TCF/pgs+7XUXBo+q8OJVuaEaHbsUxStxYOk3iG5wrmsPAi5jmQM8AdJbxONW1wWyq8Gfi7pTaBHbP9jgHcVrUL5HaIxpaeATpJmAFcSdck1ZyzRAoXvkH2VyS6pFG2iGamfAVID/DcBFeEY9wEnmdmaDMeBqOXzV0nTgc9zqGOubgX2Dd2RQwmtJDN7hiibb0qo4wNA1zye17VTPou2c865xHhLyDnnXGI8CDnnnEuMByHnnHOJ8SDknHMuMR6EnHPOJcaDkHPOucR4EHLOOZeY/w+enML2p9RH7gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaOcloKN_9o5",
        "outputId": "7ded2297-bc92-460a-c134-ad1f0339d90b"
      },
      "source": [
        "print(f\"AT LEAST FIND On Eveluation Average using RELU is {np.average(all_scores_K_relu)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Eveluation Average using RELU is 1451.5171813964844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azc_S84EStBZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}