{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Car_predictions_Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc-dLE2s9z-V"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yapWvdmbv6XQ"
      },
      "source": [
        "# **Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3FzYFJq98nD",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "73c4a80a-2def-4f6c-84f6-20514a0405f1"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7d26a05a-c5b9-4447-8fdb-72e5194ee489\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7d26a05a-c5b9-4447-8fdb-72e5194ee489\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving CarPrice_Assignment.csv to CarPrice_Assignment.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsy54TK--EWT"
      },
      "source": [
        "data = pd.read_csv(\"CarPrice_Assignment.csv\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpsyqP1W-UNu"
      },
      "source": [
        "**Checking for Null in Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhuR5xEc-SFT",
        "outputId": "33dc0ca0-7479-4288-fdf5-3a45bf516763"
      },
      "source": [
        "data.isnull().any()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "car_ID              False\n",
              "symboling           False\n",
              "CarName             False\n",
              "fueltype            False\n",
              "aspiration          False\n",
              "doornumber          False\n",
              "carbody             False\n",
              "drivewheel          False\n",
              "enginelocation      False\n",
              "wheelbase           False\n",
              "carlength           False\n",
              "carwidth            False\n",
              "carheight           False\n",
              "curbweight          False\n",
              "enginetype          False\n",
              "cylindernumber      False\n",
              "enginesize          False\n",
              "fuelsystem          False\n",
              "boreratio           False\n",
              "stroke              False\n",
              "compressionratio    False\n",
              "horsepower          False\n",
              "peakrpm             False\n",
              "citympg             False\n",
              "highwaympg          False\n",
              "price               False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxho0hkiwGO2"
      },
      "source": [
        "# **Removing and seprating labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcZ_kHRv-nW4"
      },
      "source": [
        "del data['car_ID']\n",
        "labels = data.pop('price')\n",
        "labels.astype('int16')\n",
        "data.loc[3,'CarName'] = 'audi 100ls'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFYSdxkNwduI"
      },
      "source": [
        "# **Checking objects datatypes in dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZtOQ6Uc-7Bj",
        "outputId": "39f77548-e726-4a98-9256-96d27021e2b8"
      },
      "source": [
        "data_with_object_dtype = data.dtypes[data.dtypes == 'object']\n",
        "data_with_object_dtype = list(data_with_object_dtype.keys())\n",
        "data_with_object_dtype"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CarName',\n",
              " 'fueltype',\n",
              " 'aspiration',\n",
              " 'doornumber',\n",
              " 'carbody',\n",
              " 'drivewheel',\n",
              " 'enginelocation',\n",
              " 'enginetype',\n",
              " 'cylindernumber',\n",
              " 'fuelsystem']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gBeYUInxW5C"
      },
      "source": [
        "## **One Hot Encode and vertorizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8lrDVia_oPd"
      },
      "source": [
        "New_data = pd.get_dummies(data, columns=data_with_object_dtype)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "zSpBOPfWAYj8",
        "outputId": "8268b8e5-6547-491f-bd51-341efcfc2c51"
      },
      "source": [
        "New_data.iloc[:,1:14] -= (New_data.iloc[:,1:14]).mean()\n",
        "New_data.iloc[:,1:14] /= (New_data.iloc[:,1:14]).std()\n",
        "New_data.iloc[:,1:14]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wheelbase</th>\n",
              "      <th>carlength</th>\n",
              "      <th>carwidth</th>\n",
              "      <th>carheight</th>\n",
              "      <th>curbweight</th>\n",
              "      <th>enginesize</th>\n",
              "      <th>boreratio</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compressionratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peakrpm</th>\n",
              "      <th>citympg</th>\n",
              "      <th>highwaympg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.686643</td>\n",
              "      <td>-0.425480</td>\n",
              "      <td>-0.842719</td>\n",
              "      <td>-2.015483</td>\n",
              "      <td>-0.014531</td>\n",
              "      <td>0.074267</td>\n",
              "      <td>0.517804</td>\n",
              "      <td>-1.834886</td>\n",
              "      <td>-0.287645</td>\n",
              "      <td>0.174057</td>\n",
              "      <td>-0.262318</td>\n",
              "      <td>-0.644974</td>\n",
              "      <td>-0.544725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.686643</td>\n",
              "      <td>-0.425480</td>\n",
              "      <td>-0.842719</td>\n",
              "      <td>-2.015483</td>\n",
              "      <td>-0.014531</td>\n",
              "      <td>0.074267</td>\n",
              "      <td>0.517804</td>\n",
              "      <td>-1.834886</td>\n",
              "      <td>-0.287645</td>\n",
              "      <td>0.174057</td>\n",
              "      <td>-0.262318</td>\n",
              "      <td>-0.644974</td>\n",
              "      <td>-0.544725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.706865</td>\n",
              "      <td>-0.230948</td>\n",
              "      <td>-0.190101</td>\n",
              "      <td>-0.542200</td>\n",
              "      <td>0.513625</td>\n",
              "      <td>0.602571</td>\n",
              "      <td>-2.399008</td>\n",
              "      <td>0.684271</td>\n",
              "      <td>-0.287645</td>\n",
              "      <td>1.261448</td>\n",
              "      <td>-0.262318</td>\n",
              "      <td>-0.950684</td>\n",
              "      <td>-0.689938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.173274</td>\n",
              "      <td>0.206750</td>\n",
              "      <td>0.136209</td>\n",
              "      <td>0.235366</td>\n",
              "      <td>-0.419770</td>\n",
              "      <td>-0.430023</td>\n",
              "      <td>-0.516003</td>\n",
              "      <td>0.461055</td>\n",
              "      <td>-0.035885</td>\n",
              "      <td>-0.053537</td>\n",
              "      <td>0.785932</td>\n",
              "      <td>-0.186409</td>\n",
              "      <td>-0.109087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.106848</td>\n",
              "      <td>0.206750</td>\n",
              "      <td>0.229440</td>\n",
              "      <td>0.235366</td>\n",
              "      <td>0.515545</td>\n",
              "      <td>0.218350</td>\n",
              "      <td>-0.516003</td>\n",
              "      <td>0.461055</td>\n",
              "      <td>-0.539405</td>\n",
              "      <td>0.275209</td>\n",
              "      <td>0.785932</td>\n",
              "      <td>-1.103540</td>\n",
              "      <td>-1.270789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>1.717669</td>\n",
              "      <td>1.195622</td>\n",
              "      <td>1.394830</td>\n",
              "      <td>0.726460</td>\n",
              "      <td>0.761377</td>\n",
              "      <td>0.338419</td>\n",
              "      <td>1.662375</td>\n",
              "      <td>-0.336147</td>\n",
              "      <td>-0.161765</td>\n",
              "      <td>0.249921</td>\n",
              "      <td>0.576282</td>\n",
              "      <td>-0.339264</td>\n",
              "      <td>-0.399512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>1.717669</td>\n",
              "      <td>1.195622</td>\n",
              "      <td>1.348215</td>\n",
              "      <td>0.726460</td>\n",
              "      <td>0.947672</td>\n",
              "      <td>0.338419</td>\n",
              "      <td>1.662375</td>\n",
              "      <td>-0.336147</td>\n",
              "      <td>-0.363173</td>\n",
              "      <td>1.413178</td>\n",
              "      <td>0.366632</td>\n",
              "      <td>-0.950684</td>\n",
              "      <td>-0.835151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>1.717669</td>\n",
              "      <td>1.195622</td>\n",
              "      <td>1.394830</td>\n",
              "      <td>0.726460</td>\n",
              "      <td>0.876611</td>\n",
              "      <td>1.106861</td>\n",
              "      <td>0.923942</td>\n",
              "      <td>-1.229012</td>\n",
              "      <td>-0.337997</td>\n",
              "      <td>0.755685</td>\n",
              "      <td>0.785932</td>\n",
              "      <td>-1.103540</td>\n",
              "      <td>-1.125577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>1.717669</td>\n",
              "      <td>1.195622</td>\n",
              "      <td>1.394830</td>\n",
              "      <td>0.726460</td>\n",
              "      <td>1.270327</td>\n",
              "      <td>0.434474</td>\n",
              "      <td>-1.180593</td>\n",
              "      <td>0.461055</td>\n",
              "      <td>3.236992</td>\n",
              "      <td>0.047616</td>\n",
              "      <td>-0.681618</td>\n",
              "      <td>0.119302</td>\n",
              "      <td>-0.544725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>1.717669</td>\n",
              "      <td>1.195622</td>\n",
              "      <td>1.394830</td>\n",
              "      <td>0.726460</td>\n",
              "      <td>0.972640</td>\n",
              "      <td>0.338419</td>\n",
              "      <td>1.662375</td>\n",
              "      <td>-0.336147</td>\n",
              "      <td>-0.161765</td>\n",
              "      <td>0.249921</td>\n",
              "      <td>0.576282</td>\n",
              "      <td>-0.950684</td>\n",
              "      <td>-0.835151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>205 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     wheelbase  carlength  carwidth  ...   peakrpm   citympg  highwaympg\n",
              "0    -1.686643  -0.425480 -0.842719  ... -0.262318 -0.644974   -0.544725\n",
              "1    -1.686643  -0.425480 -0.842719  ... -0.262318 -0.644974   -0.544725\n",
              "2    -0.706865  -0.230948 -0.190101  ... -0.262318 -0.950684   -0.689938\n",
              "3     0.173274   0.206750  0.136209  ...  0.785932 -0.186409   -0.109087\n",
              "4     0.106848   0.206750  0.229440  ...  0.785932 -1.103540   -1.270789\n",
              "..         ...        ...       ...  ...       ...       ...         ...\n",
              "200   1.717669   1.195622  1.394830  ...  0.576282 -0.339264   -0.399512\n",
              "201   1.717669   1.195622  1.348215  ...  0.366632 -0.950684   -0.835151\n",
              "202   1.717669   1.195622  1.394830  ...  0.785932 -1.103540   -1.125577\n",
              "203   1.717669   1.195622  1.394830  ... -0.681618  0.119302   -0.544725\n",
              "204   1.717669   1.195622  1.394830  ...  0.576282 -0.950684   -0.835151\n",
              "\n",
              "[205 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oam5mLdCcn-"
      },
      "source": [
        "data_len = len(New_data)\n",
        "train_data = New_data.iloc[:data_len*70//100]\n",
        "test_data = New_data.iloc[data_len*70//100:]\n",
        "\n",
        "labels_len = len(labels)\n",
        "train_labels = labels.iloc[:labels_len*70//100]\n",
        "test_labels = labels.iloc[labels_len*70//100:]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "50o3fR2xOnzC",
        "outputId": "61987474-2709-46bf-8169-fe54da0fe672"
      },
      "source": [
        "New_data.describe()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symboling</th>\n",
              "      <th>wheelbase</th>\n",
              "      <th>carlength</th>\n",
              "      <th>carwidth</th>\n",
              "      <th>carheight</th>\n",
              "      <th>curbweight</th>\n",
              "      <th>enginesize</th>\n",
              "      <th>boreratio</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compressionratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peakrpm</th>\n",
              "      <th>citympg</th>\n",
              "      <th>highwaympg</th>\n",
              "      <th>CarName_Nissan versa</th>\n",
              "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
              "      <th>CarName_alfa-romero giulia</th>\n",
              "      <th>CarName_alfa-romero stelvio</th>\n",
              "      <th>CarName_audi 100ls</th>\n",
              "      <th>CarName_audi 4000</th>\n",
              "      <th>CarName_audi 5000</th>\n",
              "      <th>CarName_audi 5000s (diesel)</th>\n",
              "      <th>CarName_audi fox</th>\n",
              "      <th>CarName_bmw 320i</th>\n",
              "      <th>CarName_bmw x1</th>\n",
              "      <th>CarName_bmw x3</th>\n",
              "      <th>CarName_bmw x4</th>\n",
              "      <th>CarName_bmw x5</th>\n",
              "      <th>CarName_bmw z4</th>\n",
              "      <th>CarName_buick century</th>\n",
              "      <th>CarName_buick century luxus (sw)</th>\n",
              "      <th>CarName_buick century special</th>\n",
              "      <th>CarName_buick electra 225 custom</th>\n",
              "      <th>CarName_buick opel isuzu deluxe</th>\n",
              "      <th>CarName_buick regal sport coupe (turbo)</th>\n",
              "      <th>CarName_buick skyhawk</th>\n",
              "      <th>CarName_buick skylark</th>\n",
              "      <th>CarName_chevrolet impala</th>\n",
              "      <th>CarName_chevrolet monte carlo</th>\n",
              "      <th>CarName_chevrolet vega 2300</th>\n",
              "      <th>...</th>\n",
              "      <th>CarName_vw dasher</th>\n",
              "      <th>CarName_vw rabbit</th>\n",
              "      <th>fueltype_diesel</th>\n",
              "      <th>fueltype_gas</th>\n",
              "      <th>aspiration_std</th>\n",
              "      <th>aspiration_turbo</th>\n",
              "      <th>doornumber_four</th>\n",
              "      <th>doornumber_two</th>\n",
              "      <th>carbody_convertible</th>\n",
              "      <th>carbody_hardtop</th>\n",
              "      <th>carbody_hatchback</th>\n",
              "      <th>carbody_sedan</th>\n",
              "      <th>carbody_wagon</th>\n",
              "      <th>drivewheel_4wd</th>\n",
              "      <th>drivewheel_fwd</th>\n",
              "      <th>drivewheel_rwd</th>\n",
              "      <th>enginelocation_front</th>\n",
              "      <th>enginelocation_rear</th>\n",
              "      <th>enginetype_dohc</th>\n",
              "      <th>enginetype_dohcv</th>\n",
              "      <th>enginetype_l</th>\n",
              "      <th>enginetype_ohc</th>\n",
              "      <th>enginetype_ohcf</th>\n",
              "      <th>enginetype_ohcv</th>\n",
              "      <th>enginetype_rotor</th>\n",
              "      <th>cylindernumber_eight</th>\n",
              "      <th>cylindernumber_five</th>\n",
              "      <th>cylindernumber_four</th>\n",
              "      <th>cylindernumber_six</th>\n",
              "      <th>cylindernumber_three</th>\n",
              "      <th>cylindernumber_twelve</th>\n",
              "      <th>cylindernumber_two</th>\n",
              "      <th>fuelsystem_1bbl</th>\n",
              "      <th>fuelsystem_2bbl</th>\n",
              "      <th>fuelsystem_4bbl</th>\n",
              "      <th>fuelsystem_idi</th>\n",
              "      <th>fuelsystem_mfi</th>\n",
              "      <th>fuelsystem_mpfi</th>\n",
              "      <th>fuelsystem_spdi</th>\n",
              "      <th>fuelsystem_spfi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>205.000000</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>2.050000e+02</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.834146</td>\n",
              "      <td>-2.017898e-14</td>\n",
              "      <td>-1.011440e-14</td>\n",
              "      <td>1.431700e-14</td>\n",
              "      <td>-1.499613e-14</td>\n",
              "      <td>1.261863e-16</td>\n",
              "      <td>4.034713e-17</td>\n",
              "      <td>-5.910719e-15</td>\n",
              "      <td>1.766473e-14</td>\n",
              "      <td>-5.315531e-16</td>\n",
              "      <td>1.775003e-16</td>\n",
              "      <td>3.103209e-16</td>\n",
              "      <td>1.223953e-16</td>\n",
              "      <td>1.792604e-16</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.014634</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.009756</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.009756</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.902439</td>\n",
              "      <td>0.819512</td>\n",
              "      <td>0.180488</td>\n",
              "      <td>0.560976</td>\n",
              "      <td>0.439024</td>\n",
              "      <td>0.029268</td>\n",
              "      <td>0.039024</td>\n",
              "      <td>0.341463</td>\n",
              "      <td>0.468293</td>\n",
              "      <td>0.121951</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.585366</td>\n",
              "      <td>0.370732</td>\n",
              "      <td>0.985366</td>\n",
              "      <td>0.014634</td>\n",
              "      <td>0.058537</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.058537</td>\n",
              "      <td>0.721951</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>0.063415</td>\n",
              "      <td>0.019512</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.053659</td>\n",
              "      <td>0.775610</td>\n",
              "      <td>0.117073</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.019512</td>\n",
              "      <td>0.053659</td>\n",
              "      <td>0.321951</td>\n",
              "      <td>0.014634</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.458537</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.004878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.245307</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.120377</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.098531</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.098531</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>...</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.297446</td>\n",
              "      <td>0.297446</td>\n",
              "      <td>0.385535</td>\n",
              "      <td>0.385535</td>\n",
              "      <td>0.497483</td>\n",
              "      <td>0.497483</td>\n",
              "      <td>0.168970</td>\n",
              "      <td>0.194127</td>\n",
              "      <td>0.475361</td>\n",
              "      <td>0.500215</td>\n",
              "      <td>0.328031</td>\n",
              "      <td>0.205380</td>\n",
              "      <td>0.493865</td>\n",
              "      <td>0.484183</td>\n",
              "      <td>0.120377</td>\n",
              "      <td>0.120377</td>\n",
              "      <td>0.235330</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.235330</td>\n",
              "      <td>0.449134</td>\n",
              "      <td>0.261054</td>\n",
              "      <td>0.244304</td>\n",
              "      <td>0.138655</td>\n",
              "      <td>0.154635</td>\n",
              "      <td>0.225894</td>\n",
              "      <td>0.418201</td>\n",
              "      <td>0.322294</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.138655</td>\n",
              "      <td>0.225894</td>\n",
              "      <td>0.468368</td>\n",
              "      <td>0.120377</td>\n",
              "      <td>0.297446</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.499498</td>\n",
              "      <td>0.205380</td>\n",
              "      <td>0.069843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-2.018771e+00</td>\n",
              "      <td>-2.670706e+00</td>\n",
              "      <td>-2.614113e+00</td>\n",
              "      <td>-2.424729e+00</td>\n",
              "      <td>-2.050329e+00</td>\n",
              "      <td>-1.582686e+00</td>\n",
              "      <td>-2.915911e+00</td>\n",
              "      <td>-3.780057e+00</td>\n",
              "      <td>-7.911643e-01</td>\n",
              "      <td>-1.419099e+00</td>\n",
              "      <td>-2.044342e+00</td>\n",
              "      <td>-1.867815e+00</td>\n",
              "      <td>-2.142067e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-7.068655e-01</td>\n",
              "      <td>-6.281176e-01</td>\n",
              "      <td>-8.427194e-01</td>\n",
              "      <td>-7.058983e-01</td>\n",
              "      <td>-7.885183e-01</td>\n",
              "      <td>-7.181888e-01</td>\n",
              "      <td>-6.636894e-01</td>\n",
              "      <td>-4.636990e-01</td>\n",
              "      <td>-3.883487e-01</td>\n",
              "      <td>-8.627587e-01</td>\n",
              "      <td>-6.816179e-01</td>\n",
              "      <td>-9.506844e-01</td>\n",
              "      <td>-8.351509e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-2.917055e-01</td>\n",
              "      <td>-6.883752e-02</td>\n",
              "      <td>-1.901008e-01</td>\n",
              "      <td>1.535169e-01</td>\n",
              "      <td>-2.718864e-01</td>\n",
              "      <td>-1.658710e-01</td>\n",
              "      <td>-7.294280e-02</td>\n",
              "      <td>1.102860e-01</td>\n",
              "      <td>-2.876448e-01</td>\n",
              "      <td>-2.305542e-01</td>\n",
              "      <td>1.569818e-01</td>\n",
              "      <td>-1.864087e-01</td>\n",
              "      <td>-1.090867e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.050399e-01</td>\n",
              "      <td>7.336078e-01</td>\n",
              "      <td>4.625179e-01</td>\n",
              "      <td>7.264604e-01</td>\n",
              "      <td>7.287278e-01</td>\n",
              "      <td>3.384191e-01</td>\n",
              "      <td>9.239421e-01</td>\n",
              "      <td>4.929427e-01</td>\n",
              "      <td>-1.869408e-01</td>\n",
              "      <td>3.004976e-01</td>\n",
              "      <td>7.859315e-01</td>\n",
              "      <td>7.307221e-01</td>\n",
              "      <td>4.717647e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.677223e+00</td>\n",
              "      <td>2.759985e+00</td>\n",
              "      <td>2.979761e+00</td>\n",
              "      <td>2.486215e+00</td>\n",
              "      <td>2.900886e+00</td>\n",
              "      <td>4.780975e+00</td>\n",
              "      <td>2.253122e+00</td>\n",
              "      <td>2.916435e+00</td>\n",
              "      <td>3.236992e+00</td>\n",
              "      <td>4.650065e+00</td>\n",
              "      <td>3.092081e+00</td>\n",
              "      <td>3.634970e+00</td>\n",
              "      <td>3.376022e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 198 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        symboling     wheelbase  ...  fuelsystem_spdi  fuelsystem_spfi\n",
              "count  205.000000  2.050000e+02  ...       205.000000       205.000000\n",
              "mean     0.834146 -2.017898e-14  ...         0.043902         0.004878\n",
              "std      1.245307  1.000000e+00  ...         0.205380         0.069843\n",
              "min     -2.000000 -2.018771e+00  ...         0.000000         0.000000\n",
              "25%      0.000000 -7.068655e-01  ...         0.000000         0.000000\n",
              "50%      1.000000 -2.917055e-01  ...         0.000000         0.000000\n",
              "75%      2.000000  6.050399e-01  ...         0.000000         0.000000\n",
              "max      3.000000  3.677223e+00  ...         1.000000         1.000000\n",
              "\n",
              "[8 rows x 198 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3CYfRPqPf92"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "def Train_Me_with(activation_function=\"relu\"):\n",
        "  network = models.Sequential()\n",
        "  network.add(layers.Dense(24, activation=activation_function,input_shape=(train_data.shape[1],)))\n",
        "  network.add(layers.Dense(18, activation=activation_function))\n",
        "  network.add(layers.Dense(12, activation=activation_function))\n",
        "  network.add(layers.Dense(1))\n",
        "  network.compile(\n",
        "      optimizer=\"rmsprop\",\n",
        "      loss=\"mse\",\n",
        "      metrics=['mae']\n",
        "  )\n",
        "  return network"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjQBE9otVETt"
      },
      "source": [
        "# **MAE without K fold and with tanh**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXwUd1vURdbz",
        "outputId": "ac1770b5-7d5c-4043-8c04-b8013c987c50"
      },
      "source": [
        "Model_Results1 = Train_Me_with(activation_function=\"tanh\").fit(\n",
        "      train_data,train_labels,batch_size=32,epochs=500,validation_data=(test_data,test_labels)\n",
        "  )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 3s 73ms/step - loss: 281742960.0000 - mae: 14084.1309 - val_loss: 146551984.0000 - val_mae: 11350.7119\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 278465114.6667 - mae: 14100.9157 - val_loss: 146535856.0000 - val_mae: 11350.0264\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 271912408.0000 - mae: 13968.5311 - val_loss: 146522096.0000 - val_mae: 11349.4180\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 260589357.3333 - mae: 13738.5286 - val_loss: 146509776.0000 - val_mae: 11348.8672\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 278017621.3333 - mae: 14131.9033 - val_loss: 146499232.0000 - val_mae: 11348.3818\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 285466882.6667 - mae: 14134.2671 - val_loss: 146490400.0000 - val_mae: 11347.9717\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 318993922.6667 - mae: 15011.4875 - val_loss: 146483072.0000 - val_mae: 11347.6309\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 291403621.3333 - mae: 14488.1903 - val_loss: 146476928.0000 - val_mae: 11347.3428\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 294999626.6667 - mae: 14570.1483 - val_loss: 146471712.0000 - val_mae: 11347.0986\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 276957882.6667 - mae: 14126.1042 - val_loss: 146467296.0000 - val_mae: 11346.8965\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 258162330.6667 - mae: 13591.3136 - val_loss: 146463408.0000 - val_mae: 11346.7197\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 275322104.0000 - mae: 14043.2884 - val_loss: 146460160.0000 - val_mae: 11346.5703\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 261897669.3333 - mae: 13593.8359 - val_loss: 146457232.0000 - val_mae: 11346.4385\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 299754309.3333 - mae: 14471.0396 - val_loss: 146454592.0000 - val_mae: 11346.3184\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 253427466.6667 - mae: 13678.1097 - val_loss: 146452080.0000 - val_mae: 11346.2061\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 281281530.6667 - mae: 14032.0986 - val_loss: 146449872.0000 - val_mae: 11346.1064\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 259792544.0000 - mae: 13494.5044 - val_loss: 146447696.0000 - val_mae: 11346.0088\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 291137882.6667 - mae: 14419.4551 - val_loss: 146445680.0000 - val_mae: 11345.9189\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 303337477.3333 - mae: 14583.2225 - val_loss: 146443792.0000 - val_mae: 11345.8350\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 279053920.0000 - mae: 14083.2874 - val_loss: 146441952.0000 - val_mae: 11345.7529\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 262896802.6667 - mae: 13806.5493 - val_loss: 146440176.0000 - val_mae: 11345.6748\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 260144512.0000 - mae: 13722.7021 - val_loss: 146438416.0000 - val_mae: 11345.5947\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 282457405.3333 - mae: 14147.0739 - val_loss: 146436784.0000 - val_mae: 11345.5244\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 256511376.0000 - mae: 13625.0093 - val_loss: 146435104.0000 - val_mae: 11345.4492\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 270932418.6667 - mae: 13893.7157 - val_loss: 146433504.0000 - val_mae: 11345.3789\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 285805632.0000 - mae: 14087.8008 - val_loss: 146431888.0000 - val_mae: 11345.3066\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 281973509.3333 - mae: 13938.2598 - val_loss: 146430240.0000 - val_mae: 11345.2354\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 298361045.3333 - mae: 14467.1698 - val_loss: 146428704.0000 - val_mae: 11345.1670\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 275464629.3333 - mae: 13851.2466 - val_loss: 146427168.0000 - val_mae: 11345.0977\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 273045949.3333 - mae: 13837.2227 - val_loss: 146425584.0000 - val_mae: 11345.0293\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 290250218.6667 - mae: 14358.1431 - val_loss: 146424128.0000 - val_mae: 11344.9648\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 256212298.6667 - mae: 13437.7067 - val_loss: 146422608.0000 - val_mae: 11344.8975\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 262334096.0000 - mae: 13662.4512 - val_loss: 146421104.0000 - val_mae: 11344.8330\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 293144837.3333 - mae: 14559.3849 - val_loss: 146419680.0000 - val_mae: 11344.7686\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 278570229.3333 - mae: 13875.2438 - val_loss: 146418128.0000 - val_mae: 11344.7002\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 281256298.6667 - mae: 14214.9097 - val_loss: 146416624.0000 - val_mae: 11344.6338\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 278627322.6667 - mae: 14109.9388 - val_loss: 146415120.0000 - val_mae: 11344.5674\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 289115658.6667 - mae: 14276.9299 - val_loss: 146413632.0000 - val_mae: 11344.5020\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 281230906.6667 - mae: 14348.2603 - val_loss: 146412144.0000 - val_mae: 11344.4365\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 283590922.6667 - mae: 14180.6035 - val_loss: 146410624.0000 - val_mae: 11344.3701\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 273185805.3333 - mae: 13970.7145 - val_loss: 146409200.0000 - val_mae: 11344.3076\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 311596794.6667 - mae: 14785.0983 - val_loss: 146407760.0000 - val_mae: 11344.2432\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 285329968.0000 - mae: 14337.1685 - val_loss: 146406256.0000 - val_mae: 11344.1768\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 250834880.0000 - mae: 13315.1375 - val_loss: 146404720.0000 - val_mae: 11344.1084\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 269811272.0000 - mae: 13934.2240 - val_loss: 146403232.0000 - val_mae: 11344.0439\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 289276053.3333 - mae: 14328.8783 - val_loss: 146401776.0000 - val_mae: 11343.9795\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 303175546.6667 - mae: 14529.6120 - val_loss: 146400320.0000 - val_mae: 11343.9150\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 299187050.6667 - mae: 14468.4147 - val_loss: 146398880.0000 - val_mae: 11343.8525\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 265641397.3333 - mae: 13688.6951 - val_loss: 146397376.0000 - val_mae: 11343.7861\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 260645037.3333 - mae: 13536.8177 - val_loss: 146395856.0000 - val_mae: 11343.7197\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 289140474.6667 - mae: 14247.9800 - val_loss: 146394416.0000 - val_mae: 11343.6553\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 270958050.6667 - mae: 13815.9757 - val_loss: 146392960.0000 - val_mae: 11343.5908\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 298721413.3333 - mae: 14510.8104 - val_loss: 146391504.0000 - val_mae: 11343.5264\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 292238552.0000 - mae: 14353.5866 - val_loss: 146389984.0000 - val_mae: 11343.4600\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 283509205.3333 - mae: 14324.4829 - val_loss: 146388528.0000 - val_mae: 11343.3955\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 275656576.0000 - mae: 13966.6297 - val_loss: 146387072.0000 - val_mae: 11343.3311\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 271211792.0000 - mae: 13869.3918 - val_loss: 146385584.0000 - val_mae: 11343.2666\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 267567042.6667 - mae: 13805.6326 - val_loss: 146384080.0000 - val_mae: 11343.1992\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 271720058.6667 - mae: 14094.9959 - val_loss: 146382720.0000 - val_mae: 11343.1387\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 299377920.0000 - mae: 14426.6418 - val_loss: 146381264.0000 - val_mae: 11343.0742\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 270895165.3333 - mae: 13844.8506 - val_loss: 146379824.0000 - val_mae: 11343.0117\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 271772181.3333 - mae: 13880.5099 - val_loss: 146378320.0000 - val_mae: 11342.9463\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 278571789.3333 - mae: 14084.1768 - val_loss: 146376832.0000 - val_mae: 11342.8799\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 273467370.6667 - mae: 14186.7225 - val_loss: 146375344.0000 - val_mae: 11342.8154\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 287365802.6667 - mae: 14297.8888 - val_loss: 146373968.0000 - val_mae: 11342.7529\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 277007914.6667 - mae: 13937.6598 - val_loss: 146372448.0000 - val_mae: 11342.6865\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 286841490.6667 - mae: 14464.4565 - val_loss: 146371024.0000 - val_mae: 11342.6240\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 274262109.3333 - mae: 14068.6182 - val_loss: 146369584.0000 - val_mae: 11342.5615\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 277807554.6667 - mae: 13950.8534 - val_loss: 146368112.0000 - val_mae: 11342.4971\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 258343760.0000 - mae: 13632.4989 - val_loss: 146366576.0000 - val_mae: 11342.4287\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 278100133.3333 - mae: 13837.9671 - val_loss: 146365120.0000 - val_mae: 11342.3643\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 269023146.6667 - mae: 13849.8791 - val_loss: 146363680.0000 - val_mae: 11342.3008\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 272192237.3333 - mae: 13927.5337 - val_loss: 146362192.0000 - val_mae: 11342.2363\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 304445685.3333 - mae: 14573.1616 - val_loss: 146360752.0000 - val_mae: 11342.1709\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 277526064.0000 - mae: 14027.2178 - val_loss: 146359312.0000 - val_mae: 11342.1084\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 263972589.3333 - mae: 13821.7407 - val_loss: 146357808.0000 - val_mae: 11342.0420\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 283181477.3333 - mae: 14132.8395 - val_loss: 146356336.0000 - val_mae: 11341.9775\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 257671786.6667 - mae: 13648.2183 - val_loss: 146354832.0000 - val_mae: 11341.9111\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 293839365.3333 - mae: 14541.2663 - val_loss: 146353440.0000 - val_mae: 11341.8486\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 248283661.3333 - mae: 13415.4471 - val_loss: 146351968.0000 - val_mae: 11341.7842\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 304017626.6667 - mae: 14481.8141 - val_loss: 146350512.0000 - val_mae: 11341.7197\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 257048109.3333 - mae: 13465.0296 - val_loss: 146349024.0000 - val_mae: 11341.6553\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 272399013.3333 - mae: 13958.9173 - val_loss: 146347584.0000 - val_mae: 11341.5908\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 283520293.3333 - mae: 14112.0731 - val_loss: 146346080.0000 - val_mae: 11341.5244\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 273385154.6667 - mae: 13957.0615 - val_loss: 146344656.0000 - val_mae: 11341.4619\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 280976501.3333 - mae: 14128.5397 - val_loss: 146343184.0000 - val_mae: 11341.3975\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 305770981.3333 - mae: 14844.9300 - val_loss: 146341760.0000 - val_mae: 11341.3330\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285897626.6667 - mae: 14206.3926 - val_loss: 146340288.0000 - val_mae: 11341.2686\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 277798421.3333 - mae: 14170.7404 - val_loss: 146338816.0000 - val_mae: 11341.2041\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 289527594.6667 - mae: 14437.4023 - val_loss: 146337392.0000 - val_mae: 11341.1416\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 280155480.0000 - mae: 14144.6951 - val_loss: 146335856.0000 - val_mae: 11341.0723\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 253644496.0000 - mae: 13527.0762 - val_loss: 146334384.0000 - val_mae: 11341.0088\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 281861338.6667 - mae: 14129.0099 - val_loss: 146332912.0000 - val_mae: 11340.9443\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 260115877.3333 - mae: 13585.3745 - val_loss: 146331424.0000 - val_mae: 11340.8779\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 292289322.6667 - mae: 14318.4271 - val_loss: 146329968.0000 - val_mae: 11340.8135\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 264884186.6667 - mae: 13579.1419 - val_loss: 146328496.0000 - val_mae: 11340.7490\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 271437738.6667 - mae: 14001.3662 - val_loss: 146326992.0000 - val_mae: 11340.6826\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 275832328.0000 - mae: 14200.9525 - val_loss: 146325504.0000 - val_mae: 11340.6182\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 285490074.6667 - mae: 14293.0319 - val_loss: 146324080.0000 - val_mae: 11340.5537\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 252183237.3333 - mae: 13515.4805 - val_loss: 146322624.0000 - val_mae: 11340.4912\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 307559941.3333 - mae: 14641.9380 - val_loss: 146321184.0000 - val_mae: 11340.4268\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 296148888.0000 - mae: 14417.8332 - val_loss: 146319696.0000 - val_mae: 11340.3613\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 274271472.0000 - mae: 13995.7085 - val_loss: 146318256.0000 - val_mae: 11340.2988\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 254588640.0000 - mae: 13386.1388 - val_loss: 146316784.0000 - val_mae: 11340.2334\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 267374256.0000 - mae: 13790.0814 - val_loss: 146315296.0000 - val_mae: 11340.1670\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 277721133.3333 - mae: 14020.2697 - val_loss: 146313840.0000 - val_mae: 11340.1045\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 284288392.0000 - mae: 14037.8363 - val_loss: 146312352.0000 - val_mae: 11340.0381\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 273373154.6667 - mae: 13964.0887 - val_loss: 146310880.0000 - val_mae: 11339.9736\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 280926594.6667 - mae: 14157.5273 - val_loss: 146309504.0000 - val_mae: 11339.9111\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 293221045.3333 - mae: 14436.7845 - val_loss: 146308032.0000 - val_mae: 11339.8467\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 286199290.6667 - mae: 14157.2290 - val_loss: 146306560.0000 - val_mae: 11339.7822\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 273375525.3333 - mae: 13992.6839 - val_loss: 146305104.0000 - val_mae: 11339.7178\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 288060893.3333 - mae: 14333.5658 - val_loss: 146303632.0000 - val_mae: 11339.6533\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 265235221.3333 - mae: 13826.6011 - val_loss: 146302176.0000 - val_mae: 11339.5889\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 242902408.0000 - mae: 13104.1274 - val_loss: 146300704.0000 - val_mae: 11339.5244\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 272639330.6667 - mae: 14120.1670 - val_loss: 146299296.0000 - val_mae: 11339.4619\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 269893589.3333 - mae: 14021.3983 - val_loss: 146297808.0000 - val_mae: 11339.3955\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 276620632.0000 - mae: 14087.8678 - val_loss: 146296368.0000 - val_mae: 11339.3330\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 283647125.3333 - mae: 14138.0046 - val_loss: 146294912.0000 - val_mae: 11339.2686\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 300910373.3333 - mae: 14657.6494 - val_loss: 146293440.0000 - val_mae: 11339.2041\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 270034458.6667 - mae: 13970.8076 - val_loss: 146291936.0000 - val_mae: 11339.1367\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 277599618.6667 - mae: 13879.1600 - val_loss: 146290496.0000 - val_mae: 11339.0723\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 300106725.3333 - mae: 14445.6022 - val_loss: 146289040.0000 - val_mae: 11339.0088\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285506058.6667 - mae: 14188.4290 - val_loss: 146287568.0000 - val_mae: 11338.9443\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 281709120.0000 - mae: 14125.1921 - val_loss: 146286096.0000 - val_mae: 11338.8799\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 299601216.0000 - mae: 14475.4715 - val_loss: 146284640.0000 - val_mae: 11338.8154\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 261427682.6667 - mae: 13758.2594 - val_loss: 146283184.0000 - val_mae: 11338.7510\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 319757146.6667 - mae: 14974.5824 - val_loss: 146281776.0000 - val_mae: 11338.6885\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 264609986.6667 - mae: 13763.9956 - val_loss: 146280256.0000 - val_mae: 11338.6221\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 314649733.3333 - mae: 14763.4712 - val_loss: 146278800.0000 - val_mae: 11338.5576\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 248092237.3333 - mae: 13320.3537 - val_loss: 146277328.0000 - val_mae: 11338.4932\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 303198128.0000 - mae: 14798.8382 - val_loss: 146275888.0000 - val_mae: 11338.4307\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 283179802.6667 - mae: 14128.4539 - val_loss: 146274432.0000 - val_mae: 11338.3662\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 263823872.0000 - mae: 13720.3185 - val_loss: 146272928.0000 - val_mae: 11338.3008\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 261254717.3333 - mae: 13865.3525 - val_loss: 146271456.0000 - val_mae: 11338.2334\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 281886576.0000 - mae: 14051.8151 - val_loss: 146270048.0000 - val_mae: 11338.1709\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 241847714.6667 - mae: 13282.8939 - val_loss: 146268528.0000 - val_mae: 11338.1045\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 262085376.0000 - mae: 13797.5239 - val_loss: 146267088.0000 - val_mae: 11338.0420\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 248357008.0000 - mae: 13345.6545 - val_loss: 146265584.0000 - val_mae: 11337.9756\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 269892432.0000 - mae: 13855.4927 - val_loss: 146264128.0000 - val_mae: 11337.9111\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 273650005.3333 - mae: 14013.7196 - val_loss: 146262656.0000 - val_mae: 11337.8467\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 289371850.6667 - mae: 14366.2638 - val_loss: 146261184.0000 - val_mae: 11337.7822\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 313425338.6667 - mae: 14860.9331 - val_loss: 146259776.0000 - val_mae: 11337.7178\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 308891738.6667 - mae: 14691.4329 - val_loss: 146258320.0000 - val_mae: 11337.6553\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 275663930.6667 - mae: 14114.1493 - val_loss: 146256784.0000 - val_mae: 11337.5869\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 290200821.3333 - mae: 14423.6502 - val_loss: 146255344.0000 - val_mae: 11337.5244\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 248680637.3333 - mae: 13333.7446 - val_loss: 146253888.0000 - val_mae: 11337.4600\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 280778586.6667 - mae: 14078.2585 - val_loss: 146252416.0000 - val_mae: 11337.3936\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 265116770.6667 - mae: 13796.4419 - val_loss: 146250928.0000 - val_mae: 11337.3291\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 288271008.0000 - mae: 14327.0885 - val_loss: 146249536.0000 - val_mae: 11337.2666\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 262075709.3333 - mae: 13545.7360 - val_loss: 146248016.0000 - val_mae: 11337.1992\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 299900560.0000 - mae: 14553.7205 - val_loss: 146246544.0000 - val_mae: 11337.1348\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 262648584.0000 - mae: 13772.4136 - val_loss: 146245120.0000 - val_mae: 11337.0723\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 267504904.0000 - mae: 13770.3600 - val_loss: 146243600.0000 - val_mae: 11337.0049\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 299967941.3333 - mae: 14573.7371 - val_loss: 146242192.0000 - val_mae: 11336.9443\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 293685541.3333 - mae: 14340.9800 - val_loss: 146240736.0000 - val_mae: 11336.8799\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 271085269.3333 - mae: 13960.2926 - val_loss: 146239296.0000 - val_mae: 11336.8154\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 254815352.0000 - mae: 13601.5480 - val_loss: 146237744.0000 - val_mae: 11336.7471\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 310715984.0000 - mae: 14806.0215 - val_loss: 146236320.0000 - val_mae: 11336.6846\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 291766757.3333 - mae: 14307.2762 - val_loss: 146234896.0000 - val_mae: 11336.6221\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 270459277.3333 - mae: 14002.7660 - val_loss: 146233456.0000 - val_mae: 11336.5576\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 312475466.6667 - mae: 14856.8387 - val_loss: 146232080.0000 - val_mae: 11336.4971\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 307134896.0000 - mae: 14642.2176 - val_loss: 146230608.0000 - val_mae: 11336.4326\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 300974848.0000 - mae: 14631.1497 - val_loss: 146229104.0000 - val_mae: 11336.3662\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 330241882.6667 - mae: 15618.4637 - val_loss: 146227696.0000 - val_mae: 11336.3057\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 254085397.3333 - mae: 13434.7596 - val_loss: 146226224.0000 - val_mae: 11336.2393\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 283028453.3333 - mae: 14218.0921 - val_loss: 146224784.0000 - val_mae: 11336.1768\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 270199560.0000 - mae: 13970.5983 - val_loss: 146223296.0000 - val_mae: 11336.1113\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 284511957.3333 - mae: 14240.2554 - val_loss: 146221776.0000 - val_mae: 11336.0439\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 286391808.0000 - mae: 14199.4111 - val_loss: 146220400.0000 - val_mae: 11335.9814\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 272956901.3333 - mae: 13648.6076 - val_loss: 146218912.0000 - val_mae: 11335.9170\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 248676728.0000 - mae: 13285.2013 - val_loss: 146217392.0000 - val_mae: 11335.8506\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 275464325.3333 - mae: 13964.7511 - val_loss: 146215952.0000 - val_mae: 11335.7861\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 280798264.0000 - mae: 14196.3685 - val_loss: 146214528.0000 - val_mae: 11335.7236\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 284460506.6667 - mae: 14306.7059 - val_loss: 146213088.0000 - val_mae: 11335.6592\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 287364021.3333 - mae: 14271.8747 - val_loss: 146211664.0000 - val_mae: 11335.5967\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 250402370.6667 - mae: 13590.4714 - val_loss: 146210128.0000 - val_mae: 11335.5283\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 302780053.3333 - mae: 14605.6877 - val_loss: 146208704.0000 - val_mae: 11335.4678\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 265049778.6667 - mae: 13626.3153 - val_loss: 146207200.0000 - val_mae: 11335.3994\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 290673008.0000 - mae: 14499.0251 - val_loss: 146205760.0000 - val_mae: 11335.3369\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 274992594.6667 - mae: 13904.4517 - val_loss: 146204272.0000 - val_mae: 11335.2725\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 261082634.6667 - mae: 13638.6450 - val_loss: 146202768.0000 - val_mae: 11335.2041\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 288692053.3333 - mae: 14214.1582 - val_loss: 146201296.0000 - val_mae: 11335.1387\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 241804464.0000 - mae: 13194.0719 - val_loss: 146199824.0000 - val_mae: 11335.0742\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 304073872.0000 - mae: 14615.7373 - val_loss: 146198448.0000 - val_mae: 11335.0137\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 260731434.6667 - mae: 13775.8193 - val_loss: 146196944.0000 - val_mae: 11334.9473\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 247999296.0000 - mae: 13302.2233 - val_loss: 146195456.0000 - val_mae: 11334.8818\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 316763770.6667 - mae: 14880.1203 - val_loss: 146194064.0000 - val_mae: 11334.8213\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 301601034.6667 - mae: 14850.3408 - val_loss: 146192608.0000 - val_mae: 11334.7568\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 258812416.0000 - mae: 13604.2687 - val_loss: 146191136.0000 - val_mae: 11334.6904\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 272941280.0000 - mae: 13963.9650 - val_loss: 146189648.0000 - val_mae: 11334.6260\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 298593034.6667 - mae: 14605.9990 - val_loss: 146188224.0000 - val_mae: 11334.5635\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 272043842.6667 - mae: 13804.3162 - val_loss: 146186800.0000 - val_mae: 11334.5010\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 270742325.3333 - mae: 13980.1751 - val_loss: 146185312.0000 - val_mae: 11334.4346\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 326485429.3333 - mae: 15053.2873 - val_loss: 146183888.0000 - val_mae: 11334.3721\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 248182269.3333 - mae: 13281.4382 - val_loss: 146182352.0000 - val_mae: 11334.3037\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 257377840.0000 - mae: 13477.9702 - val_loss: 146180848.0000 - val_mae: 11334.2393\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 264027818.6667 - mae: 13800.8521 - val_loss: 146179408.0000 - val_mae: 11334.1758\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 287554309.3333 - mae: 14312.2376 - val_loss: 146177984.0000 - val_mae: 11334.1113\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 284447530.6667 - mae: 14217.1532 - val_loss: 146176544.0000 - val_mae: 11334.0488\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 263599402.6667 - mae: 13898.9155 - val_loss: 146175104.0000 - val_mae: 11333.9834\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 275327122.6667 - mae: 13868.8672 - val_loss: 146173648.0000 - val_mae: 11333.9209\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 269825157.3333 - mae: 13892.2943 - val_loss: 146172128.0000 - val_mae: 11333.8545\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 312653957.3333 - mae: 14825.9375 - val_loss: 146170720.0000 - val_mae: 11333.7900\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 279090549.3333 - mae: 14198.6873 - val_loss: 146169264.0000 - val_mae: 11333.7256\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 321264026.6667 - mae: 14707.8341 - val_loss: 146167808.0000 - val_mae: 11333.6631\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 282381205.3333 - mae: 14132.6717 - val_loss: 146166320.0000 - val_mae: 11333.5967\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 247918973.3333 - mae: 13353.1522 - val_loss: 146164800.0000 - val_mae: 11333.5303\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 301639520.0000 - mae: 14568.6546 - val_loss: 146163376.0000 - val_mae: 11333.4678\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 291228373.3333 - mae: 14344.0719 - val_loss: 146161936.0000 - val_mae: 11333.4033\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 288010026.6667 - mae: 14200.9329 - val_loss: 146160480.0000 - val_mae: 11333.3389\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 274465840.0000 - mae: 13949.9933 - val_loss: 146158960.0000 - val_mae: 11333.2725\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 258934626.6667 - mae: 13758.5430 - val_loss: 146157536.0000 - val_mae: 11333.2100\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 256806093.3333 - mae: 13591.5184 - val_loss: 146156048.0000 - val_mae: 11333.1436\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 293958832.0000 - mae: 14427.4341 - val_loss: 146154592.0000 - val_mae: 11333.0791\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 279884906.6667 - mae: 14288.7764 - val_loss: 146153104.0000 - val_mae: 11333.0137\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 284054184.0000 - mae: 14209.8997 - val_loss: 146151696.0000 - val_mae: 11332.9492\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 308887653.3333 - mae: 14778.7033 - val_loss: 146150256.0000 - val_mae: 11332.8867\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285091317.3333 - mae: 14108.8914 - val_loss: 146148768.0000 - val_mae: 11332.8223\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 268505045.3333 - mae: 13818.6873 - val_loss: 146147296.0000 - val_mae: 11332.7568\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 319643274.6667 - mae: 15127.9165 - val_loss: 146145872.0000 - val_mae: 11332.6943\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 299715317.3333 - mae: 14598.9735 - val_loss: 146144384.0000 - val_mae: 11332.6299\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 269165677.3333 - mae: 13827.2772 - val_loss: 146142928.0000 - val_mae: 11332.5654\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 304020885.3333 - mae: 14615.2700 - val_loss: 146141488.0000 - val_mae: 11332.5010\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 276616904.0000 - mae: 13921.1829 - val_loss: 146139968.0000 - val_mae: 11332.4346\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 275541317.3333 - mae: 14029.7578 - val_loss: 146138480.0000 - val_mae: 11332.3682\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 291660453.3333 - mae: 14298.9941 - val_loss: 146137008.0000 - val_mae: 11332.3037\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 283566421.3333 - mae: 14273.2922 - val_loss: 146135504.0000 - val_mae: 11332.2383\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 303010837.3333 - mae: 14429.1510 - val_loss: 146134080.0000 - val_mae: 11332.1758\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 287092821.3333 - mae: 14129.5161 - val_loss: 146132608.0000 - val_mae: 11332.1113\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 259957544.0000 - mae: 13595.2868 - val_loss: 146131136.0000 - val_mae: 11332.0439\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 256922762.6667 - mae: 13487.9318 - val_loss: 146129680.0000 - val_mae: 11331.9795\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 301866714.6667 - mae: 14549.6810 - val_loss: 146128288.0000 - val_mae: 11331.9189\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 264899861.3333 - mae: 13667.0311 - val_loss: 146126784.0000 - val_mae: 11331.8525\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 267469786.6667 - mae: 13754.5306 - val_loss: 146125296.0000 - val_mae: 11331.7861\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 300242757.3333 - mae: 14651.3558 - val_loss: 146123872.0000 - val_mae: 11331.7236\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 269885813.3333 - mae: 13976.7284 - val_loss: 146122416.0000 - val_mae: 11331.6611\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285696357.3333 - mae: 14221.3963 - val_loss: 146120976.0000 - val_mae: 11331.5967\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 304323568.0000 - mae: 14813.6003 - val_loss: 146119520.0000 - val_mae: 11331.5322\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 259821490.6667 - mae: 13606.1675 - val_loss: 146118016.0000 - val_mae: 11331.4658\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 317724586.6667 - mae: 14860.9188 - val_loss: 146116576.0000 - val_mae: 11331.4014\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 238911330.6667 - mae: 13112.7044 - val_loss: 146115008.0000 - val_mae: 11331.3330\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 266961701.3333 - mae: 13737.9027 - val_loss: 146113584.0000 - val_mae: 11331.2705\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 280969613.3333 - mae: 14020.7578 - val_loss: 146112112.0000 - val_mae: 11331.2061\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 258687322.6667 - mae: 13684.8835 - val_loss: 146110640.0000 - val_mae: 11331.1387\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 309576298.6667 - mae: 14693.6852 - val_loss: 146109248.0000 - val_mae: 11331.0791\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 274586722.6667 - mae: 13880.3102 - val_loss: 146107760.0000 - val_mae: 11331.0117\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 252077080.0000 - mae: 13501.8590 - val_loss: 146106272.0000 - val_mae: 11330.9463\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 256775480.0000 - mae: 13549.1958 - val_loss: 146104832.0000 - val_mae: 11330.8838\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 283962794.6667 - mae: 14043.5321 - val_loss: 146103328.0000 - val_mae: 11330.8174\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 288511157.3333 - mae: 14311.6379 - val_loss: 146101872.0000 - val_mae: 11330.7529\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 291974437.3333 - mae: 14271.8128 - val_loss: 146100416.0000 - val_mae: 11330.6904\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 302029637.3333 - mae: 14648.4206 - val_loss: 146098992.0000 - val_mae: 11330.6260\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 277968725.3333 - mae: 14022.3649 - val_loss: 146097552.0000 - val_mae: 11330.5615\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 248738546.6667 - mae: 13285.9691 - val_loss: 146096064.0000 - val_mae: 11330.4971\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 275579882.6667 - mae: 13960.5921 - val_loss: 146094608.0000 - val_mae: 11330.4326\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 255675400.0000 - mae: 13432.5339 - val_loss: 146093088.0000 - val_mae: 11330.3662\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 260151061.3333 - mae: 13725.6772 - val_loss: 146091632.0000 - val_mae: 11330.3018\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 268367826.6667 - mae: 13810.5081 - val_loss: 146090144.0000 - val_mae: 11330.2363\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 291394085.3333 - mae: 14354.8340 - val_loss: 146088720.0000 - val_mae: 11330.1738\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 304798906.6667 - mae: 14449.6442 - val_loss: 146087264.0000 - val_mae: 11330.1084\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 259555136.0000 - mae: 13579.2646 - val_loss: 146085792.0000 - val_mae: 11330.0439\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 297574010.6667 - mae: 14548.3714 - val_loss: 146084352.0000 - val_mae: 11329.9795\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 311826325.3333 - mae: 14721.4639 - val_loss: 146082912.0000 - val_mae: 11329.9170\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 288719432.0000 - mae: 14022.6745 - val_loss: 146081408.0000 - val_mae: 11329.8506\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 294392368.0000 - mae: 14324.5150 - val_loss: 146079984.0000 - val_mae: 11329.7881\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 256398432.0000 - mae: 13602.0794 - val_loss: 146078496.0000 - val_mae: 11329.7217\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 264864901.3333 - mae: 13767.3434 - val_loss: 146077040.0000 - val_mae: 11329.6572\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 260048645.3333 - mae: 13773.3154 - val_loss: 146075600.0000 - val_mae: 11329.5947\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 256465821.3333 - mae: 13655.4259 - val_loss: 146074112.0000 - val_mae: 11329.5283\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 306713984.0000 - mae: 14691.0773 - val_loss: 146072688.0000 - val_mae: 11329.4658\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 256148141.3333 - mae: 13532.6639 - val_loss: 146071184.0000 - val_mae: 11329.3994\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 299051381.3333 - mae: 14418.9172 - val_loss: 146069728.0000 - val_mae: 11329.3350\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 251746322.6667 - mae: 13485.7093 - val_loss: 146068272.0000 - val_mae: 11329.2705\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 283715293.3333 - mae: 14075.5187 - val_loss: 146066784.0000 - val_mae: 11329.2041\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 265939928.0000 - mae: 13688.4087 - val_loss: 146065344.0000 - val_mae: 11329.1416\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 273059968.0000 - mae: 13787.8571 - val_loss: 146063856.0000 - val_mae: 11329.0742\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 289609045.3333 - mae: 14201.6133 - val_loss: 146062400.0000 - val_mae: 11329.0117\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 252592466.6667 - mae: 13383.8027 - val_loss: 146060880.0000 - val_mae: 11328.9443\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 263598170.6667 - mae: 13724.8201 - val_loss: 146059424.0000 - val_mae: 11328.8799\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 266598709.3333 - mae: 13769.8091 - val_loss: 146058000.0000 - val_mae: 11328.8174\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 290423109.3333 - mae: 14380.3392 - val_loss: 146056544.0000 - val_mae: 11328.7529\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 281692250.6667 - mae: 14149.0636 - val_loss: 146055088.0000 - val_mae: 11328.6885\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 272763744.0000 - mae: 13764.6929 - val_loss: 146053584.0000 - val_mae: 11328.6221\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 290243226.6667 - mae: 14472.2168 - val_loss: 146052144.0000 - val_mae: 11328.5596\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 274169752.0000 - mae: 14188.7051 - val_loss: 146050704.0000 - val_mae: 11328.4951\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 291047760.0000 - mae: 14364.5910 - val_loss: 146049248.0000 - val_mae: 11328.4307\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 261285914.6667 - mae: 13805.0853 - val_loss: 146047728.0000 - val_mae: 11328.3643\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 269655402.6667 - mae: 14065.8218 - val_loss: 146046320.0000 - val_mae: 11328.3018\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 269508397.3333 - mae: 13862.9624 - val_loss: 146044848.0000 - val_mae: 11328.2383\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 262425237.3333 - mae: 13623.9834 - val_loss: 146043376.0000 - val_mae: 11328.1709\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 285126282.6667 - mae: 14241.3542 - val_loss: 146041888.0000 - val_mae: 11328.1064\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 267958776.0000 - mae: 13920.5636 - val_loss: 146040448.0000 - val_mae: 11328.0420\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 291250320.0000 - mae: 14483.4771 - val_loss: 146039008.0000 - val_mae: 11327.9795\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 253795917.3333 - mae: 13428.9180 - val_loss: 146037536.0000 - val_mae: 11327.9131\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 289394362.6667 - mae: 14350.5109 - val_loss: 146036112.0000 - val_mae: 11327.8506\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 271598541.3333 - mae: 13992.5771 - val_loss: 146034624.0000 - val_mae: 11327.7861\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285218485.3333 - mae: 14231.5340 - val_loss: 146033168.0000 - val_mae: 11327.7217\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 259677813.3333 - mae: 13457.6862 - val_loss: 146031664.0000 - val_mae: 11327.6553\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 254940880.0000 - mae: 13554.8156 - val_loss: 146030208.0000 - val_mae: 11327.5908\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 295120586.6667 - mae: 14399.4202 - val_loss: 146028736.0000 - val_mae: 11327.5264\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 301437834.6667 - mae: 14544.6149 - val_loss: 146027296.0000 - val_mae: 11327.4619\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 250832250.6667 - mae: 13407.0545 - val_loss: 146025808.0000 - val_mae: 11327.3955\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 272307450.6667 - mae: 13906.7900 - val_loss: 146024320.0000 - val_mae: 11327.3311\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 253421074.6667 - mae: 13678.8670 - val_loss: 146022832.0000 - val_mae: 11327.2637\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 254374640.0000 - mae: 13398.3112 - val_loss: 146021408.0000 - val_mae: 11327.2012\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 298031802.6667 - mae: 14347.5742 - val_loss: 146019984.0000 - val_mae: 11327.1387\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 320429498.6667 - mae: 14931.1011 - val_loss: 146018544.0000 - val_mae: 11327.0762\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 243729277.3333 - mae: 13356.5326 - val_loss: 146017056.0000 - val_mae: 11327.0098\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 288939498.6667 - mae: 14249.6978 - val_loss: 146015600.0000 - val_mae: 11326.9463\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 248427824.0000 - mae: 13425.8062 - val_loss: 146014112.0000 - val_mae: 11326.8799\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 283545285.3333 - mae: 14136.2044 - val_loss: 146012624.0000 - val_mae: 11326.8154\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 278723882.6667 - mae: 14028.0791 - val_loss: 146011152.0000 - val_mae: 11326.7490\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 283017509.3333 - mae: 14161.7223 - val_loss: 146009728.0000 - val_mae: 11326.6865\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 302144410.6667 - mae: 14557.9310 - val_loss: 146008288.0000 - val_mae: 11326.6240\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 278549930.6667 - mae: 14091.4046 - val_loss: 146006848.0000 - val_mae: 11326.5596\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 278767896.0000 - mae: 14041.6605 - val_loss: 146005360.0000 - val_mae: 11326.4932\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 253765152.0000 - mae: 13421.3242 - val_loss: 146003840.0000 - val_mae: 11326.4268\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 265480210.6667 - mae: 13610.0944 - val_loss: 146002320.0000 - val_mae: 11326.3584\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 283551738.6667 - mae: 14192.7562 - val_loss: 146000912.0000 - val_mae: 11326.2988\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 266189218.6667 - mae: 13884.4481 - val_loss: 145999504.0000 - val_mae: 11326.2363\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 296638698.6667 - mae: 14340.2863 - val_loss: 145998048.0000 - val_mae: 11326.1709\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 268202306.6667 - mae: 13733.1276 - val_loss: 145996640.0000 - val_mae: 11326.1084\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 295167621.3333 - mae: 14476.4608 - val_loss: 145995184.0000 - val_mae: 11326.0439\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 267075845.3333 - mae: 13706.6841 - val_loss: 145993696.0000 - val_mae: 11325.9795\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 250088685.3333 - mae: 13437.3794 - val_loss: 145992176.0000 - val_mae: 11325.9111\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 270343346.6667 - mae: 13823.2785 - val_loss: 145990688.0000 - val_mae: 11325.8467\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 299535290.6667 - mae: 14435.6807 - val_loss: 145989232.0000 - val_mae: 11325.7822\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 298020293.3333 - mae: 14638.3818 - val_loss: 145987792.0000 - val_mae: 11325.7178\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 272492784.0000 - mae: 13929.1317 - val_loss: 145986400.0000 - val_mae: 11325.6572\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 246506880.0000 - mae: 13189.6104 - val_loss: 145984912.0000 - val_mae: 11325.5908\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 293048032.0000 - mae: 14456.4915 - val_loss: 145983488.0000 - val_mae: 11325.5283\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 289212293.3333 - mae: 14316.4456 - val_loss: 145982032.0000 - val_mae: 11325.4639\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 281271106.6667 - mae: 14090.0801 - val_loss: 145980576.0000 - val_mae: 11325.3994\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 266428154.6667 - mae: 13757.7191 - val_loss: 145979120.0000 - val_mae: 11325.3350\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 277548789.3333 - mae: 13897.5555 - val_loss: 145977648.0000 - val_mae: 11325.2705\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 270160333.3333 - mae: 13842.7969 - val_loss: 145976160.0000 - val_mae: 11325.2041\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 263435650.6667 - mae: 13652.6792 - val_loss: 145974688.0000 - val_mae: 11325.1387\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 287354917.3333 - mae: 14279.8955 - val_loss: 145973216.0000 - val_mae: 11325.0742\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 286877773.3333 - mae: 14253.9474 - val_loss: 145971728.0000 - val_mae: 11325.0088\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 264886341.3333 - mae: 13776.8167 - val_loss: 145970272.0000 - val_mae: 11324.9443\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 265510458.6667 - mae: 13716.9517 - val_loss: 145968816.0000 - val_mae: 11324.8799\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 277646002.6667 - mae: 14047.1152 - val_loss: 145967392.0000 - val_mae: 11324.8174\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 269479568.0000 - mae: 13786.5073 - val_loss: 145965920.0000 - val_mae: 11324.7510\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 265920664.0000 - mae: 13758.9635 - val_loss: 145964432.0000 - val_mae: 11324.6865\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 290930618.6667 - mae: 14396.8786 - val_loss: 145962944.0000 - val_mae: 11324.6221\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 306302672.0000 - mae: 14803.4331 - val_loss: 145961520.0000 - val_mae: 11324.5576\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 293349018.6667 - mae: 14338.5576 - val_loss: 145960032.0000 - val_mae: 11324.4932\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 276516160.0000 - mae: 14146.1901 - val_loss: 145958576.0000 - val_mae: 11324.4287\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 283981042.6667 - mae: 14258.7095 - val_loss: 145957088.0000 - val_mae: 11324.3633\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 302221824.0000 - mae: 14671.8864 - val_loss: 145955648.0000 - val_mae: 11324.3008\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 260142746.6667 - mae: 13699.9616 - val_loss: 145954160.0000 - val_mae: 11324.2334\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 254894888.0000 - mae: 13351.6527 - val_loss: 145952656.0000 - val_mae: 11324.1670\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 269761032.0000 - mae: 13803.5511 - val_loss: 145951184.0000 - val_mae: 11324.1025\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 280796162.6667 - mae: 14068.9227 - val_loss: 145949728.0000 - val_mae: 11324.0381\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 287721560.0000 - mae: 14309.7962 - val_loss: 145948272.0000 - val_mae: 11323.9736\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 240667360.0000 - mae: 13251.1383 - val_loss: 145946832.0000 - val_mae: 11323.9092\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 257955416.0000 - mae: 13592.1917 - val_loss: 145945392.0000 - val_mae: 11323.8467\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 289136810.6667 - mae: 14227.2573 - val_loss: 145943952.0000 - val_mae: 11323.7822\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 294720728.0000 - mae: 14303.0908 - val_loss: 145942464.0000 - val_mae: 11323.7178\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 301552586.6667 - mae: 14516.0496 - val_loss: 145941008.0000 - val_mae: 11323.6533\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 256771784.0000 - mae: 13396.7144 - val_loss: 145939520.0000 - val_mae: 11323.5869\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 271690749.3333 - mae: 13847.1105 - val_loss: 145938096.0000 - val_mae: 11323.5244\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 259088061.3333 - mae: 13823.2275 - val_loss: 145936672.0000 - val_mae: 11323.4600\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 276984880.0000 - mae: 14045.8467 - val_loss: 145935232.0000 - val_mae: 11323.3975\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 297204864.0000 - mae: 14431.7183 - val_loss: 145933744.0000 - val_mae: 11323.3311\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 295021061.3333 - mae: 14505.4596 - val_loss: 145932304.0000 - val_mae: 11323.2686\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 275030789.3333 - mae: 13955.1133 - val_loss: 145930768.0000 - val_mae: 11323.1992\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 258506770.6667 - mae: 13640.1118 - val_loss: 145929280.0000 - val_mae: 11323.1348\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 261184586.6667 - mae: 13609.1346 - val_loss: 145927824.0000 - val_mae: 11323.0693\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 273773154.6667 - mae: 13939.7939 - val_loss: 145926416.0000 - val_mae: 11323.0088\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 288407685.3333 - mae: 14374.8709 - val_loss: 145924960.0000 - val_mae: 11322.9443\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 309443269.3333 - mae: 14804.0871 - val_loss: 145923520.0000 - val_mae: 11322.8799\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 243543514.6667 - mae: 13250.8161 - val_loss: 145922016.0000 - val_mae: 11322.8135\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 291807594.6667 - mae: 14514.4429 - val_loss: 145920608.0000 - val_mae: 11322.7529\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 313551162.6667 - mae: 14931.4315 - val_loss: 145919184.0000 - val_mae: 11322.6885\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 262446533.3333 - mae: 13815.0895 - val_loss: 145917664.0000 - val_mae: 11322.6221\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 267486082.6667 - mae: 13972.4601 - val_loss: 145916224.0000 - val_mae: 11322.5576\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 301605914.6667 - mae: 14509.9854 - val_loss: 145914752.0000 - val_mae: 11322.4932\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 277138906.6667 - mae: 13961.2562 - val_loss: 145913264.0000 - val_mae: 11322.4268\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 309649157.3333 - mae: 14658.5138 - val_loss: 145911840.0000 - val_mae: 11322.3643\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 274107562.6667 - mae: 14061.7604 - val_loss: 145910320.0000 - val_mae: 11322.2988\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 282905645.3333 - mae: 14211.8501 - val_loss: 145908864.0000 - val_mae: 11322.2334\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 265366920.0000 - mae: 13814.5659 - val_loss: 145907376.0000 - val_mae: 11322.1670\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 256543749.3333 - mae: 13402.9800 - val_loss: 145905872.0000 - val_mae: 11322.1006\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 298358474.6667 - mae: 14438.1701 - val_loss: 145904448.0000 - val_mae: 11322.0381\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 263348021.3333 - mae: 13713.0693 - val_loss: 145902960.0000 - val_mae: 11321.9717\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 304205808.0000 - mae: 14616.3916 - val_loss: 145901520.0000 - val_mae: 11321.9092\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 274240989.3333 - mae: 13853.9956 - val_loss: 145900064.0000 - val_mae: 11321.8447\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 278953128.0000 - mae: 14111.7109 - val_loss: 145898656.0000 - val_mae: 11321.7822\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 280729514.6667 - mae: 14240.5439 - val_loss: 145897184.0000 - val_mae: 11321.7178\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 279531280.0000 - mae: 13981.5379 - val_loss: 145895744.0000 - val_mae: 11321.6533\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 296974474.6667 - mae: 14332.1243 - val_loss: 145894256.0000 - val_mae: 11321.5869\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 267263714.6667 - mae: 13805.6343 - val_loss: 145892800.0000 - val_mae: 11321.5244\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 258325805.3333 - mae: 13766.7604 - val_loss: 145891296.0000 - val_mae: 11321.4580\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 291912405.3333 - mae: 14456.5793 - val_loss: 145889840.0000 - val_mae: 11321.3936\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 289853493.3333 - mae: 14328.1969 - val_loss: 145888384.0000 - val_mae: 11321.3291\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 243040309.3333 - mae: 13321.3625 - val_loss: 145886912.0000 - val_mae: 11321.2637\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 281815018.6667 - mae: 14109.5939 - val_loss: 145885472.0000 - val_mae: 11321.1992\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 274511365.3333 - mae: 13955.7381 - val_loss: 145883984.0000 - val_mae: 11321.1338\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 289250400.0000 - mae: 14324.0711 - val_loss: 145882544.0000 - val_mae: 11321.0713\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 283144232.0000 - mae: 14222.9992 - val_loss: 145881088.0000 - val_mae: 11321.0068\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 277466416.0000 - mae: 13904.0016 - val_loss: 145879600.0000 - val_mae: 11320.9404\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 278087432.0000 - mae: 14038.4964 - val_loss: 145878128.0000 - val_mae: 11320.8760\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 268974184.0000 - mae: 13869.3345 - val_loss: 145876688.0000 - val_mae: 11320.8115\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 253762266.6667 - mae: 13455.6891 - val_loss: 145875248.0000 - val_mae: 11320.7490\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 275048688.0000 - mae: 14154.5267 - val_loss: 145873760.0000 - val_mae: 11320.6826\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 291518389.3333 - mae: 14201.0459 - val_loss: 145872336.0000 - val_mae: 11320.6201\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 254677885.3333 - mae: 13595.9845 - val_loss: 145870816.0000 - val_mae: 11320.5518\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 306131866.6667 - mae: 14697.7622 - val_loss: 145869360.0000 - val_mae: 11320.4893\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 309410165.3333 - mae: 14802.4367 - val_loss: 145867936.0000 - val_mae: 11320.4258\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 285917146.6667 - mae: 14251.8459 - val_loss: 145866448.0000 - val_mae: 11320.3613\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 273517237.3333 - mae: 13936.4640 - val_loss: 145865008.0000 - val_mae: 11320.2959\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 245620805.3333 - mae: 13357.3221 - val_loss: 145863488.0000 - val_mae: 11320.2295\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 286206896.0000 - mae: 14214.1737 - val_loss: 145862032.0000 - val_mae: 11320.1650\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 270028800.0000 - mae: 13812.9119 - val_loss: 145860560.0000 - val_mae: 11320.1006\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 331761285.3333 - mae: 15222.6344 - val_loss: 145859152.0000 - val_mae: 11320.0381\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 298043520.0000 - mae: 14455.0763 - val_loss: 145857744.0000 - val_mae: 11319.9756\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 274616408.0000 - mae: 14038.6021 - val_loss: 145856288.0000 - val_mae: 11319.9111\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 302880480.0000 - mae: 14622.2778 - val_loss: 145854832.0000 - val_mae: 11319.8467\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 288321629.3333 - mae: 14190.1304 - val_loss: 145853328.0000 - val_mae: 11319.7803\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 272406157.3333 - mae: 13913.5591 - val_loss: 145851840.0000 - val_mae: 11319.7139\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 297838858.6667 - mae: 14530.1943 - val_loss: 145850400.0000 - val_mae: 11319.6514\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 258661458.6667 - mae: 13749.3968 - val_loss: 145848912.0000 - val_mae: 11319.5850\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 250396397.3333 - mae: 13314.7419 - val_loss: 145847392.0000 - val_mae: 11319.5186\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 272713088.0000 - mae: 13926.8911 - val_loss: 145845968.0000 - val_mae: 11319.4561\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 294533413.3333 - mae: 14578.8901 - val_loss: 145844528.0000 - val_mae: 11319.3916\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 263772669.3333 - mae: 13745.7516 - val_loss: 145843072.0000 - val_mae: 11319.3262\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 295279749.3333 - mae: 14362.0394 - val_loss: 145841648.0000 - val_mae: 11319.2637\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 281354634.6667 - mae: 14281.7759 - val_loss: 145840160.0000 - val_mae: 11319.1973\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 265077666.6667 - mae: 13803.0649 - val_loss: 145838688.0000 - val_mae: 11319.1338\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 272665986.6667 - mae: 14163.8182 - val_loss: 145837152.0000 - val_mae: 11319.0654\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 311380416.0000 - mae: 14644.8838 - val_loss: 145835760.0000 - val_mae: 11319.0049\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 267009968.0000 - mae: 14075.0454 - val_loss: 145834288.0000 - val_mae: 11318.9404\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 276369309.3333 - mae: 13866.6361 - val_loss: 145832864.0000 - val_mae: 11318.8760\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 273067781.3333 - mae: 13865.4310 - val_loss: 145831392.0000 - val_mae: 11318.8115\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 269901808.0000 - mae: 13669.9609 - val_loss: 145829888.0000 - val_mae: 11318.7451\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 297802352.0000 - mae: 14494.2186 - val_loss: 145828448.0000 - val_mae: 11318.6807\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 304076778.6667 - mae: 14747.0938 - val_loss: 145827008.0000 - val_mae: 11318.6182\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 277910253.3333 - mae: 14146.0272 - val_loss: 145825504.0000 - val_mae: 11318.5518\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 279976197.3333 - mae: 14147.2996 - val_loss: 145824064.0000 - val_mae: 11318.4883\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 262279288.0000 - mae: 13772.4995 - val_loss: 145822560.0000 - val_mae: 11318.4209\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 252616210.6667 - mae: 13395.0693 - val_loss: 145821104.0000 - val_mae: 11318.3564\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 272558493.3333 - mae: 13956.4629 - val_loss: 145819648.0000 - val_mae: 11318.2920\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 272904949.3333 - mae: 13761.7848 - val_loss: 145818192.0000 - val_mae: 11318.2275\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 254775762.6667 - mae: 13760.7437 - val_loss: 145816736.0000 - val_mae: 11318.1631\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 230541952.0000 - mae: 12937.1623 - val_loss: 145815184.0000 - val_mae: 11318.0967\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 301551664.0000 - mae: 14739.0698 - val_loss: 145813792.0000 - val_mae: 11318.0342\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 266088490.6667 - mae: 13602.2581 - val_loss: 145812352.0000 - val_mae: 11317.9697\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 289183410.6667 - mae: 14372.7975 - val_loss: 145810928.0000 - val_mae: 11317.9072\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 276405845.3333 - mae: 13904.9233 - val_loss: 145809440.0000 - val_mae: 11317.8428\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 269910757.3333 - mae: 13708.0389 - val_loss: 145807984.0000 - val_mae: 11317.7783\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 270390034.6667 - mae: 13785.1603 - val_loss: 145806480.0000 - val_mae: 11317.7119\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 300477973.3333 - mae: 14564.2264 - val_loss: 145805040.0000 - val_mae: 11317.6475\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 269167245.3333 - mae: 13985.8042 - val_loss: 145803664.0000 - val_mae: 11317.5869\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 254924845.3333 - mae: 13339.8307 - val_loss: 145802176.0000 - val_mae: 11317.5205\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 247478909.3333 - mae: 13248.0662 - val_loss: 145800672.0000 - val_mae: 11317.4541\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 280352573.3333 - mae: 14042.1351 - val_loss: 145799216.0000 - val_mae: 11317.3887\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 265013397.3333 - mae: 13817.5869 - val_loss: 145797744.0000 - val_mae: 11317.3242\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 281644122.6667 - mae: 14329.4256 - val_loss: 145796304.0000 - val_mae: 11317.2598\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 297295056.0000 - mae: 14517.5192 - val_loss: 145794896.0000 - val_mae: 11317.1973\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 270400466.6667 - mae: 13827.3701 - val_loss: 145793440.0000 - val_mae: 11317.1338\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 271748112.0000 - mae: 13731.6867 - val_loss: 145791936.0000 - val_mae: 11317.0693\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 292113381.3333 - mae: 14385.6632 - val_loss: 145790480.0000 - val_mae: 11317.0029\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 291054874.6667 - mae: 14384.0073 - val_loss: 145789040.0000 - val_mae: 11316.9404\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 289145725.3333 - mae: 14456.8986 - val_loss: 145787552.0000 - val_mae: 11316.8740\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 263165557.3333 - mae: 13836.9753 - val_loss: 145786032.0000 - val_mae: 11316.8076\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 277401477.3333 - mae: 14034.0791 - val_loss: 145784592.0000 - val_mae: 11316.7432\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 273088922.6667 - mae: 13797.7005 - val_loss: 145783120.0000 - val_mae: 11316.6787\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 247271733.3333 - mae: 13412.4124 - val_loss: 145781664.0000 - val_mae: 11316.6143\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 306266938.6667 - mae: 14762.8003 - val_loss: 145780240.0000 - val_mae: 11316.5518\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 276401178.6667 - mae: 14052.5231 - val_loss: 145778752.0000 - val_mae: 11316.4863\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 292222730.6667 - mae: 14293.0955 - val_loss: 145777328.0000 - val_mae: 11316.4238\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 325481637.3333 - mae: 14985.8781 - val_loss: 145775904.0000 - val_mae: 11316.3613\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 272687328.0000 - mae: 13976.2280 - val_loss: 145774464.0000 - val_mae: 11316.2959\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 321051269.3333 - mae: 14970.2935 - val_loss: 145773008.0000 - val_mae: 11316.2314\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 253605912.0000 - mae: 13605.3262 - val_loss: 145771504.0000 - val_mae: 11316.1650\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 282740973.3333 - mae: 14355.3859 - val_loss: 145770000.0000 - val_mae: 11316.1006\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 264515565.3333 - mae: 13767.0509 - val_loss: 145768544.0000 - val_mae: 11316.0361\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 283392213.3333 - mae: 14145.6006 - val_loss: 145767072.0000 - val_mae: 11315.9697\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 268068410.6667 - mae: 14087.3249 - val_loss: 145765600.0000 - val_mae: 11315.9053\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 285921712.0000 - mae: 14104.7612 - val_loss: 145764128.0000 - val_mae: 11315.8389\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 295775650.6667 - mae: 14649.7433 - val_loss: 145762672.0000 - val_mae: 11315.7744\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 282916045.3333 - mae: 14067.4481 - val_loss: 145761200.0000 - val_mae: 11315.7100\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 271228584.0000 - mae: 13842.5628 - val_loss: 145759696.0000 - val_mae: 11315.6436\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 252726058.6667 - mae: 13414.5771 - val_loss: 145758272.0000 - val_mae: 11315.5811\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 261836850.6667 - mae: 13629.1847 - val_loss: 145756768.0000 - val_mae: 11315.5137\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 284173616.0000 - mae: 14194.7065 - val_loss: 145755360.0000 - val_mae: 11315.4512\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 262091589.3333 - mae: 13737.4899 - val_loss: 145753904.0000 - val_mae: 11315.3867\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 283077477.3333 - mae: 14313.5885 - val_loss: 145752464.0000 - val_mae: 11315.3223\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 238088645.3333 - mae: 13239.8958 - val_loss: 145750944.0000 - val_mae: 11315.2568\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 260151242.6667 - mae: 13784.8633 - val_loss: 145749488.0000 - val_mae: 11315.1924\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 278083272.0000 - mae: 14175.5938 - val_loss: 145748064.0000 - val_mae: 11315.1299\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 290878522.6667 - mae: 14358.8293 - val_loss: 145746640.0000 - val_mae: 11315.0674\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 273427408.0000 - mae: 13937.3143 - val_loss: 145745184.0000 - val_mae: 11315.0029\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 281387162.6667 - mae: 14275.1689 - val_loss: 145743744.0000 - val_mae: 11314.9385\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 299482880.0000 - mae: 14514.7809 - val_loss: 145742288.0000 - val_mae: 11314.8740\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 286940682.6667 - mae: 14272.7074 - val_loss: 145740832.0000 - val_mae: 11314.8096\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 270024877.3333 - mae: 13707.1527 - val_loss: 145739344.0000 - val_mae: 11314.7451\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 274304397.3333 - mae: 13884.4762 - val_loss: 145737856.0000 - val_mae: 11314.6787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "J0kdwyvnsBMU",
        "outputId": "a2cc67a3-3553-492c-96ad-0104a63cd985"
      },
      "source": [
        "history_dict = Model_Results1.history\n",
        "mae_values = history_dict['mae']\n",
        "val_mae_values = history_dict['val_mae']\n",
        "epoches = np.arange(1,len(history_dict['mae'])+1)\n",
        "plt.plot(epoches,mae_values,'r',label=\"Training Mae\")\n",
        "plt.plot(epoches,val_mae_values,'g',label=\"Validating Mae\")\n",
        "plt.title('Training and validation Mae')\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Mae\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSaegsocTG0P",
        "outputId": "f7eb9f93-2c93-488f-8a66-0f4068d19cf7"
      },
      "source": [
        "history_dict = Model_Results1.history\n",
        "val_acc_values = history_dict['val_mae']\n",
        "maxi = np.max(val_acc_values)\n",
        "mini = np.min(val_acc_values)\n",
        "avrg = (maxi+mini)/2\n",
        "print(f\"FOR MODEL1 Average Validation Absolute Error = {avrg}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOR MODEL1 Average Validation Absolute Error = 11332.6953125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjM7-hq0VW1B"
      },
      "source": [
        "# **MAE without K fold and with selu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj4MmPC7SFU0",
        "outputId": "b1819525-85dc-4733-de01-b81c79d76c48"
      },
      "source": [
        "Model_Results2 = Train_Me_with(activation_function=\"selu\").fit(\n",
        "      train_data,train_labels,batch_size=20,epochs=500,validation_data=(test_data,test_labels)\n",
        "  )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 1s 32ms/step - loss: 280999872.0000 - mae: 14351.2556 - val_loss: 146549728.0000 - val_mae: 11350.7207\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 267881758.2222 - mae: 13879.8528 - val_loss: 146521952.0000 - val_mae: 11349.5186\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 295166645.3333 - mae: 14653.5821 - val_loss: 146491504.0000 - val_mae: 11348.2119\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 251047941.3333 - mae: 13393.1392 - val_loss: 146461648.0000 - val_mae: 11346.8652\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 280170830.2222 - mae: 14252.5519 - val_loss: 146431952.0000 - val_mae: 11345.5449\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 301666748.4444 - mae: 14622.4741 - val_loss: 146400320.0000 - val_mae: 11344.1934\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 286450218.6667 - mae: 14263.5050 - val_loss: 146366912.0000 - val_mae: 11342.7529\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 290055024.0000 - mae: 14220.3127 - val_loss: 146328944.0000 - val_mae: 11341.1553\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 250505496.8889 - mae: 13323.5520 - val_loss: 146291152.0000 - val_mae: 11339.5420\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 267449886.2222 - mae: 13734.5984 - val_loss: 146246848.0000 - val_mae: 11337.6709\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 307153802.6667 - mae: 14673.7270 - val_loss: 146197344.0000 - val_mae: 11335.5938\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 297755975.1111 - mae: 14409.6673 - val_loss: 146145184.0000 - val_mae: 11333.3779\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 302021664.0000 - mae: 14703.9078 - val_loss: 146086944.0000 - val_mae: 11330.9141\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 276834186.6667 - mae: 13892.4951 - val_loss: 146018736.0000 - val_mae: 11328.0312\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 293529137.7778 - mae: 14475.8878 - val_loss: 145946896.0000 - val_mae: 11324.9707\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 311325059.5556 - mae: 14908.5745 - val_loss: 145867072.0000 - val_mae: 11321.5771\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 275740865.7778 - mae: 14099.2819 - val_loss: 145776288.0000 - val_mae: 11317.7500\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 250096538.6667 - mae: 13555.0865 - val_loss: 145674864.0000 - val_mae: 11313.4404\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 283327651.5556 - mae: 14235.5327 - val_loss: 145565536.0000 - val_mae: 11308.8096\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 275621859.5556 - mae: 13994.9167 - val_loss: 145440064.0000 - val_mae: 11303.5361\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 273381824.0000 - mae: 13924.5931 - val_loss: 145317552.0000 - val_mae: 11298.3389\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 284524599.1111 - mae: 14143.5401 - val_loss: 145175248.0000 - val_mae: 11292.3047\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 288685096.8889 - mae: 14430.1981 - val_loss: 145026704.0000 - val_mae: 11285.9932\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 277508762.6667 - mae: 13978.7219 - val_loss: 144862688.0000 - val_mae: 11279.0361\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 265983584.0000 - mae: 13568.7436 - val_loss: 144673264.0000 - val_mae: 11271.0771\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 288832538.6667 - mae: 14364.4965 - val_loss: 144481728.0000 - val_mae: 11262.9746\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 248824686.2222 - mae: 13629.1453 - val_loss: 144287888.0000 - val_mae: 11254.7295\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 317029365.3333 - mae: 14760.1124 - val_loss: 144057456.0000 - val_mae: 11245.0039\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 286848007.1111 - mae: 14108.4298 - val_loss: 143839088.0000 - val_mae: 11235.6777\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 294961408.0000 - mae: 14585.3209 - val_loss: 143606416.0000 - val_mae: 11225.7549\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 271864869.3333 - mae: 13686.0186 - val_loss: 143351072.0000 - val_mae: 11214.8613\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 293283740.4444 - mae: 14336.2724 - val_loss: 143061856.0000 - val_mae: 11202.5850\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 257258357.3333 - mae: 13596.3757 - val_loss: 142755520.0000 - val_mae: 11189.5889\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 254577767.1111 - mae: 13629.3706 - val_loss: 142436944.0000 - val_mae: 11176.0361\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 238805432.8889 - mae: 13064.9227 - val_loss: 142067792.0000 - val_mae: 11160.4795\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 242728129.7778 - mae: 13348.2476 - val_loss: 141742976.0000 - val_mae: 11146.6338\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 275178458.6667 - mae: 13891.5897 - val_loss: 141381280.0000 - val_mae: 11131.2559\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 299657895.1111 - mae: 14562.6019 - val_loss: 140982736.0000 - val_mae: 11114.3408\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 235727804.4444 - mae: 13145.1036 - val_loss: 140615152.0000 - val_mae: 11098.5625\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 294120853.3333 - mae: 14287.5926 - val_loss: 140200176.0000 - val_mae: 11080.8203\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 246812531.5556 - mae: 13449.7408 - val_loss: 139771344.0000 - val_mae: 11062.4512\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 239183939.5556 - mae: 12982.6781 - val_loss: 139312960.0000 - val_mae: 11042.8076\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 275978142.2222 - mae: 14012.4654 - val_loss: 138850320.0000 - val_mae: 11022.9062\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 279216284.4444 - mae: 14101.1679 - val_loss: 138298720.0000 - val_mae: 10999.3828\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 233773064.8889 - mae: 12913.2114 - val_loss: 137750912.0000 - val_mae: 10975.8984\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 281556092.4444 - mae: 14134.3568 - val_loss: 137202032.0000 - val_mae: 10952.2549\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 260225461.3333 - mae: 13621.6073 - val_loss: 136648640.0000 - val_mae: 10928.3662\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 265486417.7778 - mae: 13669.4523 - val_loss: 136060448.0000 - val_mae: 10902.9287\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 252062901.3333 - mae: 13404.0769 - val_loss: 135335296.0000 - val_mae: 10871.8506\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 244490021.3333 - mae: 13044.3167 - val_loss: 134680048.0000 - val_mae: 10843.4326\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 257141541.3333 - mae: 13390.3156 - val_loss: 134050424.0000 - val_mae: 10815.8789\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 244942581.3333 - mae: 13281.2896 - val_loss: 133300736.0000 - val_mae: 10783.3701\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 268309164.4444 - mae: 14022.7569 - val_loss: 132572576.0000 - val_mae: 10751.6006\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 297540433.7778 - mae: 14432.7783 - val_loss: 131875656.0000 - val_mae: 10720.9258\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 249215047.1111 - mae: 13310.8339 - val_loss: 131113960.0000 - val_mae: 10687.4785\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 229871658.6667 - mae: 12664.1584 - val_loss: 130206712.0000 - val_mae: 10647.8691\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 215570880.0000 - mae: 12392.0515 - val_loss: 129336456.0000 - val_mae: 10609.5791\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 270080867.5556 - mae: 13535.2937 - val_loss: 128531592.0000 - val_mae: 10573.7314\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 228285813.3333 - mae: 12646.0309 - val_loss: 127667320.0000 - val_mae: 10535.1865\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 277358951.1111 - mae: 13929.3809 - val_loss: 126685480.0000 - val_mae: 10491.4268\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 247173100.4444 - mae: 13068.8064 - val_loss: 125762048.0000 - val_mae: 10450.0645\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 218520520.0000 - mae: 12374.7311 - val_loss: 124699480.0000 - val_mae: 10402.5361\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 246046437.3333 - mae: 13042.0795 - val_loss: 123738096.0000 - val_mae: 10359.2188\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 308489928.8889 - mae: 14431.9430 - val_loss: 122738064.0000 - val_mae: 10313.9775\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 221875760.0000 - mae: 12352.4760 - val_loss: 121605232.0000 - val_mae: 10262.6680\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 237037251.5556 - mae: 12867.4670 - val_loss: 120369088.0000 - val_mae: 10206.6582\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 220943099.5556 - mae: 12485.0540 - val_loss: 119259064.0000 - val_mae: 10155.6396\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 224152588.4444 - mae: 12350.0042 - val_loss: 118048888.0000 - val_mae: 10100.1689\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 276740055.1111 - mae: 13648.1879 - val_loss: 116799896.0000 - val_mae: 10042.6016\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 226080832.0000 - mae: 12411.0270 - val_loss: 115517576.0000 - val_mae: 9983.1973\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 240160952.8889 - mae: 12810.7400 - val_loss: 114280168.0000 - val_mae: 9925.3145\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 227044867.5556 - mae: 12343.9290 - val_loss: 112940016.0000 - val_mae: 9862.4297\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 216200472.8889 - mae: 12277.8681 - val_loss: 111566352.0000 - val_mae: 9797.7559\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 220102887.1111 - mae: 11850.7319 - val_loss: 110192072.0000 - val_mae: 9732.2979\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 236196855.1111 - mae: 12598.0041 - val_loss: 108753440.0000 - val_mae: 9663.5293\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 227340122.6667 - mae: 12450.5240 - val_loss: 107312464.0000 - val_mae: 9594.1758\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 225318352.0000 - mae: 12408.0232 - val_loss: 105660520.0000 - val_mae: 9514.5498\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 220407905.7778 - mae: 12186.3158 - val_loss: 104118472.0000 - val_mae: 9439.2842\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 235931491.5556 - mae: 12598.3372 - val_loss: 102504728.0000 - val_mae: 9360.0557\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 211519376.0000 - mae: 11833.0493 - val_loss: 100986888.0000 - val_mae: 9284.7061\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 169407354.6667 - mae: 10725.5442 - val_loss: 99156600.0000 - val_mae: 9193.6211\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 239434696.8889 - mae: 12654.5726 - val_loss: 97868456.0000 - val_mae: 9127.5879\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 164355725.3333 - mae: 10537.9248 - val_loss: 96325136.0000 - val_mae: 9048.4004\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 194859054.2222 - mae: 11092.1071 - val_loss: 94759568.0000 - val_mae: 8967.4326\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 180438448.8889 - mae: 10878.1172 - val_loss: 93025992.0000 - val_mae: 8877.4512\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 182708983.1111 - mae: 11059.1717 - val_loss: 91243360.0000 - val_mae: 8784.3184\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 152193784.8889 - mae: 10211.9340 - val_loss: 89248088.0000 - val_mae: 8679.0176\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 176750878.2222 - mae: 10941.8813 - val_loss: 87501200.0000 - val_mae: 8585.7412\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 176937768.8889 - mae: 10695.6022 - val_loss: 85689040.0000 - val_mae: 8487.7939\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 168451480.8889 - mae: 10573.8502 - val_loss: 83563512.0000 - val_mae: 8372.4600\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 162828184.0000 - mae: 10380.1453 - val_loss: 82024152.0000 - val_mae: 8286.4150\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 202882711.1111 - mae: 11136.7201 - val_loss: 80191904.0000 - val_mae: 8183.6440\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 172870972.4444 - mae: 10539.8422 - val_loss: 78257160.0000 - val_mae: 8074.1611\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 188648700.4444 - mae: 10739.1232 - val_loss: 76316064.0000 - val_mae: 7962.7490\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 173236778.6667 - mae: 10446.5014 - val_loss: 74439824.0000 - val_mae: 7853.4536\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 158446365.3333 - mae: 10025.6169 - val_loss: 72366768.0000 - val_mae: 7731.2397\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 194614551.1111 - mae: 10799.4882 - val_loss: 70412624.0000 - val_mae: 7613.6650\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 182928275.5556 - mae: 10522.7525 - val_loss: 68467368.0000 - val_mae: 7495.1602\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 162679326.2222 - mae: 9792.5060 - val_loss: 66408760.0000 - val_mae: 7367.7461\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 140464110.2222 - mae: 9327.7416 - val_loss: 64275748.0000 - val_mae: 7233.7319\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 127784947.5556 - mae: 8902.8807 - val_loss: 62037896.0000 - val_mae: 7091.3013\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 134200944.8889 - mae: 9140.5633 - val_loss: 60095212.0000 - val_mae: 6964.1978\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 147882525.3333 - mae: 9365.0839 - val_loss: 57780168.0000 - val_mae: 6811.2749\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 129747930.6667 - mae: 8904.7141 - val_loss: 55667084.0000 - val_mae: 6667.9175\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 147245781.3333 - mae: 9136.5474 - val_loss: 53731992.0000 - val_mae: 6533.0083\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 122093200.8889 - mae: 8496.6431 - val_loss: 51541828.0000 - val_mae: 6377.4800\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 101270568.8889 - mae: 7677.3126 - val_loss: 49249556.0000 - val_mae: 6212.1489\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 133915432.8889 - mae: 8626.6634 - val_loss: 47354632.0000 - val_mae: 6070.9443\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 119732684.4444 - mae: 8160.6351 - val_loss: 45415060.0000 - val_mae: 5922.9058\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 133203447.1111 - mae: 8568.3002 - val_loss: 43410676.0000 - val_mae: 5766.0615\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 114984775.1111 - mae: 7938.8581 - val_loss: 41022608.0000 - val_mae: 5575.0347\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 128556774.2222 - mae: 8198.0881 - val_loss: 39317724.0000 - val_mae: 5432.9199\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 92652600.0000 - mae: 6908.4654 - val_loss: 37309436.0000 - val_mae: 5261.7344\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 104969401.7778 - mae: 7306.1546 - val_loss: 35531996.0000 - val_mae: 5105.1978\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 107249828.4444 - mae: 7332.2818 - val_loss: 33614724.0000 - val_mae: 4932.1343\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 84349685.7778 - mae: 6468.4806 - val_loss: 31674036.0000 - val_mae: 4749.4697\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 102619128.0000 - mae: 7192.4941 - val_loss: 29796222.0000 - val_mae: 4572.8159\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 90614460.4444 - mae: 6657.5984 - val_loss: 27822464.0000 - val_mae: 4381.1475\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 87019740.8889 - mae: 6276.4239 - val_loss: 26128702.0000 - val_mae: 4209.1553\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 86662388.4444 - mae: 6289.9273 - val_loss: 24309648.0000 - val_mae: 4015.8455\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 78150599.1111 - mae: 5745.4360 - val_loss: 22674280.0000 - val_mae: 3834.5015\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 82462943.1111 - mae: 6167.1793 - val_loss: 21069142.0000 - val_mae: 3655.4446\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 67895411.5556 - mae: 5385.8072 - val_loss: 19415462.0000 - val_mae: 3468.9438\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 64079760.4444 - mae: 5085.7037 - val_loss: 18034256.0000 - val_mae: 3308.9043\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 64642821.3333 - mae: 4864.9863 - val_loss: 16497534.0000 - val_mae: 3123.0625\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 63785710.2222 - mae: 4871.8772 - val_loss: 15095878.0000 - val_mae: 2949.7554\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 74957802.6667 - mae: 5195.1815 - val_loss: 13955958.0000 - val_mae: 2803.6218\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 64698598.6667 - mae: 4822.5747 - val_loss: 12751821.0000 - val_mae: 2663.4678\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 57379905.3333 - mae: 4558.9198 - val_loss: 11573461.0000 - val_mae: 2513.9583\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 45389719.5556 - mae: 3933.1814 - val_loss: 10606200.0000 - val_mae: 2382.5520\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 45365143.7778 - mae: 3951.2859 - val_loss: 9635213.0000 - val_mae: 2242.5066\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 44982491.3333 - mae: 3695.4573 - val_loss: 9089166.0000 - val_mae: 2161.3665\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 39563453.7778 - mae: 3753.6726 - val_loss: 8470405.0000 - val_mae: 2065.1885\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 40653662.2222 - mae: 3731.7956 - val_loss: 7808607.0000 - val_mae: 1960.1436\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 34801077.3333 - mae: 3526.1872 - val_loss: 7382452.5000 - val_mae: 1890.3885\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 40829123.3333 - mae: 3833.9588 - val_loss: 7044358.0000 - val_mae: 1850.0537\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 43003242.6667 - mae: 3798.5206 - val_loss: 6749398.0000 - val_mae: 1821.4342\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 38863318.4444 - mae: 3678.6672 - val_loss: 6532274.0000 - val_mae: 1797.5002\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 31953000.2222 - mae: 3368.2084 - val_loss: 6400526.5000 - val_mae: 1788.9209\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 27165445.3333 - mae: 3230.6392 - val_loss: 6385735.0000 - val_mae: 1788.6805\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 31975841.1111 - mae: 3597.1957 - val_loss: 6421450.5000 - val_mae: 1797.5001\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 29392347.3333 - mae: 3458.3481 - val_loss: 6482991.5000 - val_mae: 1809.9791\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 33308217.3333 - mae: 3810.5106 - val_loss: 6560858.0000 - val_mae: 1826.1313\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 28814113.3333 - mae: 3456.9331 - val_loss: 6834486.5000 - val_mae: 1876.7756\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 29240552.2222 - mae: 3541.6540 - val_loss: 6928344.5000 - val_mae: 1894.9873\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 27689181.5556 - mae: 3477.8046 - val_loss: 7122664.5000 - val_mae: 1931.8651\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 26524853.1111 - mae: 3461.5940 - val_loss: 7291250.5000 - val_mae: 1960.5436\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 21523817.5556 - mae: 3195.3722 - val_loss: 7436461.5000 - val_mae: 1981.8181\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 26696425.7778 - mae: 3640.1117 - val_loss: 7539332.5000 - val_mae: 1997.4336\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 27137434.0000 - mae: 3581.4297 - val_loss: 7642872.5000 - val_mae: 2012.3662\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 21281221.1111 - mae: 3319.5255 - val_loss: 7769005.5000 - val_mae: 2029.4220\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 28052462.8889 - mae: 3586.8815 - val_loss: 7902702.0000 - val_mae: 2046.2145\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 23087742.8889 - mae: 3375.9244 - val_loss: 8287700.5000 - val_mae: 2104.4487\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18690216.7778 - mae: 3111.0952 - val_loss: 8390767.0000 - val_mae: 2118.3281\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 23316576.4444 - mae: 3381.9796 - val_loss: 8813372.0000 - val_mae: 2179.1265\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 20061422.6667 - mae: 3196.7782 - val_loss: 9059154.0000 - val_mae: 2211.0662\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18749565.8889 - mae: 3275.1766 - val_loss: 9036908.0000 - val_mae: 2202.6240\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 23549609.3333 - mae: 3522.5087 - val_loss: 9066409.0000 - val_mae: 2206.6985\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 22061932.8889 - mae: 3464.6584 - val_loss: 9485292.0000 - val_mae: 2270.2375\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18940880.4444 - mae: 3187.2631 - val_loss: 9315975.0000 - val_mae: 2243.5381\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 26037284.0000 - mae: 3612.3295 - val_loss: 9250308.0000 - val_mae: 2234.1580\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19983839.7778 - mae: 3234.7538 - val_loss: 9705191.0000 - val_mae: 2301.2505\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 22951160.6667 - mae: 3476.3075 - val_loss: 9693088.0000 - val_mae: 2299.9485\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 17332299.9444 - mae: 3020.7477 - val_loss: 9396412.0000 - val_mae: 2258.0803\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19764600.6667 - mae: 3385.6162 - val_loss: 9576293.0000 - val_mae: 2285.0605\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19536284.2222 - mae: 3208.4531 - val_loss: 9420136.0000 - val_mae: 2265.1621\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 21168393.7778 - mae: 3233.4666 - val_loss: 9190997.0000 - val_mae: 2236.8748\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 20037397.6111 - mae: 3145.7346 - val_loss: 9493291.0000 - val_mae: 2280.9207\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 20564669.1111 - mae: 3176.3060 - val_loss: 9813589.0000 - val_mae: 2330.2656\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 21641032.6667 - mae: 3338.2467 - val_loss: 9659946.0000 - val_mae: 2310.9207\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18390250.0000 - mae: 3106.7783 - val_loss: 9803272.0000 - val_mae: 2333.6060\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17078588.3333 - mae: 3081.0326 - val_loss: 10174176.0000 - val_mae: 2388.0493\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16316634.3333 - mae: 3057.1416 - val_loss: 9815893.0000 - val_mae: 2342.3276\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16116437.7778 - mae: 2984.5319 - val_loss: 9634639.0000 - val_mae: 2319.6091\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 22855514.0000 - mae: 3495.5646 - val_loss: 9685278.0000 - val_mae: 2329.5583\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 18874626.8889 - mae: 3227.1518 - val_loss: 9707284.0000 - val_mae: 2336.5303\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 17306973.2222 - mae: 3183.5343 - val_loss: 10033291.0000 - val_mae: 2384.4521\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 20145233.3333 - mae: 3321.8832 - val_loss: 9894415.0000 - val_mae: 2369.7908\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 17225148.2222 - mae: 3128.9486 - val_loss: 9763747.0000 - val_mae: 2356.0710\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 19108170.2222 - mae: 3203.4301 - val_loss: 9712374.0000 - val_mae: 2348.2866\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16592978.7778 - mae: 2955.5612 - val_loss: 9789893.0000 - val_mae: 2358.9382\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18430173.1111 - mae: 3245.8021 - val_loss: 9826050.0000 - val_mae: 2367.0762\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17652602.8889 - mae: 3099.3968 - val_loss: 9834277.0000 - val_mae: 2371.3931\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18779375.3333 - mae: 3262.4354 - val_loss: 9588373.0000 - val_mae: 2336.2561\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17034362.2222 - mae: 3013.8596 - val_loss: 9637025.0000 - val_mae: 2347.2563\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15814388.4444 - mae: 2949.1377 - val_loss: 9877066.0000 - val_mae: 2385.5950\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 17228963.8889 - mae: 3154.2281 - val_loss: 9689868.0000 - val_mae: 2357.9597\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16160604.6667 - mae: 2975.7370 - val_loss: 9588767.0000 - val_mae: 2342.5674\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15965729.1111 - mae: 2956.7528 - val_loss: 9495722.0000 - val_mae: 2334.0945\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17243119.2222 - mae: 3019.2924 - val_loss: 9349387.0000 - val_mae: 2315.3677\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15029410.4444 - mae: 2908.0312 - val_loss: 9414280.0000 - val_mae: 2323.7839\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16634499.1111 - mae: 2993.7887 - val_loss: 9568962.0000 - val_mae: 2344.4583\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14912670.5556 - mae: 2876.6292 - val_loss: 9550441.0000 - val_mae: 2345.1667\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18087383.2222 - mae: 3134.3955 - val_loss: 9965617.0000 - val_mae: 2406.0667\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19022190.0000 - mae: 3146.2438 - val_loss: 10101555.0000 - val_mae: 2427.6423\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 16613976.1111 - mae: 2952.9731 - val_loss: 9982467.0000 - val_mae: 2412.1423\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18543832.6667 - mae: 3193.3877 - val_loss: 10114007.0000 - val_mae: 2431.0691\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15967861.0000 - mae: 2981.0082 - val_loss: 10431689.0000 - val_mae: 2476.4250\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17227386.6667 - mae: 3057.6700 - val_loss: 10342600.0000 - val_mae: 2463.8816\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13581198.5000 - mae: 2710.7462 - val_loss: 10310317.0000 - val_mae: 2462.2354\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13262029.0000 - mae: 2768.6095 - val_loss: 10263611.0000 - val_mae: 2456.5999\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16991839.0000 - mae: 3028.6797 - val_loss: 10480469.0000 - val_mae: 2487.0640\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15312848.1111 - mae: 2939.0888 - val_loss: 10626583.0000 - val_mae: 2507.0012\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15029483.2222 - mae: 2849.3669 - val_loss: 10775803.0000 - val_mae: 2526.0081\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13775116.1111 - mae: 2816.4365 - val_loss: 10844110.0000 - val_mae: 2531.8552\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13635416.1111 - mae: 2805.8861 - val_loss: 10477490.0000 - val_mae: 2486.3992\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13004073.7778 - mae: 2658.0762 - val_loss: 10745047.0000 - val_mae: 2520.0498\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 15909582.2222 - mae: 2975.9374 - val_loss: 10649385.0000 - val_mae: 2508.8760\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16294079.3333 - mae: 2946.9849 - val_loss: 10589575.0000 - val_mae: 2498.4746\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14133367.3333 - mae: 2813.4584 - val_loss: 10292889.0000 - val_mae: 2458.4092\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14625624.8889 - mae: 2893.3371 - val_loss: 10649985.0000 - val_mae: 2504.9043\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14183982.6667 - mae: 2847.3351 - val_loss: 10434012.0000 - val_mae: 2477.8359\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16951299.2222 - mae: 3103.8679 - val_loss: 10468046.0000 - val_mae: 2480.4800\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13981668.4444 - mae: 2903.8787 - val_loss: 10414251.0000 - val_mae: 2472.1675\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14679288.5556 - mae: 2810.3190 - val_loss: 10404636.0000 - val_mae: 2467.9189\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14742347.0000 - mae: 2841.3107 - val_loss: 10199913.0000 - val_mae: 2439.6282\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12668754.0000 - mae: 2641.0105 - val_loss: 10179083.0000 - val_mae: 2437.3916\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12877027.5556 - mae: 2667.7957 - val_loss: 10072769.0000 - val_mae: 2424.2490\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13988507.0000 - mae: 2706.9802 - val_loss: 9958945.0000 - val_mae: 2407.1921\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11659387.6667 - mae: 2510.2829 - val_loss: 10024302.0000 - val_mae: 2416.2949\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14569447.4444 - mae: 2776.2133 - val_loss: 10045800.0000 - val_mae: 2418.4412\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12935031.5556 - mae: 2694.5291 - val_loss: 9987484.0000 - val_mae: 2412.1819\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15642605.4444 - mae: 2874.5769 - val_loss: 10186236.0000 - val_mae: 2436.9285\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14774860.4444 - mae: 2787.9037 - val_loss: 10268110.0000 - val_mae: 2447.7488\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15272258.4444 - mae: 2872.3052 - val_loss: 10442358.0000 - val_mae: 2467.7964\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15604312.3333 - mae: 2923.2409 - val_loss: 10413425.0000 - val_mae: 2462.7434\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12805894.3333 - mae: 2688.9346 - val_loss: 10742044.0000 - val_mae: 2501.2056\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12152820.8889 - mae: 2591.5718 - val_loss: 10923682.0000 - val_mae: 2520.0974\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12470628.8889 - mae: 2659.3397 - val_loss: 10846713.0000 - val_mae: 2509.6863\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14424121.7778 - mae: 2800.5127 - val_loss: 10805004.0000 - val_mae: 2501.6226\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13609247.5556 - mae: 2717.7432 - val_loss: 10686218.0000 - val_mae: 2483.0803\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14450347.8889 - mae: 2750.7673 - val_loss: 10653013.0000 - val_mae: 2475.6965\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12117612.5556 - mae: 2613.6600 - val_loss: 10529577.0000 - val_mae: 2459.0554\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12255953.6667 - mae: 2647.3443 - val_loss: 10488434.0000 - val_mae: 2456.6829\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13716595.4444 - mae: 2636.4042 - val_loss: 10861950.0000 - val_mae: 2499.0059\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12528829.8889 - mae: 2485.6558 - val_loss: 11122308.0000 - val_mae: 2531.1001\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11985947.0000 - mae: 2551.5407 - val_loss: 10956412.0000 - val_mae: 2520.5278\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14072325.2222 - mae: 2679.4469 - val_loss: 10931759.0000 - val_mae: 2522.2378\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12306799.0000 - mae: 2612.9930 - val_loss: 11330272.0000 - val_mae: 2564.6973\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11070765.6667 - mae: 2492.6699 - val_loss: 11357898.0000 - val_mae: 2572.0566\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10012597.1667 - mae: 2253.4710 - val_loss: 11696134.0000 - val_mae: 2608.3367\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 11389373.1111 - mae: 2490.9004 - val_loss: 11964547.0000 - val_mae: 2638.1995\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 11543184.1111 - mae: 2459.3898 - val_loss: 11958019.0000 - val_mae: 2642.6970\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 11137216.7778 - mae: 2428.4282 - val_loss: 11944490.0000 - val_mae: 2644.0103\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14588941.7778 - mae: 2777.3396 - val_loss: 11757544.0000 - val_mae: 2637.6240\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10199969.3889 - mae: 2335.3374 - val_loss: 11521096.0000 - val_mae: 2622.8538\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12176316.3333 - mae: 2535.7000 - val_loss: 11639770.0000 - val_mae: 2636.2600\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12647971.1111 - mae: 2615.3799 - val_loss: 11738942.0000 - val_mae: 2646.1272\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11070787.8889 - mae: 2489.1999 - val_loss: 11764798.0000 - val_mae: 2654.2529\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11723306.3333 - mae: 2451.1938 - val_loss: 11829601.0000 - val_mae: 2666.3108\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9182872.0000 - mae: 2241.2228 - val_loss: 11916318.0000 - val_mae: 2676.3997\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10133478.0000 - mae: 2359.9798 - val_loss: 12144168.0000 - val_mae: 2696.3342\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9128570.3333 - mae: 2202.6610 - val_loss: 12234587.0000 - val_mae: 2705.7654\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11975956.5556 - mae: 2433.3771 - val_loss: 12178294.0000 - val_mae: 2701.7883\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10472052.6667 - mae: 2313.0771 - val_loss: 12285474.0000 - val_mae: 2713.3958\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10024321.6667 - mae: 2244.7531 - val_loss: 12454208.0000 - val_mae: 2734.1079\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 10226120.1667 - mae: 2302.4164 - val_loss: 12527613.0000 - val_mae: 2740.6692\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10555689.0000 - mae: 2331.3850 - val_loss: 12671493.0000 - val_mae: 2750.3362\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11091521.8889 - mae: 2439.8018 - val_loss: 12631937.0000 - val_mae: 2749.7385\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9704114.4444 - mae: 2212.8955 - val_loss: 12448823.0000 - val_mae: 2743.3254\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9862722.3333 - mae: 2359.5532 - val_loss: 12555990.0000 - val_mae: 2761.0740\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9963505.1111 - mae: 2349.2448 - val_loss: 12791282.0000 - val_mae: 2774.4700\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11830547.3333 - mae: 2461.5556 - val_loss: 12741653.0000 - val_mae: 2773.2756\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8186009.9444 - mae: 2153.6382 - val_loss: 13061144.0000 - val_mae: 2800.2996\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11114366.3333 - mae: 2434.1121 - val_loss: 13169053.0000 - val_mae: 2813.9858\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9422848.8889 - mae: 2284.2204 - val_loss: 12938708.0000 - val_mae: 2796.8723\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9689386.0556 - mae: 2246.8363 - val_loss: 12771293.0000 - val_mae: 2786.8604\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10182992.6667 - mae: 2380.7356 - val_loss: 12861238.0000 - val_mae: 2791.0037\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9691631.9444 - mae: 2275.8419 - val_loss: 12724100.0000 - val_mae: 2784.0757\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9073338.5556 - mae: 2170.4599 - val_loss: 12779808.0000 - val_mae: 2789.6106\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8406368.6667 - mae: 2110.4514 - val_loss: 12717724.0000 - val_mae: 2783.5166\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 9300268.9444 - mae: 2242.5311 - val_loss: 12842020.0000 - val_mae: 2788.7239\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9950786.8889 - mae: 2267.4194 - val_loss: 12978050.0000 - val_mae: 2799.1123\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9384576.6111 - mae: 2271.3648 - val_loss: 13070810.0000 - val_mae: 2801.8657\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 10320537.3333 - mae: 2341.4986 - val_loss: 13189719.0000 - val_mae: 2806.4668\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 10614443.3333 - mae: 2358.6119 - val_loss: 13064223.0000 - val_mae: 2800.1980\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 10174194.7778 - mae: 2284.3058 - val_loss: 13102622.0000 - val_mae: 2801.1172\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7449888.1667 - mae: 1963.3691 - val_loss: 13128745.0000 - val_mae: 2802.5151\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8916032.3333 - mae: 2130.3717 - val_loss: 13084121.0000 - val_mae: 2797.2751\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8790472.8889 - mae: 2133.3831 - val_loss: 13130316.0000 - val_mae: 2799.1028\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9837235.8889 - mae: 2272.3204 - val_loss: 13164866.0000 - val_mae: 2809.5088\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9054922.8333 - mae: 2060.3610 - val_loss: 13255033.0000 - val_mae: 2815.7329\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8009346.8889 - mae: 2059.0870 - val_loss: 13338419.0000 - val_mae: 2823.9365\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7416891.6111 - mae: 1902.6337 - val_loss: 13383136.0000 - val_mae: 2831.7949\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7285930.8889 - mae: 1955.5738 - val_loss: 13507836.0000 - val_mae: 2837.7476\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7785699.1111 - mae: 1934.7333 - val_loss: 13811845.0000 - val_mae: 2852.1250\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8683364.4444 - mae: 2135.9522 - val_loss: 14090919.0000 - val_mae: 2873.2361\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6369287.7778 - mae: 1802.3937 - val_loss: 14318251.0000 - val_mae: 2893.7097\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8310463.7778 - mae: 2007.8957 - val_loss: 14461487.0000 - val_mae: 2906.6243\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7601817.5833 - mae: 1964.3784 - val_loss: 14334415.0000 - val_mae: 2902.9377\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8451745.5000 - mae: 2046.3125 - val_loss: 14287419.0000 - val_mae: 2906.5503\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 7895147.5000 - mae: 2031.3352 - val_loss: 14253269.0000 - val_mae: 2903.4224\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9039441.3333 - mae: 2071.3998 - val_loss: 14191458.0000 - val_mae: 2903.5786\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8405622.7222 - mae: 2004.2652 - val_loss: 14160600.0000 - val_mae: 2893.2271\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7750798.6667 - mae: 1930.5476 - val_loss: 14334954.0000 - val_mae: 2905.0994\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6716256.4444 - mae: 1816.3345 - val_loss: 14607786.0000 - val_mae: 2924.8069\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6649720.9444 - mae: 1804.4713 - val_loss: 14639133.0000 - val_mae: 2931.7092\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7110918.7222 - mae: 1843.8558 - val_loss: 14584966.0000 - val_mae: 2933.6370\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7795186.7222 - mae: 1898.9201 - val_loss: 14376380.0000 - val_mae: 2915.1543\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7716322.1667 - mae: 1894.9404 - val_loss: 14367464.0000 - val_mae: 2906.8892\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8088065.6667 - mae: 1937.3907 - val_loss: 14245452.0000 - val_mae: 2896.5012\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6699030.6111 - mae: 1766.3693 - val_loss: 14339061.0000 - val_mae: 2905.8982\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6796241.6944 - mae: 1740.0661 - val_loss: 14448694.0000 - val_mae: 2909.7986\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5712393.8056 - mae: 1675.0337 - val_loss: 14350168.0000 - val_mae: 2901.9893\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6684357.0000 - mae: 1808.0836 - val_loss: 14502786.0000 - val_mae: 2910.5393\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6218676.6667 - mae: 1752.2303 - val_loss: 14607436.0000 - val_mae: 2921.4700\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5321778.9167 - mae: 1635.9294 - val_loss: 14564808.0000 - val_mae: 2916.0999\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6212051.8611 - mae: 1681.7823 - val_loss: 14461309.0000 - val_mae: 2904.4060\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6663152.0556 - mae: 1828.3912 - val_loss: 14307289.0000 - val_mae: 2889.1472\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6339931.2778 - mae: 1700.6248 - val_loss: 14331305.0000 - val_mae: 2890.2783\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7062209.5000 - mae: 1807.3343 - val_loss: 14371386.0000 - val_mae: 2893.6636\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5325345.1806 - mae: 1518.5067 - val_loss: 14391288.0000 - val_mae: 2891.4094\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7897551.6111 - mae: 1848.4013 - val_loss: 14510343.0000 - val_mae: 2899.3367\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6509085.3333 - mae: 1771.3611 - val_loss: 14597850.0000 - val_mae: 2902.9617\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5538098.0000 - mae: 1591.3010 - val_loss: 14466247.0000 - val_mae: 2890.2529\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6110360.7778 - mae: 1669.4823 - val_loss: 14313352.0000 - val_mae: 2880.1863\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5455329.6667 - mae: 1646.9158 - val_loss: 14508139.0000 - val_mae: 2881.3901\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7015406.5000 - mae: 1786.4002 - val_loss: 14692837.0000 - val_mae: 2891.0762\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5333149.0000 - mae: 1545.5333 - val_loss: 14541177.0000 - val_mae: 2884.7124\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5974227.6111 - mae: 1583.3915 - val_loss: 14357717.0000 - val_mae: 2873.1694\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5081045.0278 - mae: 1546.5798 - val_loss: 14346660.0000 - val_mae: 2868.4680\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4922521.6944 - mae: 1534.4294 - val_loss: 14453122.0000 - val_mae: 2874.8831\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7059591.5000 - mae: 1714.2088 - val_loss: 14532556.0000 - val_mae: 2880.3484\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5295600.0556 - mae: 1572.6477 - val_loss: 14608075.0000 - val_mae: 2878.9983\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4398812.2083 - mae: 1400.9164 - val_loss: 14673771.0000 - val_mae: 2875.6682\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5395800.2500 - mae: 1528.2495 - val_loss: 14638434.0000 - val_mae: 2874.7681\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5699493.5000 - mae: 1599.6625 - val_loss: 14719075.0000 - val_mae: 2876.9246\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4987030.6667 - mae: 1458.1519 - val_loss: 14807739.0000 - val_mae: 2878.7844\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5361161.2778 - mae: 1571.1842 - val_loss: 14902893.0000 - val_mae: 2879.3965\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3907777.7778 - mae: 1313.5300 - val_loss: 14909879.0000 - val_mae: 2876.4465\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4357892.6111 - mae: 1369.1174 - val_loss: 14673399.0000 - val_mae: 2867.5066\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7049056.1667 - mae: 1707.2124 - val_loss: 14559245.0000 - val_mae: 2861.4575\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4367325.9722 - mae: 1350.6608 - val_loss: 14390172.0000 - val_mae: 2846.7727\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5038686.9167 - mae: 1462.7672 - val_loss: 14450991.0000 - val_mae: 2848.5422\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5166692.5556 - mae: 1444.5531 - val_loss: 14426008.0000 - val_mae: 2845.2830\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5883040.1111 - mae: 1559.8698 - val_loss: 14639923.0000 - val_mae: 2854.7361\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4988057.8611 - mae: 1494.4838 - val_loss: 14822189.0000 - val_mae: 2862.5923\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4533592.9444 - mae: 1397.9731 - val_loss: 14979268.0000 - val_mae: 2869.6052\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5300270.3889 - mae: 1530.3825 - val_loss: 15043921.0000 - val_mae: 2872.3625\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4888586.7778 - mae: 1385.9425 - val_loss: 14825670.0000 - val_mae: 2861.3220\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5000377.9444 - mae: 1468.9854 - val_loss: 15036942.0000 - val_mae: 2870.4556\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4236905.5000 - mae: 1356.9899 - val_loss: 15140467.0000 - val_mae: 2875.5520\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5037598.2778 - mae: 1421.6325 - val_loss: 15215109.0000 - val_mae: 2877.9846\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4746828.6111 - mae: 1406.1764 - val_loss: 14834847.0000 - val_mae: 2849.3442\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4044544.7083 - mae: 1297.1625 - val_loss: 14839535.0000 - val_mae: 2850.7922\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3970632.5278 - mae: 1253.2374 - val_loss: 15107743.0000 - val_mae: 2869.5127\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3530500.8611 - mae: 1211.8829 - val_loss: 14957884.0000 - val_mae: 2857.7380\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5781875.3889 - mae: 1519.2757 - val_loss: 14937280.0000 - val_mae: 2854.8040\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4058362.3333 - mae: 1245.3336 - val_loss: 14831402.0000 - val_mae: 2849.0000\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3729782.2500 - mae: 1250.9008 - val_loss: 15227158.0000 - val_mae: 2873.4094\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4576146.7778 - mae: 1382.2892 - val_loss: 15238018.0000 - val_mae: 2870.8120\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3661284.9306 - mae: 1232.6826 - val_loss: 15293128.0000 - val_mae: 2872.0107\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5349876.3889 - mae: 1480.4966 - val_loss: 15335756.0000 - val_mae: 2873.1091\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4377803.8611 - mae: 1277.1617 - val_loss: 15242075.0000 - val_mae: 2863.7329\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3239572.0000 - mae: 1139.9417 - val_loss: 15256882.0000 - val_mae: 2865.1814\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4652454.1389 - mae: 1331.8249 - val_loss: 14931317.0000 - val_mae: 2843.2349\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4050425.3056 - mae: 1288.6380 - val_loss: 15048803.0000 - val_mae: 2843.9236\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3922653.1944 - mae: 1295.9319 - val_loss: 15348945.0000 - val_mae: 2867.4065\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3739967.7778 - mae: 1148.7123 - val_loss: 15124987.0000 - val_mae: 2848.6040\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4123706.4167 - mae: 1257.4152 - val_loss: 14901741.0000 - val_mae: 2828.8066\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3382189.8611 - mae: 1190.0077 - val_loss: 14965299.0000 - val_mae: 2832.3813\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3024854.6111 - mae: 1073.6062 - val_loss: 14990722.0000 - val_mae: 2833.9998\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3294391.6111 - mae: 1207.3177 - val_loss: 15072840.0000 - val_mae: 2837.8232\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2938429.4722 - mae: 1096.1770 - val_loss: 15292562.0000 - val_mae: 2853.6194\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3224713.7639 - mae: 1128.6091 - val_loss: 15317935.0000 - val_mae: 2854.8538\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3991777.6111 - mae: 1157.7244 - val_loss: 15185842.0000 - val_mae: 2842.2820\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3203119.2500 - mae: 1161.3794 - val_loss: 14800661.0000 - val_mae: 2819.0891\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2554617.2500 - mae: 1061.9514 - val_loss: 14929822.0000 - val_mae: 2823.9502\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3641937.3611 - mae: 1263.4392 - val_loss: 15082860.0000 - val_mae: 2833.6321\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3499051.7222 - mae: 1185.2976 - val_loss: 15114521.0000 - val_mae: 2834.9062\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2863222.1944 - mae: 1008.3882 - val_loss: 15422177.0000 - val_mae: 2855.1477\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3981875.5278 - mae: 1219.1620 - val_loss: 15295725.0000 - val_mae: 2850.5312\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3519545.0000 - mae: 1160.0897 - val_loss: 15050027.0000 - val_mae: 2835.5212\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3227381.1111 - mae: 1150.8376 - val_loss: 15449941.0000 - val_mae: 2860.1926\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3742927.2222 - mae: 1195.0043 - val_loss: 15418257.0000 - val_mae: 2855.6577\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3250554.7500 - mae: 1131.6389 - val_loss: 15733876.0000 - val_mae: 2880.0522\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3683761.2222 - mae: 1121.5961 - val_loss: 15598065.0000 - val_mae: 2868.0635\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3068111.8333 - mae: 1067.4226 - val_loss: 15614241.0000 - val_mae: 2868.5295\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2876070.5139 - mae: 1061.1151 - val_loss: 15440246.0000 - val_mae: 2860.8481\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2845856.8750 - mae: 1004.9485 - val_loss: 15446328.0000 - val_mae: 2857.6389\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2896425.0556 - mae: 1075.9259 - val_loss: 15491364.0000 - val_mae: 2857.5083\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2747626.0556 - mae: 1003.5558 - val_loss: 15314808.0000 - val_mae: 2849.7188\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2892022.2708 - mae: 1016.6099 - val_loss: 15427853.0000 - val_mae: 2853.0173\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2881399.3333 - mae: 1010.7483 - val_loss: 15747978.0000 - val_mae: 2877.2202\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3906132.0000 - mae: 1162.0335 - val_loss: 15671773.0000 - val_mae: 2871.4163\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2077708.2917 - mae: 905.7270 - val_loss: 15317844.0000 - val_mae: 2846.4944\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2775726.7222 - mae: 1007.5120 - val_loss: 15166001.0000 - val_mae: 2835.0483\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3030008.9167 - mae: 950.5939 - val_loss: 15251703.0000 - val_mae: 2836.4673\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2799859.6528 - mae: 1066.3657 - val_loss: 15394988.0000 - val_mae: 2841.9512\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2552340.2778 - mae: 1050.0194 - val_loss: 15334522.0000 - val_mae: 2839.6506\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3228719.2222 - mae: 1016.6114 - val_loss: 15258094.0000 - val_mae: 2838.6350\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2493375.7222 - mae: 999.2106 - val_loss: 15258798.0000 - val_mae: 2841.3464\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1937962.0486 - mae: 896.6563 - val_loss: 15507572.0000 - val_mae: 2855.2107\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2004827.4375 - mae: 881.4891 - val_loss: 15646106.0000 - val_mae: 2864.6216\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3213034.9167 - mae: 1054.9701 - val_loss: 15535032.0000 - val_mae: 2859.5159\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2351996.2778 - mae: 915.2272 - val_loss: 15695823.0000 - val_mae: 2870.8604\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2571281.1389 - mae: 954.4962 - val_loss: 15561960.0000 - val_mae: 2863.0940\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2329050.0556 - mae: 908.6034 - val_loss: 15563748.0000 - val_mae: 2864.5891\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2331835.6250 - mae: 938.7601 - val_loss: 15583894.0000 - val_mae: 2865.7041\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2137850.3333 - mae: 936.9380 - val_loss: 15858119.0000 - val_mae: 2882.2959\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2572474.5000 - mae: 924.2464 - val_loss: 15352603.0000 - val_mae: 2847.7881\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2043995.3056 - mae: 902.2318 - val_loss: 15540517.0000 - val_mae: 2862.3916\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1952085.5278 - mae: 887.5399 - val_loss: 15974850.0000 - val_mae: 2891.5767\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2868811.0556 - mae: 1001.9221 - val_loss: 15924862.0000 - val_mae: 2888.1189\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2504385.5972 - mae: 970.4318 - val_loss: 16030611.0000 - val_mae: 2895.4854\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2010112.3611 - mae: 902.2110 - val_loss: 16006016.0000 - val_mae: 2896.9958\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1898280.4306 - mae: 896.4905 - val_loss: 16002913.0000 - val_mae: 2895.9731\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1770987.0764 - mae: 827.9885 - val_loss: 16160276.0000 - val_mae: 2907.3550\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2190635.4306 - mae: 885.1740 - val_loss: 16247683.0000 - val_mae: 2911.9187\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2223039.7014 - mae: 904.3958 - val_loss: 16068154.0000 - val_mae: 2902.1504\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1529667.9236 - mae: 804.8444 - val_loss: 16447457.0000 - val_mae: 2932.1069\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2182278.9583 - mae: 927.2307 - val_loss: 16366514.0000 - val_mae: 2927.4060\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2637281.1667 - mae: 904.6129 - val_loss: 16208191.0000 - val_mae: 2917.3462\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1748776.4861 - mae: 813.7816 - val_loss: 16248474.0000 - val_mae: 2918.8757\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1599795.2708 - mae: 789.9391 - val_loss: 16197257.0000 - val_mae: 2915.0342\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1685651.1111 - mae: 836.9326 - val_loss: 16474821.0000 - val_mae: 2938.1599\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1893302.9444 - mae: 845.1034 - val_loss: 16532861.0000 - val_mae: 2941.3831\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2372581.5000 - mae: 917.9310 - val_loss: 16377513.0000 - val_mae: 2923.3721\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1724822.8750 - mae: 815.6530 - val_loss: 16410969.0000 - val_mae: 2922.7190\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1684856.3333 - mae: 812.8815 - val_loss: 16060122.0000 - val_mae: 2894.2688\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2500613.8194 - mae: 881.9682 - val_loss: 16212540.0000 - val_mae: 2905.9434\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2541361.8333 - mae: 868.6818 - val_loss: 16010649.0000 - val_mae: 2889.8438\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2070483.7500 - mae: 819.6497 - val_loss: 16054879.0000 - val_mae: 2894.8740\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2224535.0556 - mae: 798.8237 - val_loss: 15965061.0000 - val_mae: 2883.9680\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1337370.8194 - mae: 701.9456 - val_loss: 16592047.0000 - val_mae: 2929.8923\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2148892.1528 - mae: 787.6938 - val_loss: 16302740.0000 - val_mae: 2909.8916\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1517426.3403 - mae: 740.5899 - val_loss: 16502397.0000 - val_mae: 2926.3992\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2211702.6111 - mae: 813.7626 - val_loss: 16072681.0000 - val_mae: 2898.6030\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1448210.4861 - mae: 782.0112 - val_loss: 16344180.0000 - val_mae: 2912.1018\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1770425.9444 - mae: 772.3205 - val_loss: 16179291.0000 - val_mae: 2901.1370\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1854430.8472 - mae: 808.9810 - val_loss: 16378642.0000 - val_mae: 2915.6416\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2257703.5694 - mae: 827.6459 - val_loss: 16339607.0000 - val_mae: 2916.9580\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2417089.0278 - mae: 846.7353 - val_loss: 16410517.0000 - val_mae: 2921.1440\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1494714.7222 - mae: 724.3039 - val_loss: 16422033.0000 - val_mae: 2920.7244\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1218654.2569 - mae: 687.8601 - val_loss: 16782212.0000 - val_mae: 2947.7502\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1456838.5833 - mae: 755.1419 - val_loss: 16750118.0000 - val_mae: 2946.2842\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1195543.7674 - mae: 636.7321 - val_loss: 16853546.0000 - val_mae: 2950.6665\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1381823.0833 - mae: 697.3542 - val_loss: 16568778.0000 - val_mae: 2929.7788\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1619237.0000 - mae: 770.1912 - val_loss: 16623731.0000 - val_mae: 2935.0322\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1278250.3403 - mae: 689.5668 - val_loss: 16783042.0000 - val_mae: 2950.0349\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1337550.3681 - mae: 700.0240 - val_loss: 16632684.0000 - val_mae: 2938.5220\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1408190.4306 - mae: 685.9538 - val_loss: 16943262.0000 - val_mae: 2955.4319\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1269354.6181 - mae: 665.2812 - val_loss: 17107922.0000 - val_mae: 2969.2351\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2169700.5278 - mae: 842.0191 - val_loss: 17020284.0000 - val_mae: 2955.5972\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1828544.7153 - mae: 766.5435 - val_loss: 16923956.0000 - val_mae: 2946.4709\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1481870.5312 - mae: 646.2787 - val_loss: 16528242.0000 - val_mae: 2924.1663\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1764920.3750 - mae: 749.6616 - val_loss: 16552172.0000 - val_mae: 2930.3538\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1652810.7778 - mae: 723.0284 - val_loss: 16788338.0000 - val_mae: 2944.1245\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1276716.3681 - mae: 639.1814 - val_loss: 16902198.0000 - val_mae: 2953.1174\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1190748.0139 - mae: 680.5731 - val_loss: 16999814.0000 - val_mae: 2957.6853\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1347504.8750 - mae: 690.6115 - val_loss: 17244854.0000 - val_mae: 2979.8110\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1131885.2778 - mae: 637.4976 - val_loss: 17626836.0000 - val_mae: 3005.4529\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1177132.4653 - mae: 637.0462 - val_loss: 17085038.0000 - val_mae: 2965.8298\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1477922.5938 - mae: 667.7520 - val_loss: 16855604.0000 - val_mae: 2948.5750\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1536544.4306 - mae: 658.7247 - val_loss: 16533817.0000 - val_mae: 2929.8645\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1071525.1250 - mae: 620.1493 - val_loss: 16905636.0000 - val_mae: 2953.8999\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1300680.7986 - mae: 654.7569 - val_loss: 16624664.0000 - val_mae: 2931.3154\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1133772.0903 - mae: 671.5465 - val_loss: 16908120.0000 - val_mae: 2947.1965\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1296410.4861 - mae: 679.2166 - val_loss: 16874942.0000 - val_mae: 2947.1812\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1079557.4931 - mae: 616.3834 - val_loss: 16877860.0000 - val_mae: 2947.8130\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1086615.1667 - mae: 580.6992 - val_loss: 17062248.0000 - val_mae: 2966.2112\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1037701.9167 - mae: 627.4033 - val_loss: 16683250.0000 - val_mae: 2937.0728\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1188773.8889 - mae: 639.6422 - val_loss: 16769723.0000 - val_mae: 2940.6404\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 975624.1389 - mae: 586.8204 - val_loss: 16869958.0000 - val_mae: 2953.0291\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 938572.8889 - mae: 589.6702 - val_loss: 16978142.0000 - val_mae: 2952.1685\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1802576.5556 - mae: 748.2743 - val_loss: 16775017.0000 - val_mae: 2941.8372\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 981146.3958 - mae: 608.5269 - val_loss: 16736082.0000 - val_mae: 2940.5596\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1169894.5000 - mae: 632.3165 - val_loss: 16378926.0000 - val_mae: 2922.2742\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 879212.2014 - mae: 551.4277 - val_loss: 16763145.0000 - val_mae: 2944.7371\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1042060.9097 - mae: 606.8571 - val_loss: 16555972.0000 - val_mae: 2935.9351\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1318613.8750 - mae: 613.1422 - val_loss: 16472247.0000 - val_mae: 2927.3423\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1325142.7083 - mae: 637.9716 - val_loss: 16613222.0000 - val_mae: 2933.0330\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1095856.7708 - mae: 584.7102 - val_loss: 16868374.0000 - val_mae: 2941.9297\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1278832.9514 - mae: 630.5194 - val_loss: 16917518.0000 - val_mae: 2945.5774\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1468225.7639 - mae: 638.3391 - val_loss: 16869120.0000 - val_mae: 2948.6138\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1095685.2569 - mae: 587.2342 - val_loss: 16454895.0000 - val_mae: 2922.8105\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1156038.5625 - mae: 639.5811 - val_loss: 17005400.0000 - val_mae: 2952.2083\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 816605.5938 - mae: 519.7069 - val_loss: 17378254.0000 - val_mae: 2974.5225\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1452924.7778 - mae: 656.5926 - val_loss: 16791588.0000 - val_mae: 2942.5913\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1491667.7500 - mae: 584.5265 - val_loss: 16406902.0000 - val_mae: 2922.6345\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1377468.6389 - mae: 643.9671 - val_loss: 16681784.0000 - val_mae: 2935.6770\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1254744.9826 - mae: 598.3950 - val_loss: 16873910.0000 - val_mae: 2949.6296\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1155617.6215 - mae: 534.5405 - val_loss: 16830698.0000 - val_mae: 2936.6553\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 771025.2465 - mae: 522.0682 - val_loss: 17010254.0000 - val_mae: 2948.8423\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1343543.8194 - mae: 601.8166 - val_loss: 16803316.0000 - val_mae: 2939.8916\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 871214.5486 - mae: 540.5316 - val_loss: 16764701.0000 - val_mae: 2932.6946\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1114935.8472 - mae: 580.1376 - val_loss: 16709148.0000 - val_mae: 2935.6394\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1106346.9444 - mae: 628.8037 - val_loss: 16724516.0000 - val_mae: 2936.8704\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1028908.7535 - mae: 563.4704 - val_loss: 16614356.0000 - val_mae: 2930.9685\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 696523.6458 - mae: 493.5399 - val_loss: 16878392.0000 - val_mae: 2940.0500\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 830755.5938 - mae: 494.4805 - val_loss: 17101262.0000 - val_mae: 2952.8359\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 736675.3993 - mae: 504.1240 - val_loss: 16794998.0000 - val_mae: 2933.8865\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 712377.8698 - mae: 492.8196 - val_loss: 16894912.0000 - val_mae: 2935.3064\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1091959.0972 - mae: 538.9800 - val_loss: 16640044.0000 - val_mae: 2922.1594\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 990419.8542 - mae: 543.1897 - val_loss: 16736968.0000 - val_mae: 2927.7666\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 981256.7604 - mae: 525.6756 - val_loss: 16701034.0000 - val_mae: 2923.1697\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 809415.3403 - mae: 534.2776 - val_loss: 16744367.0000 - val_mae: 2929.6511\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 730160.4375 - mae: 525.0861 - val_loss: 17297268.0000 - val_mae: 2963.9741\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1003746.9028 - mae: 559.0012 - val_loss: 17096658.0000 - val_mae: 2958.4712\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 942555.2986 - mae: 544.7104 - val_loss: 16883774.0000 - val_mae: 2945.7207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fXrRpcHbt4VF",
        "outputId": "11992f40-db08-4684-f2f8-09e6589fd50e"
      },
      "source": [
        "history_dict = Model_Results2.history\n",
        "mae_values = history_dict['mae']\n",
        "val_mae_values = history_dict['val_mae']\n",
        "epoches = np.arange(1,len(history_dict['mae'])+1)\n",
        "plt.plot(epoches,mae_values,'r',label=\"Training Mae\")\n",
        "plt.plot(epoches,val_mae_values,'g',label=\"Validating Mae\")\n",
        "plt.title('Training and validation Mae')\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Mae\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kduZlTvtWD4C",
        "outputId": "1042287e-ed39-443c-9228-fb8d9dc07853"
      },
      "source": [
        "history_dict = Model_Results2.history\n",
        "val_acc_values = history_dict['val_mae']\n",
        "maxi = np.max(val_acc_values)\n",
        "mini = np.min(val_acc_values)\n",
        "avrg = (maxi+mini)/2\n",
        "print(f\"FOR MODEL1 Average Validation Absolute Error = {avrg}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOR MODEL1 Average Validation Absolute Error = 6569.700622558594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khmyamDgmgeN"
      },
      "source": [
        "# **MAE without K fold and with gelu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_prT5RtWuum",
        "outputId": "7f767fd2-d108-4787-d49a-2aaf8aee9724"
      },
      "source": [
        "Model_Results3 = Train_Me_with(activation_function=\"gelu\").fit(\n",
        "      train_data,train_labels,batch_size=20,epochs=500,validation_data=(test_data,test_labels)\n",
        "  )"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 1s 35ms/step - loss: 304329774.2222 - mae: 14711.4377 - val_loss: 146559408.0000 - val_mae: 11350.9785\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 258432247.1111 - mae: 13679.1426 - val_loss: 146543056.0000 - val_mae: 11350.3359\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 271233600.0000 - mae: 13816.2744 - val_loss: 146521600.0000 - val_mae: 11349.4932\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 266095395.5556 - mae: 13936.7185 - val_loss: 146501136.0000 - val_mae: 11348.6523\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 285284400.0000 - mae: 14287.2706 - val_loss: 146472432.0000 - val_mae: 11347.4980\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 258663710.2222 - mae: 13658.5700 - val_loss: 146443600.0000 - val_mae: 11346.3125\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 286115957.3333 - mae: 14047.6760 - val_loss: 146405888.0000 - val_mae: 11344.7861\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 283891326.2222 - mae: 14315.5852 - val_loss: 146363632.0000 - val_mae: 11343.0938\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 256841722.6667 - mae: 13519.1984 - val_loss: 146313904.0000 - val_mae: 11341.0996\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 293879512.8889 - mae: 14189.2399 - val_loss: 146256768.0000 - val_mae: 11338.8262\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 306476282.6667 - mae: 14792.7235 - val_loss: 146187584.0000 - val_mae: 11336.1250\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 275810970.6667 - mae: 13859.9571 - val_loss: 146119136.0000 - val_mae: 11333.3926\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 283222259.5556 - mae: 14223.1675 - val_loss: 146042544.0000 - val_mae: 11330.3584\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 245289041.7778 - mae: 13205.8688 - val_loss: 145961040.0000 - val_mae: 11327.1162\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 294208988.4444 - mae: 14457.0312 - val_loss: 145864576.0000 - val_mae: 11323.3350\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 284317560.8889 - mae: 14074.3613 - val_loss: 145761328.0000 - val_mae: 11319.1992\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 296379271.1111 - mae: 14445.3906 - val_loss: 145655248.0000 - val_mae: 11314.9600\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 291522044.4444 - mae: 14316.3218 - val_loss: 145535024.0000 - val_mae: 11310.1777\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 309114055.1111 - mae: 14683.7027 - val_loss: 145387280.0000 - val_mae: 11304.4072\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 269744195.5556 - mae: 13897.2955 - val_loss: 145244432.0000 - val_mae: 11298.7510\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 276921116.4444 - mae: 14043.6108 - val_loss: 145084976.0000 - val_mae: 11292.4307\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 273253984.0000 - mae: 13975.0714 - val_loss: 144905632.0000 - val_mae: 11285.3096\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 278091594.6667 - mae: 13865.3485 - val_loss: 144729872.0000 - val_mae: 11278.2881\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 267749937.7778 - mae: 13961.5792 - val_loss: 144536736.0000 - val_mae: 11270.5908\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 294008560.0000 - mae: 14520.8043 - val_loss: 144312320.0000 - val_mae: 11261.6807\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 308083928.8889 - mae: 14684.7221 - val_loss: 144066592.0000 - val_mae: 11251.9648\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 238216289.7778 - mae: 13014.9769 - val_loss: 143824320.0000 - val_mae: 11242.3047\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 282435091.5556 - mae: 13879.7989 - val_loss: 143546800.0000 - val_mae: 11231.3213\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 267974119.1111 - mae: 13930.1647 - val_loss: 143252512.0000 - val_mae: 11219.6074\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 301985948.4444 - mae: 14703.3989 - val_loss: 142960400.0000 - val_mae: 11207.8994\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 277268718.2222 - mae: 14044.2495 - val_loss: 142612304.0000 - val_mae: 11194.1309\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 260508842.6667 - mae: 13646.0488 - val_loss: 142256592.0000 - val_mae: 11179.8506\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 284404791.1111 - mae: 14278.4834 - val_loss: 141884480.0000 - val_mae: 11164.9814\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 264824673.7778 - mae: 13681.2482 - val_loss: 141469680.0000 - val_mae: 11148.4404\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 231052179.5556 - mae: 13010.2259 - val_loss: 141099648.0000 - val_mae: 11133.3623\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 286573969.7778 - mae: 14159.6247 - val_loss: 140683632.0000 - val_mae: 11116.5000\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 277283626.6667 - mae: 13978.4970 - val_loss: 140219456.0000 - val_mae: 11097.6621\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 264565091.5556 - mae: 13784.3936 - val_loss: 139728160.0000 - val_mae: 11077.8340\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 286788261.3333 - mae: 14273.0869 - val_loss: 139162016.0000 - val_mae: 11055.1592\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 286374398.2222 - mae: 14325.2875 - val_loss: 138603616.0000 - val_mae: 11032.5205\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 278146090.6667 - mae: 14215.4449 - val_loss: 138062816.0000 - val_mae: 11010.4453\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 262085516.4444 - mae: 13643.5432 - val_loss: 137416032.0000 - val_mae: 10984.2891\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 271717354.6667 - mae: 13804.1542 - val_loss: 136783184.0000 - val_mae: 10958.5498\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 249245292.4444 - mae: 13217.6275 - val_loss: 136076992.0000 - val_mae: 10929.7598\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 270895562.6667 - mae: 13888.1291 - val_loss: 135400416.0000 - val_mae: 10901.9014\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 286594312.8889 - mae: 14219.5906 - val_loss: 134696032.0000 - val_mae: 10872.9512\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 259210515.5556 - mae: 13565.1833 - val_loss: 133869048.0000 - val_mae: 10839.1963\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 261959198.2222 - mae: 13680.8381 - val_loss: 133044968.0000 - val_mae: 10805.0518\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 271405699.5556 - mae: 13864.3105 - val_loss: 132192480.0000 - val_mae: 10770.0020\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 261641411.5556 - mae: 13602.9872 - val_loss: 131282808.0000 - val_mae: 10732.1631\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 227149328.0000 - mae: 12788.2477 - val_loss: 130435472.0000 - val_mae: 10696.6816\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 255982551.1111 - mae: 13572.0519 - val_loss: 129582728.0000 - val_mae: 10660.7285\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 296557294.2222 - mae: 14226.6841 - val_loss: 128656848.0000 - val_mae: 10621.5215\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 228511857.7778 - mae: 12618.9182 - val_loss: 127562424.0000 - val_mae: 10575.4873\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 245827205.3333 - mae: 13214.0098 - val_loss: 126512672.0000 - val_mae: 10530.9395\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 280323630.2222 - mae: 13991.5178 - val_loss: 125325264.0000 - val_mae: 10480.8564\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 232552769.7778 - mae: 12725.8461 - val_loss: 124219456.0000 - val_mae: 10433.5605\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 245004755.5556 - mae: 13182.9463 - val_loss: 123090000.0000 - val_mae: 10384.7910\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 266977409.7778 - mae: 13592.1599 - val_loss: 122034552.0000 - val_mae: 10338.6758\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 217437608.8889 - mae: 12243.3136 - val_loss: 120631176.0000 - val_mae: 10278.1846\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 226203246.2222 - mae: 12673.1620 - val_loss: 119467096.0000 - val_mae: 10226.8467\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 247422218.6667 - mae: 13111.8507 - val_loss: 118203840.0000 - val_mae: 10171.2383\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 265664604.4444 - mae: 13521.8300 - val_loss: 116900544.0000 - val_mae: 10113.3311\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 240169365.3333 - mae: 12805.7504 - val_loss: 115474232.0000 - val_mae: 10049.7314\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 203287587.5556 - mae: 11965.7298 - val_loss: 113863464.0000 - val_mae: 9978.2158\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 187365758.2222 - mae: 11635.8454 - val_loss: 112298072.0000 - val_mae: 9907.9814\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 183697056.0000 - mae: 11490.5039 - val_loss: 110654216.0000 - val_mae: 9833.8086\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 198348449.7778 - mae: 11730.7620 - val_loss: 108907176.0000 - val_mae: 9754.5908\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 209281351.1111 - mae: 12183.0544 - val_loss: 107335960.0000 - val_mae: 9681.8135\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 241794616.8889 - mae: 12866.0039 - val_loss: 105877504.0000 - val_mae: 9613.1484\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 210926728.8889 - mae: 12056.5217 - val_loss: 104278312.0000 - val_mae: 9537.7324\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 190062225.7778 - mae: 11632.0749 - val_loss: 102447464.0000 - val_mae: 9451.5117\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 218484568.8889 - mae: 12197.9281 - val_loss: 100715288.0000 - val_mae: 9368.4893\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 207252264.8889 - mae: 11912.1532 - val_loss: 98933912.0000 - val_mae: 9282.3770\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 225079582.2222 - mae: 12186.7821 - val_loss: 97004304.0000 - val_mae: 9188.4062\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 203093827.5556 - mae: 11836.7951 - val_loss: 95106024.0000 - val_mae: 9094.9023\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 180249114.6667 - mae: 11278.5749 - val_loss: 93134360.0000 - val_mae: 8996.7803\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 201217205.3333 - mae: 11667.4334 - val_loss: 91203192.0000 - val_mae: 8899.2871\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 182208858.6667 - mae: 11179.6520 - val_loss: 89144352.0000 - val_mae: 8794.5361\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 204869292.4444 - mae: 11524.0497 - val_loss: 87023784.0000 - val_mae: 8685.0820\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 175739288.8889 - mae: 10914.2454 - val_loss: 84724176.0000 - val_mae: 8565.3730\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 159058264.8889 - mae: 10279.7462 - val_loss: 82594800.0000 - val_mae: 8452.9805\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 183540764.4444 - mae: 10991.0958 - val_loss: 80302456.0000 - val_mae: 8330.1182\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 147250532.4444 - mae: 10102.6887 - val_loss: 77972600.0000 - val_mae: 8203.1270\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 138906606.2222 - mae: 9693.7386 - val_loss: 75821480.0000 - val_mae: 8082.7505\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 150106591.1111 - mae: 10001.7096 - val_loss: 73678968.0000 - val_mae: 7960.8345\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 173293464.8889 - mae: 10733.5419 - val_loss: 71560952.0000 - val_mae: 7838.5073\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 167283998.2222 - mae: 10407.1267 - val_loss: 69027640.0000 - val_mae: 7691.0947\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 161631441.7778 - mae: 10203.2280 - val_loss: 66861820.0000 - val_mae: 7561.4492\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 142447116.4444 - mae: 9442.6940 - val_loss: 64287800.0000 - val_mae: 7406.4756\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 138858636.4444 - mae: 9615.5246 - val_loss: 61835116.0000 - val_mae: 7255.1968\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 128299953.7778 - mae: 9155.5088 - val_loss: 59585012.0000 - val_mae: 7111.4224\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 135558820.4444 - mae: 9384.2666 - val_loss: 57245560.0000 - val_mae: 6959.4331\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 129271028.4444 - mae: 8944.4071 - val_loss: 54724568.0000 - val_mae: 6792.4834\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 122465036.4444 - mae: 8780.0613 - val_loss: 52334032.0000 - val_mae: 6628.3560\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 118593361.7778 - mae: 8454.1429 - val_loss: 49871668.0000 - val_mae: 6455.6455\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 107040783.1111 - mae: 8124.0952 - val_loss: 47489012.0000 - val_mae: 6283.8037\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 106694359.1111 - mae: 7995.5042 - val_loss: 45211772.0000 - val_mae: 6114.5166\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 101777562.6667 - mae: 7955.5490 - val_loss: 42743400.0000 - val_mae: 5925.5024\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 88267145.3333 - mae: 7259.7745 - val_loss: 40437896.0000 - val_mae: 5742.5508\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 100556201.7778 - mae: 7505.8394 - val_loss: 38369972.0000 - val_mae: 5573.4556\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 112613110.2222 - mae: 7924.4076 - val_loss: 36298920.0000 - val_mae: 5397.2720\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 83014999.1111 - mae: 6861.8541 - val_loss: 33910756.0000 - val_mae: 5189.0991\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 79716855.1111 - mae: 6623.1245 - val_loss: 31888388.0000 - val_mae: 5009.5767\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 75352512.4444 - mae: 6371.1036 - val_loss: 29705778.0000 - val_mae: 4808.4404\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 95302255.1111 - mae: 7117.1904 - val_loss: 27813218.0000 - val_mae: 4625.7344\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 91007099.5556 - mae: 6962.8767 - val_loss: 25744452.0000 - val_mae: 4416.9097\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 62731600.0000 - mae: 5946.8744 - val_loss: 23885260.0000 - val_mae: 4226.2378\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 73903545.3333 - mae: 6212.4028 - val_loss: 22119978.0000 - val_mae: 4045.7117\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 53957047.5556 - mae: 5099.7374 - val_loss: 20415830.0000 - val_mae: 3860.2214\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 64030357.7778 - mae: 5467.5710 - val_loss: 18845848.0000 - val_mae: 3677.1226\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 50095738.2222 - mae: 4857.5413 - val_loss: 17140180.0000 - val_mae: 3465.4326\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 48108185.3333 - mae: 4709.1141 - val_loss: 15503858.0000 - val_mae: 3267.0413\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 49388545.7778 - mae: 4736.5719 - val_loss: 14249030.0000 - val_mae: 3109.4663\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 36405390.8889 - mae: 4209.4686 - val_loss: 13092992.0000 - val_mae: 2959.5610\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 45231133.3333 - mae: 4588.8305 - val_loss: 11860627.0000 - val_mae: 2802.8210\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 44974858.2222 - mae: 4436.6455 - val_loss: 10970822.0000 - val_mae: 2683.9939\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 35456992.0000 - mae: 3819.6948 - val_loss: 10072420.0000 - val_mae: 2555.3828\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 30543034.6667 - mae: 3613.1334 - val_loss: 9145993.0000 - val_mae: 2431.1086\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 32163718.8889 - mae: 3677.2100 - val_loss: 8584607.0000 - val_mae: 2346.5574\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 30608233.7778 - mae: 3837.8232 - val_loss: 8266485.0000 - val_mae: 2293.4221\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 27705483.3333 - mae: 3444.7037 - val_loss: 7911651.0000 - val_mae: 2228.1030\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 22591266.4444 - mae: 3177.1801 - val_loss: 7687518.0000 - val_mae: 2170.7761\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 29855217.3333 - mae: 3687.2522 - val_loss: 7572987.0000 - val_mae: 2139.6023\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 23504749.7778 - mae: 3276.1793 - val_loss: 7515889.5000 - val_mae: 2106.4749\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 26084614.8889 - mae: 3471.2507 - val_loss: 7540218.5000 - val_mae: 2087.8186\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 21261111.4444 - mae: 3294.4632 - val_loss: 7700562.5000 - val_mae: 2099.5076\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 26498038.4444 - mae: 3592.6196 - val_loss: 7987330.0000 - val_mae: 2134.5996\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 20239820.1111 - mae: 3098.0401 - val_loss: 8212847.5000 - val_mae: 2157.3308\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18747630.1111 - mae: 3150.3875 - val_loss: 8291030.5000 - val_mae: 2167.5791\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18620686.6667 - mae: 3179.2322 - val_loss: 8690262.0000 - val_mae: 2209.5100\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 20910016.2222 - mae: 3384.5282 - val_loss: 8951663.0000 - val_mae: 2246.1296\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 20121464.7778 - mae: 3279.5282 - val_loss: 9086606.0000 - val_mae: 2266.2793\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17960876.0000 - mae: 3136.9674 - val_loss: 9506300.0000 - val_mae: 2331.4246\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19997195.3333 - mae: 3331.1888 - val_loss: 9356127.0000 - val_mae: 2310.3115\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19391916.2222 - mae: 3388.9313 - val_loss: 9314747.0000 - val_mae: 2308.6794\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18607736.8889 - mae: 3192.2054 - val_loss: 9341882.0000 - val_mae: 2312.5625\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17302069.5556 - mae: 3165.6788 - val_loss: 9782239.0000 - val_mae: 2380.0132\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18516400.2222 - mae: 3103.9240 - val_loss: 9848450.0000 - val_mae: 2391.8752\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16330258.8889 - mae: 3116.0438 - val_loss: 10072488.0000 - val_mae: 2424.3474\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18443636.6667 - mae: 3147.8802 - val_loss: 10087761.0000 - val_mae: 2428.3928\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15709300.0000 - mae: 2971.7783 - val_loss: 10187255.0000 - val_mae: 2445.0798\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16714473.8889 - mae: 3055.3842 - val_loss: 9844483.0000 - val_mae: 2398.5891\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19599148.8889 - mae: 3232.0996 - val_loss: 10146451.0000 - val_mae: 2439.8909\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17573734.0000 - mae: 3186.3447 - val_loss: 9812321.0000 - val_mae: 2400.5640\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19867326.2222 - mae: 3305.2985 - val_loss: 9827576.0000 - val_mae: 2402.7717\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18390161.7778 - mae: 3228.3341 - val_loss: 9665485.0000 - val_mae: 2385.2268\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 17214993.3333 - mae: 3090.9181 - val_loss: 9669398.0000 - val_mae: 2382.5996\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 17378521.7778 - mae: 3094.4725 - val_loss: 9887292.0000 - val_mae: 2404.8220\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15577419.5556 - mae: 2984.7715 - val_loss: 9907810.0000 - val_mae: 2408.0513\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13995131.1111 - mae: 2836.7366 - val_loss: 10045978.0000 - val_mae: 2422.7410\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15087669.8889 - mae: 2909.0032 - val_loss: 9917046.0000 - val_mae: 2404.9482\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 17026689.6667 - mae: 3101.0747 - val_loss: 9880002.0000 - val_mae: 2404.0779\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 15599560.0000 - mae: 2936.0387 - val_loss: 9584004.0000 - val_mae: 2365.1145\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14606112.1111 - mae: 2818.5771 - val_loss: 9904553.0000 - val_mae: 2409.3694\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15045609.4444 - mae: 2865.0826 - val_loss: 9782337.0000 - val_mae: 2392.9475\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14580030.5000 - mae: 2784.9282 - val_loss: 9927553.0000 - val_mae: 2409.9185\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13692903.7778 - mae: 2680.1154 - val_loss: 9336775.0000 - val_mae: 2330.8181\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11782151.9444 - mae: 2510.1991 - val_loss: 9915889.0000 - val_mae: 2407.8657\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16070584.2222 - mae: 2942.2190 - val_loss: 9976097.0000 - val_mae: 2420.6177\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12458538.5000 - mae: 2595.9561 - val_loss: 10102347.0000 - val_mae: 2432.9690\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12405164.2222 - mae: 2551.1812 - val_loss: 9910483.0000 - val_mae: 2405.2568\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16069845.0000 - mae: 2976.7834 - val_loss: 10297138.0000 - val_mae: 2459.2639\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13078661.6667 - mae: 2615.0944 - val_loss: 10252794.0000 - val_mae: 2451.2261\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12069171.5000 - mae: 2483.5824 - val_loss: 9929939.0000 - val_mae: 2403.0381\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13280566.1111 - mae: 2753.3336 - val_loss: 10053257.0000 - val_mae: 2420.4573\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14954741.3333 - mae: 2770.8102 - val_loss: 9971837.0000 - val_mae: 2408.6997\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13835258.1111 - mae: 2644.0145 - val_loss: 10032281.0000 - val_mae: 2415.6372\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12542298.3333 - mae: 2666.2470 - val_loss: 10166691.0000 - val_mae: 2429.7178\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10974959.3333 - mae: 2400.6548 - val_loss: 9936936.0000 - val_mae: 2400.6748\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13060008.6667 - mae: 2707.8946 - val_loss: 10549862.0000 - val_mae: 2479.8879\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13212350.3333 - mae: 2647.6620 - val_loss: 9995679.0000 - val_mae: 2415.0063\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12190400.4444 - mae: 2517.9749 - val_loss: 9977415.0000 - val_mae: 2412.8865\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11788909.6667 - mae: 2507.4834 - val_loss: 9751103.0000 - val_mae: 2391.7244\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11604530.3333 - mae: 2458.9998 - val_loss: 9772713.0000 - val_mae: 2393.9917\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 11919674.1111 - mae: 2511.0257 - val_loss: 10009655.0000 - val_mae: 2415.6350\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 11078333.6667 - mae: 2423.3771 - val_loss: 9879372.0000 - val_mae: 2401.6975\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12881730.6667 - mae: 2462.0766 - val_loss: 9836081.0000 - val_mae: 2398.0774\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13787797.0000 - mae: 2522.1190 - val_loss: 9617641.0000 - val_mae: 2379.1792\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9439963.5556 - mae: 2235.0272 - val_loss: 10439441.0000 - val_mae: 2464.3188\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 12343009.8889 - mae: 2508.3456 - val_loss: 10418013.0000 - val_mae: 2463.7434\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10504165.5556 - mae: 2310.6811 - val_loss: 10050172.0000 - val_mae: 2425.7688\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9169145.2778 - mae: 2139.3553 - val_loss: 9786595.0000 - val_mae: 2401.8174\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12315503.7778 - mae: 2385.7763 - val_loss: 10146606.0000 - val_mae: 2435.1169\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9838628.7778 - mae: 2233.0852 - val_loss: 10252393.0000 - val_mae: 2449.4880\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12839574.6667 - mae: 2570.4593 - val_loss: 9920262.0000 - val_mae: 2413.4502\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11708620.5556 - mae: 2397.2337 - val_loss: 9904755.0000 - val_mae: 2413.7639\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10125209.0000 - mae: 2250.5194 - val_loss: 10430450.0000 - val_mae: 2466.4016\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9164963.8889 - mae: 2165.6172 - val_loss: 11135701.0000 - val_mae: 2536.6899\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10521355.7778 - mae: 2386.1564 - val_loss: 10628903.0000 - val_mae: 2491.8586\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9185276.9444 - mae: 2258.2610 - val_loss: 10809703.0000 - val_mae: 2504.9900\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8623764.5000 - mae: 2113.1376 - val_loss: 11109225.0000 - val_mae: 2537.4224\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11061939.4444 - mae: 2420.2887 - val_loss: 10950537.0000 - val_mae: 2522.9487\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9373396.7778 - mae: 2098.2792 - val_loss: 10913444.0000 - val_mae: 2517.5369\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10607589.5556 - mae: 2331.7044 - val_loss: 10719732.0000 - val_mae: 2500.3997\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9014757.7222 - mae: 2152.2790 - val_loss: 10785797.0000 - val_mae: 2508.5952\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9502626.7778 - mae: 2240.2674 - val_loss: 10914510.0000 - val_mae: 2517.9939\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9654146.7778 - mae: 2143.5144 - val_loss: 10621921.0000 - val_mae: 2491.5720\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9174522.8889 - mae: 2178.8733 - val_loss: 11151595.0000 - val_mae: 2542.2302\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9661043.8889 - mae: 2138.9288 - val_loss: 10524061.0000 - val_mae: 2484.9644\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7958383.1111 - mae: 1974.8725 - val_loss: 11369120.0000 - val_mae: 2568.0593\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7567649.8333 - mae: 1922.1503 - val_loss: 10891481.0000 - val_mae: 2523.3308\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7172305.3889 - mae: 1860.7420 - val_loss: 10500715.0000 - val_mae: 2482.8152\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8624427.8889 - mae: 1988.3922 - val_loss: 10332348.0000 - val_mae: 2468.4312\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7371295.2778 - mae: 1939.9890 - val_loss: 10501793.0000 - val_mae: 2486.1228\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6887053.5000 - mae: 1810.0847 - val_loss: 10786056.0000 - val_mae: 2517.5466\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6605781.0556 - mae: 1700.1934 - val_loss: 11254572.0000 - val_mae: 2569.4045\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7215747.8611 - mae: 1845.3666 - val_loss: 11599704.0000 - val_mae: 2606.1760\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8066585.9444 - mae: 1964.3179 - val_loss: 11153695.0000 - val_mae: 2564.0383\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5820800.7500 - mae: 1681.1944 - val_loss: 11943400.0000 - val_mae: 2641.1128\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6384462.3889 - mae: 1728.5278 - val_loss: 11581865.0000 - val_mae: 2604.3066\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5753509.3889 - mae: 1621.9177 - val_loss: 11683797.0000 - val_mae: 2620.1606\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7535504.3333 - mae: 1868.8152 - val_loss: 11347844.0000 - val_mae: 2587.3564\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6603618.8611 - mae: 1824.5940 - val_loss: 11348843.0000 - val_mae: 2588.5032\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7328717.1111 - mae: 1810.6451 - val_loss: 11052980.0000 - val_mae: 2558.3184\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5664602.2778 - mae: 1658.4548 - val_loss: 11115633.0000 - val_mae: 2562.2444\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6045547.9444 - mae: 1705.7899 - val_loss: 11425454.0000 - val_mae: 2596.9902\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6529726.2222 - mae: 1819.1838 - val_loss: 11468479.0000 - val_mae: 2599.6421\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8117937.2222 - mae: 1832.8628 - val_loss: 10900744.0000 - val_mae: 2544.5681\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5579216.7778 - mae: 1590.4683 - val_loss: 11289630.0000 - val_mae: 2576.7954\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5066868.5833 - mae: 1466.1343 - val_loss: 11100963.0000 - val_mae: 2558.1987\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6298026.3333 - mae: 1726.1382 - val_loss: 11831535.0000 - val_mae: 2629.9204\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5527141.8056 - mae: 1598.5263 - val_loss: 11466596.0000 - val_mae: 2597.7927\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 6328244.8889 - mae: 1669.9472 - val_loss: 11556698.0000 - val_mae: 2605.8616\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5166959.6944 - mae: 1557.6853 - val_loss: 12709721.0000 - val_mae: 2715.8645\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4924224.8056 - mae: 1551.3115 - val_loss: 12758006.0000 - val_mae: 2724.3911\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5921808.6667 - mae: 1668.6103 - val_loss: 13096301.0000 - val_mae: 2758.5854\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4963531.2222 - mae: 1577.6449 - val_loss: 13313316.0000 - val_mae: 2781.6189\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6395169.8889 - mae: 1761.8399 - val_loss: 12991623.0000 - val_mae: 2750.3547\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5223453.0556 - mae: 1511.9152 - val_loss: 12244489.0000 - val_mae: 2685.0459\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7389926.0556 - mae: 1804.0608 - val_loss: 12174727.0000 - val_mae: 2682.1279\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5905435.0556 - mae: 1600.8677 - val_loss: 12238988.0000 - val_mae: 2686.8530\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4858037.8333 - mae: 1506.0196 - val_loss: 12706907.0000 - val_mae: 2724.0774\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6409938.5000 - mae: 1715.6980 - val_loss: 11884332.0000 - val_mae: 2652.4675\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4953825.8889 - mae: 1474.8451 - val_loss: 12559128.0000 - val_mae: 2708.3564\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5466812.5556 - mae: 1575.1571 - val_loss: 12602449.0000 - val_mae: 2714.0161\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4816554.6667 - mae: 1488.9663 - val_loss: 12470441.0000 - val_mae: 2705.1924\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5050940.0556 - mae: 1561.7959 - val_loss: 11948756.0000 - val_mae: 2659.2222\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5909231.8333 - mae: 1662.3813 - val_loss: 12739992.0000 - val_mae: 2730.9238\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5011897.1111 - mae: 1489.4632 - val_loss: 12481099.0000 - val_mae: 2711.2979\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4935052.0556 - mae: 1543.4350 - val_loss: 13054684.0000 - val_mae: 2764.1777\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5205358.0000 - mae: 1553.4486 - val_loss: 12867127.0000 - val_mae: 2744.7778\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4159852.8889 - mae: 1392.2647 - val_loss: 12615928.0000 - val_mae: 2724.6562\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5353890.8889 - mae: 1504.2968 - val_loss: 12449677.0000 - val_mae: 2710.1653\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5232142.6389 - mae: 1478.3697 - val_loss: 12779043.0000 - val_mae: 2736.5872\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4522718.4444 - mae: 1496.3185 - val_loss: 12349515.0000 - val_mae: 2697.4473\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3961622.0000 - mae: 1380.5084 - val_loss: 12657220.0000 - val_mae: 2725.8269\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4660210.6667 - mae: 1464.8376 - val_loss: 13295555.0000 - val_mae: 2783.7861\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4566170.7778 - mae: 1428.7226 - val_loss: 13138436.0000 - val_mae: 2771.4922\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4786855.8889 - mae: 1442.9565 - val_loss: 12690695.0000 - val_mae: 2730.7507\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4920197.2222 - mae: 1472.0587 - val_loss: 13114218.0000 - val_mae: 2766.7251\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5075488.9444 - mae: 1463.3528 - val_loss: 12927083.0000 - val_mae: 2755.2952\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4078761.2500 - mae: 1341.8430 - val_loss: 13256534.0000 - val_mae: 2786.9038\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4378902.9167 - mae: 1437.4517 - val_loss: 13865708.0000 - val_mae: 2834.3364\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4856463.5556 - mae: 1349.5716 - val_loss: 13211263.0000 - val_mae: 2782.8616\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3337624.1667 - mae: 1237.9120 - val_loss: 12558892.0000 - val_mae: 2728.4463\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4964017.8056 - mae: 1407.7292 - val_loss: 13029969.0000 - val_mae: 2765.8953\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3916196.1389 - mae: 1314.6923 - val_loss: 13804779.0000 - val_mae: 2831.1938\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3721362.9722 - mae: 1239.2383 - val_loss: 13009122.0000 - val_mae: 2769.5322\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4530890.6111 - mae: 1469.2337 - val_loss: 13369979.0000 - val_mae: 2797.7114\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3778306.6111 - mae: 1282.6722 - val_loss: 13594560.0000 - val_mae: 2816.1812\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3483194.9722 - mae: 1184.1930 - val_loss: 13605541.0000 - val_mae: 2818.9231\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2948037.6667 - mae: 1153.7196 - val_loss: 13214285.0000 - val_mae: 2789.7961\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4115647.7222 - mae: 1285.1425 - val_loss: 13092104.0000 - val_mae: 2779.3406\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3239389.8472 - mae: 1246.8153 - val_loss: 14607103.0000 - val_mae: 2899.2473\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3423295.7222 - mae: 1204.0740 - val_loss: 13872296.0000 - val_mae: 2847.3679\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3066667.9861 - mae: 1116.2792 - val_loss: 13327950.0000 - val_mae: 2805.2676\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2520813.7431 - mae: 1085.4072 - val_loss: 13062040.0000 - val_mae: 2779.6633\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2652462.0556 - mae: 1092.9387 - val_loss: 13638269.0000 - val_mae: 2823.3801\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4228181.0000 - mae: 1300.3080 - val_loss: 13579624.0000 - val_mae: 2820.1040\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2977665.7500 - mae: 1172.8294 - val_loss: 13672458.0000 - val_mae: 2829.6318\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2529111.4167 - mae: 1048.8775 - val_loss: 14121595.0000 - val_mae: 2866.8438\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2673696.9583 - mae: 1034.8163 - val_loss: 13231181.0000 - val_mae: 2793.5625\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2718406.2083 - mae: 1096.6903 - val_loss: 13613386.0000 - val_mae: 2815.9031\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3707061.3889 - mae: 1151.9933 - val_loss: 14197361.0000 - val_mae: 2863.7974\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3485275.9722 - mae: 1171.4124 - val_loss: 14081628.0000 - val_mae: 2857.2791\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2975226.0278 - mae: 1126.1076 - val_loss: 13938976.0000 - val_mae: 2847.1074\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2439488.6806 - mae: 946.3516 - val_loss: 13332771.0000 - val_mae: 2795.1880\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3558271.0278 - mae: 1133.0994 - val_loss: 13656206.0000 - val_mae: 2816.2031\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4003659.9167 - mae: 1207.1108 - val_loss: 14399601.0000 - val_mae: 2878.6658\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3655561.6389 - mae: 1149.9939 - val_loss: 14617675.0000 - val_mae: 2895.0447\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2971403.9306 - mae: 1111.1487 - val_loss: 13999500.0000 - val_mae: 2851.7061\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2895140.3889 - mae: 1027.0851 - val_loss: 13373114.0000 - val_mae: 2802.9800\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2977357.5833 - mae: 1134.9219 - val_loss: 13854087.0000 - val_mae: 2842.2668\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2896573.0278 - mae: 1091.5184 - val_loss: 13549487.0000 - val_mae: 2817.9946\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3463583.4722 - mae: 1178.1339 - val_loss: 13963522.0000 - val_mae: 2847.5330\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3026407.5833 - mae: 1084.5842 - val_loss: 13643767.0000 - val_mae: 2825.8884\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3057374.6667 - mae: 1113.3977 - val_loss: 13292254.0000 - val_mae: 2797.0476\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2403446.7083 - mae: 1036.6319 - val_loss: 14107991.0000 - val_mae: 2861.9548\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2839531.3333 - mae: 1088.9097 - val_loss: 14226332.0000 - val_mae: 2869.9346\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3102492.8611 - mae: 1139.9928 - val_loss: 13663916.0000 - val_mae: 2825.8560\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2515066.9722 - mae: 1054.8807 - val_loss: 14731859.0000 - val_mae: 2909.4849\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2011725.5278 - mae: 932.5134 - val_loss: 13551559.0000 - val_mae: 2822.1331\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2529657.1667 - mae: 1073.2513 - val_loss: 15026761.0000 - val_mae: 2934.7900\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2238254.9167 - mae: 898.4048 - val_loss: 14405540.0000 - val_mae: 2891.3933\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2792487.5556 - mae: 987.8567 - val_loss: 13829645.0000 - val_mae: 2847.4517\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1783273.3264 - mae: 910.9321 - val_loss: 15159951.0000 - val_mae: 2947.2319\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2482957.8889 - mae: 1064.5010 - val_loss: 14817875.0000 - val_mae: 2924.1714\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2812868.0000 - mae: 1110.9587 - val_loss: 14060317.0000 - val_mae: 2871.9114\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2377532.5903 - mae: 927.7889 - val_loss: 14645820.0000 - val_mae: 2907.6467\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2870666.3889 - mae: 1043.1911 - val_loss: 14619710.0000 - val_mae: 2901.7222\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2818721.2500 - mae: 1103.7319 - val_loss: 13934959.0000 - val_mae: 2854.7761\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2786686.3611 - mae: 1071.7536 - val_loss: 14400836.0000 - val_mae: 2884.1304\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2878160.3889 - mae: 1062.6455 - val_loss: 13236116.0000 - val_mae: 2796.0876\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2292708.8194 - mae: 976.4995 - val_loss: 13237319.0000 - val_mae: 2796.4277\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1927500.4861 - mae: 886.9964 - val_loss: 14527955.0000 - val_mae: 2890.8911\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1723818.9861 - mae: 854.8153 - val_loss: 14777725.0000 - val_mae: 2907.3645\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2809478.2500 - mae: 1031.4589 - val_loss: 14004661.0000 - val_mae: 2850.9385\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2254582.9444 - mae: 982.2742 - val_loss: 14044075.0000 - val_mae: 2856.4773\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2182787.8750 - mae: 967.6768 - val_loss: 14627252.0000 - val_mae: 2900.4951\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2619233.7222 - mae: 1030.5126 - val_loss: 14486399.0000 - val_mae: 2892.2891\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2013130.7778 - mae: 925.0532 - val_loss: 14626699.0000 - val_mae: 2903.0295\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2999262.3056 - mae: 1055.3017 - val_loss: 14312194.0000 - val_mae: 2880.2837\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2259815.5764 - mae: 953.1536 - val_loss: 14465331.0000 - val_mae: 2889.8005\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2637145.6944 - mae: 982.7516 - val_loss: 14043383.0000 - val_mae: 2860.5188\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1737408.9861 - mae: 832.4245 - val_loss: 15154883.0000 - val_mae: 2939.6052\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2529686.5417 - mae: 962.0119 - val_loss: 14602489.0000 - val_mae: 2898.4211\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1489145.6667 - mae: 817.6222 - val_loss: 13582390.0000 - val_mae: 2826.2927\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2232840.6389 - mae: 932.0743 - val_loss: 13858789.0000 - val_mae: 2837.5808\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1508291.1042 - mae: 797.8762 - val_loss: 14559682.0000 - val_mae: 2888.4458\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2027157.2639 - mae: 863.7141 - val_loss: 13738196.0000 - val_mae: 2835.5122\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1750629.3194 - mae: 850.4857 - val_loss: 13912344.0000 - val_mae: 2859.4270\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1744142.9167 - mae: 832.0400 - val_loss: 14711138.0000 - val_mae: 2902.2607\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1602226.3542 - mae: 836.1893 - val_loss: 14639032.0000 - val_mae: 2896.9124\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2358692.3472 - mae: 916.4292 - val_loss: 13948076.0000 - val_mae: 2854.1326\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2451178.5139 - mae: 890.1004 - val_loss: 13854955.0000 - val_mae: 2852.2295\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2170628.9861 - mae: 889.6581 - val_loss: 14651615.0000 - val_mae: 2902.3237\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1515480.3542 - mae: 798.4514 - val_loss: 14749830.0000 - val_mae: 2903.2817\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2132466.0972 - mae: 821.8356 - val_loss: 13928005.0000 - val_mae: 2847.9170\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1904411.4167 - mae: 831.1354 - val_loss: 14165903.0000 - val_mae: 2868.1084\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1427513.2361 - mae: 719.7492 - val_loss: 15655130.0000 - val_mae: 2968.0891\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1772541.5139 - mae: 877.5933 - val_loss: 15127451.0000 - val_mae: 2940.2039\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1372864.8889 - mae: 727.9268 - val_loss: 14495597.0000 - val_mae: 2901.3413\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1625285.3472 - mae: 780.0831 - val_loss: 15238326.0000 - val_mae: 2944.1631\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1462205.2083 - mae: 784.8286 - val_loss: 15047805.0000 - val_mae: 2938.7991\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1617560.1944 - mae: 792.6679 - val_loss: 15056430.0000 - val_mae: 2935.2197\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1739132.6944 - mae: 822.9150 - val_loss: 14690260.0000 - val_mae: 2912.2729\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1820560.3750 - mae: 809.7613 - val_loss: 15512873.0000 - val_mae: 2965.9751\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1358918.7639 - mae: 722.6888 - val_loss: 14036142.0000 - val_mae: 2872.9990\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1514756.2569 - mae: 742.0693 - val_loss: 14176885.0000 - val_mae: 2878.1926\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1359353.9306 - mae: 754.3251 - val_loss: 14352825.0000 - val_mae: 2885.5986\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1694115.6806 - mae: 787.9630 - val_loss: 14479080.0000 - val_mae: 2894.9333\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1617189.3958 - mae: 760.9570 - val_loss: 14700837.0000 - val_mae: 2894.4329\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1391970.0556 - mae: 716.5042 - val_loss: 14793575.0000 - val_mae: 2909.2012\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1124800.0278 - mae: 653.3575 - val_loss: 14281247.0000 - val_mae: 2883.1428\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1882040.3333 - mae: 801.6837 - val_loss: 14552068.0000 - val_mae: 2897.6023\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1843042.8889 - mae: 787.9398 - val_loss: 14512911.0000 - val_mae: 2897.1606\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1761222.5556 - mae: 798.1951 - val_loss: 14914680.0000 - val_mae: 2916.0979\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1264085.9306 - mae: 709.1233 - val_loss: 14198317.0000 - val_mae: 2873.3750\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1463812.6944 - mae: 695.1010 - val_loss: 13677109.0000 - val_mae: 2837.3479\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1387107.7639 - mae: 716.8035 - val_loss: 13794356.0000 - val_mae: 2848.4622\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1386605.6389 - mae: 766.6869 - val_loss: 14948771.0000 - val_mae: 2919.1396\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1288277.6875 - mae: 664.0423 - val_loss: 14822607.0000 - val_mae: 2920.5496\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1221705.7292 - mae: 652.5174 - val_loss: 14801230.0000 - val_mae: 2918.7600\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1959753.4583 - mae: 745.2696 - val_loss: 14577719.0000 - val_mae: 2902.9033\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1410591.8125 - mae: 699.6833 - val_loss: 14301863.0000 - val_mae: 2898.1399\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1468458.4028 - mae: 701.1778 - val_loss: 14283878.0000 - val_mae: 2891.6736\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1141903.6597 - mae: 652.8126 - val_loss: 15904952.0000 - val_mae: 2996.9351\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1043171.3125 - mae: 642.7482 - val_loss: 15178197.0000 - val_mae: 2947.4519\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1808218.9444 - mae: 735.4009 - val_loss: 14772934.0000 - val_mae: 2911.9634\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1457287.2361 - mae: 684.8172 - val_loss: 14378807.0000 - val_mae: 2898.1047\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1756143.8472 - mae: 769.0105 - val_loss: 14288763.0000 - val_mae: 2893.6089\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1192644.7674 - mae: 648.1330 - val_loss: 15640673.0000 - val_mae: 2989.5496\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1082863.5764 - mae: 634.2661 - val_loss: 14230933.0000 - val_mae: 2893.5366\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1174875.3542 - mae: 674.8264 - val_loss: 15014062.0000 - val_mae: 2936.5940\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1112458.0069 - mae: 644.8305 - val_loss: 15407336.0000 - val_mae: 2969.5164\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1635820.5278 - mae: 696.6546 - val_loss: 14642202.0000 - val_mae: 2929.2771\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 979915.4583 - mae: 628.7049 - val_loss: 16559427.0000 - val_mae: 3056.9612\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1177872.4306 - mae: 693.5708 - val_loss: 15939587.0000 - val_mae: 3022.3442\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 942327.6979 - mae: 595.3226 - val_loss: 15391053.0000 - val_mae: 2980.6458\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1039092.4340 - mae: 582.4646 - val_loss: 14784006.0000 - val_mae: 2933.4568\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 871534.1424 - mae: 547.6242 - val_loss: 14387239.0000 - val_mae: 2900.9058\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1308052.3229 - mae: 621.7792 - val_loss: 14031348.0000 - val_mae: 2879.5344\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1331376.1181 - mae: 677.1920 - val_loss: 14503869.0000 - val_mae: 2905.2466\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1221397.5833 - mae: 655.8694 - val_loss: 14975128.0000 - val_mae: 2931.6904\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 977086.0833 - mae: 608.7609 - val_loss: 15400933.0000 - val_mae: 2970.4233\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1647525.9167 - mae: 710.9914 - val_loss: 13779805.0000 - val_mae: 2866.7488\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1017050.1354 - mae: 594.8364 - val_loss: 14825166.0000 - val_mae: 2924.8643\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 955169.4410 - mae: 594.6906 - val_loss: 14774701.0000 - val_mae: 2928.4038\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 850975.3056 - mae: 537.2394 - val_loss: 15178733.0000 - val_mae: 2962.7502\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 906346.9549 - mae: 531.4466 - val_loss: 15323599.0000 - val_mae: 2972.4307\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1251233.0625 - mae: 635.9921 - val_loss: 16174724.0000 - val_mae: 3029.9800\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 777711.6806 - mae: 551.9194 - val_loss: 16217896.0000 - val_mae: 3046.9438\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1241202.6076 - mae: 621.6033 - val_loss: 15554220.0000 - val_mae: 3007.2288\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1654254.5694 - mae: 717.0354 - val_loss: 15400854.0000 - val_mae: 2992.8091\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1088494.2153 - mae: 605.5364 - val_loss: 15241525.0000 - val_mae: 2985.6372\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1014024.6285 - mae: 607.1443 - val_loss: 15892806.0000 - val_mae: 3021.9167\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1119465.2778 - mae: 605.8833 - val_loss: 15303386.0000 - val_mae: 2981.2288\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1287121.3194 - mae: 587.0618 - val_loss: 15075497.0000 - val_mae: 2968.7441\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 885626.0000 - mae: 583.5538 - val_loss: 15146609.0000 - val_mae: 2976.1714\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1399591.2917 - mae: 634.2663 - val_loss: 15187847.0000 - val_mae: 2988.3108\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 987813.1597 - mae: 548.7224 - val_loss: 15963236.0000 - val_mae: 3035.4778\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 893759.5694 - mae: 557.1576 - val_loss: 16040037.0000 - val_mae: 3033.5042\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1055905.2292 - mae: 562.9937 - val_loss: 15655482.0000 - val_mae: 3016.2747\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1044755.9722 - mae: 600.5790 - val_loss: 15179310.0000 - val_mae: 2978.6750\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1080039.9792 - mae: 564.2643 - val_loss: 15119228.0000 - val_mae: 2971.4849\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 863701.2708 - mae: 543.0600 - val_loss: 16397261.0000 - val_mae: 3069.3621\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1399980.7014 - mae: 676.4274 - val_loss: 15370430.0000 - val_mae: 2997.1770\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1045172.3611 - mae: 616.4216 - val_loss: 16019273.0000 - val_mae: 3037.3584\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 868675.8056 - mae: 537.3528 - val_loss: 15483212.0000 - val_mae: 3004.3967\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1155993.4583 - mae: 594.0604 - val_loss: 15155692.0000 - val_mae: 2976.0979\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1175707.7708 - mae: 536.7223 - val_loss: 15921832.0000 - val_mae: 3013.3262\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 876062.3819 - mae: 529.6446 - val_loss: 14941005.0000 - val_mae: 2956.4900\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 587708.2674 - mae: 447.0162 - val_loss: 15318115.0000 - val_mae: 2981.3213\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 893254.7639 - mae: 495.5275 - val_loss: 14658734.0000 - val_mae: 2939.8315\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 876575.6806 - mae: 560.2304 - val_loss: 15632447.0000 - val_mae: 2997.3374\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 846946.5347 - mae: 521.4515 - val_loss: 15516271.0000 - val_mae: 2994.4341\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 788896.0938 - mae: 492.8132 - val_loss: 16142573.0000 - val_mae: 3039.8181\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 982381.2708 - mae: 589.3737 - val_loss: 16244232.0000 - val_mae: 3050.3281\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 688082.3628 - mae: 475.6922 - val_loss: 15853835.0000 - val_mae: 3024.8569\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 856781.8264 - mae: 503.3013 - val_loss: 15524566.0000 - val_mae: 3010.9138\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1262473.3889 - mae: 593.6743 - val_loss: 14659610.0000 - val_mae: 2950.0132\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 808062.3889 - mae: 507.5774 - val_loss: 15704315.0000 - val_mae: 3009.0652\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 925987.5556 - mae: 501.7020 - val_loss: 15250473.0000 - val_mae: 2991.6777\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1334223.0903 - mae: 587.7060 - val_loss: 14749747.0000 - val_mae: 2964.3982\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 920082.0000 - mae: 549.8321 - val_loss: 16055584.0000 - val_mae: 3049.6465\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 917098.6111 - mae: 521.3471 - val_loss: 15937148.0000 - val_mae: 3036.4021\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 599211.2556 - mae: 422.5275 - val_loss: 15423659.0000 - val_mae: 2996.9294\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 596983.0347 - mae: 436.9631 - val_loss: 15896253.0000 - val_mae: 3027.9128\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 649069.8646 - mae: 464.8771 - val_loss: 15575570.0000 - val_mae: 3011.3694\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 780855.2986 - mae: 481.3594 - val_loss: 15830130.0000 - val_mae: 3026.1743\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 694242.8924 - mae: 470.2818 - val_loss: 15823886.0000 - val_mae: 3028.4021\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 744056.2326 - mae: 455.1702 - val_loss: 16178699.0000 - val_mae: 3030.3062\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 896857.7153 - mae: 506.0540 - val_loss: 15100918.0000 - val_mae: 2965.7048\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 793348.4444 - mae: 524.3882 - val_loss: 14585079.0000 - val_mae: 2938.3503\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 789565.7153 - mae: 556.5711 - val_loss: 16228781.0000 - val_mae: 3043.4624\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 704225.7847 - mae: 456.6579 - val_loss: 16410724.0000 - val_mae: 3063.5894\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 838358.0799 - mae: 510.7365 - val_loss: 15698666.0000 - val_mae: 3026.3882\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 811273.5833 - mae: 471.3914 - val_loss: 15071586.0000 - val_mae: 2983.6738\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 611059.4583 - mae: 445.3211 - val_loss: 16627385.0000 - val_mae: 3074.9033\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 749966.3229 - mae: 509.4213 - val_loss: 16176047.0000 - val_mae: 3047.6152\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 828773.9931 - mae: 546.0845 - val_loss: 16598097.0000 - val_mae: 3089.9175\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1144428.8750 - mae: 573.1943 - val_loss: 15998148.0000 - val_mae: 3022.7871\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 830278.3264 - mae: 533.4138 - val_loss: 15924584.0000 - val_mae: 3027.9199\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 659533.4392 - mae: 427.6623 - val_loss: 15342106.0000 - val_mae: 3001.1272\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 866425.3958 - mae: 509.0025 - val_loss: 16525586.0000 - val_mae: 3070.9138\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 759800.6441 - mae: 495.2832 - val_loss: 15135277.0000 - val_mae: 2992.7209\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 857716.9028 - mae: 529.1372 - val_loss: 16929316.0000 - val_mae: 3106.7017\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 777472.3403 - mae: 476.7964 - val_loss: 16051551.0000 - val_mae: 3038.4128\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 646527.1528 - mae: 439.8529 - val_loss: 15156374.0000 - val_mae: 2996.8723\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 723312.3785 - mae: 500.1319 - val_loss: 15861662.0000 - val_mae: 3027.1943\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 546628.8785 - mae: 427.3785 - val_loss: 16441371.0000 - val_mae: 3075.4321\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 756671.0799 - mae: 456.0176 - val_loss: 16293597.0000 - val_mae: 3043.1428\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 666095.5208 - mae: 436.6037 - val_loss: 15909695.0000 - val_mae: 3020.3010\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 972963.9722 - mae: 487.2802 - val_loss: 15901972.0000 - val_mae: 3008.0051\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 511187.1372 - mae: 405.0375 - val_loss: 16105596.0000 - val_mae: 3033.4314\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 686167.7535 - mae: 419.8858 - val_loss: 16082720.0000 - val_mae: 3044.6682\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 628139.0347 - mae: 434.4175 - val_loss: 16541896.0000 - val_mae: 3066.2295\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 608774.5035 - mae: 423.2112 - val_loss: 15428306.0000 - val_mae: 2993.8652\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1090633.4097 - mae: 551.3554 - val_loss: 15965951.0000 - val_mae: 3018.7178\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 604020.7604 - mae: 423.7118 - val_loss: 16127459.0000 - val_mae: 3027.8777\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 884291.5556 - mae: 481.0082 - val_loss: 16300027.0000 - val_mae: 3056.0637\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 718118.5451 - mae: 443.0548 - val_loss: 16768647.0000 - val_mae: 3072.6484\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 526811.0139 - mae: 430.0902 - val_loss: 16583144.0000 - val_mae: 3073.9329\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 670684.4514 - mae: 419.2850 - val_loss: 17541928.0000 - val_mae: 3137.0886\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 763331.1771 - mae: 482.5731 - val_loss: 16178429.0000 - val_mae: 3048.9529\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 679517.0278 - mae: 422.1664 - val_loss: 17338198.0000 - val_mae: 3106.2998\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 742851.8368 - mae: 502.3278 - val_loss: 15839209.0000 - val_mae: 3018.9900\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 638386.6441 - mae: 396.4518 - val_loss: 16051648.0000 - val_mae: 3021.6499\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 828765.3264 - mae: 472.9740 - val_loss: 16404387.0000 - val_mae: 3045.9546\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 468934.3698 - mae: 351.1928 - val_loss: 15938694.0000 - val_mae: 3013.2329\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 713117.8490 - mae: 422.8626 - val_loss: 15752798.0000 - val_mae: 2999.5225\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 530924.2743 - mae: 370.3744 - val_loss: 16608398.0000 - val_mae: 3071.1907\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 552735.0451 - mae: 408.5169 - val_loss: 17225260.0000 - val_mae: 3100.1755\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 792289.0764 - mae: 482.5129 - val_loss: 16157300.0000 - val_mae: 3037.3130\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 512374.3403 - mae: 382.7264 - val_loss: 15833760.0000 - val_mae: 3016.3845\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 690010.1875 - mae: 453.0259 - val_loss: 16500776.0000 - val_mae: 3064.4500\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 518627.3368 - mae: 363.9525 - val_loss: 16200142.0000 - val_mae: 3039.2788\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 830220.3889 - mae: 458.7808 - val_loss: 15493426.0000 - val_mae: 2990.1177\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 588925.6024 - mae: 430.8389 - val_loss: 16782268.0000 - val_mae: 3070.5903\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 580813.3819 - mae: 440.4937 - val_loss: 16403808.0000 - val_mae: 3050.8923\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 559043.1545 - mae: 384.3629 - val_loss: 16226687.0000 - val_mae: 3030.9810\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 835273.7847 - mae: 442.3467 - val_loss: 16643249.0000 - val_mae: 3071.3516\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 491151.2500 - mae: 396.5028 - val_loss: 16307276.0000 - val_mae: 3040.7068\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 607475.1372 - mae: 376.4333 - val_loss: 16417463.0000 - val_mae: 3044.0798\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 509969.9306 - mae: 362.9355 - val_loss: 17409406.0000 - val_mae: 3100.9817\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 803843.1389 - mae: 493.8161 - val_loss: 16707483.0000 - val_mae: 3062.3657\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 656727.4392 - mae: 417.7965 - val_loss: 16725986.0000 - val_mae: 3050.7603\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 742940.3472 - mae: 449.3372 - val_loss: 15982776.0000 - val_mae: 3004.8467\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 566110.6424 - mae: 388.0748 - val_loss: 15841596.0000 - val_mae: 3004.2717\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 386759.3585 - mae: 340.9794 - val_loss: 17645904.0000 - val_mae: 3119.3091\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 517233.6667 - mae: 415.2341 - val_loss: 17853118.0000 - val_mae: 3146.3010\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 755696.7292 - mae: 500.4543 - val_loss: 16954292.0000 - val_mae: 3092.4548\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 393937.6892 - mae: 318.9330 - val_loss: 17096234.0000 - val_mae: 3089.9053\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 416656.0174 - mae: 359.2336 - val_loss: 16299283.0000 - val_mae: 3031.7876\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 522670.4757 - mae: 388.7287 - val_loss: 17809658.0000 - val_mae: 3140.1023\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 718094.7917 - mae: 454.0068 - val_loss: 15956402.0000 - val_mae: 3013.9717\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 491663.1901 - mae: 386.1060 - val_loss: 17487326.0000 - val_mae: 3113.0833\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 547209.6875 - mae: 406.8313 - val_loss: 16733839.0000 - val_mae: 3065.5171\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 673699.1215 - mae: 396.2332 - val_loss: 16685490.0000 - val_mae: 3054.6799\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 680850.6736 - mae: 393.1470 - val_loss: 16904336.0000 - val_mae: 3072.5427\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 411441.7066 - mae: 329.0812 - val_loss: 16069180.0000 - val_mae: 3026.1921\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 552533.2431 - mae: 396.0022 - val_loss: 16793390.0000 - val_mae: 3065.4270\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 375179.1372 - mae: 317.3096 - val_loss: 16554578.0000 - val_mae: 3049.0186\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 556594.2083 - mae: 409.1801 - val_loss: 16486146.0000 - val_mae: 3044.7937\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 380647.8160 - mae: 326.3457 - val_loss: 16645848.0000 - val_mae: 3056.5747\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 597603.1632 - mae: 391.2581 - val_loss: 16611943.0000 - val_mae: 3055.3425\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 593047.0208 - mae: 368.2788 - val_loss: 17479774.0000 - val_mae: 3110.1519\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 434336.5799 - mae: 358.2021 - val_loss: 17191454.0000 - val_mae: 3092.9636\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 574528.5660 - mae: 410.1726 - val_loss: 16698344.0000 - val_mae: 3065.1826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fzuwjOMYuAIU",
        "outputId": "5ad22124-5d98-4c7e-8c23-f556ac0c1bd1"
      },
      "source": [
        "history_dict = Model_Results3.history\n",
        "mae_values = history_dict['loss']\n",
        "val_mae_values = history_dict['val_loss']\n",
        "epoches = np.arange(1,len(history_dict['mae'])+1)\n",
        "plt.plot(epoches,mae_values,'r',label=\"Training Mae\")\n",
        "plt.plot(epoches,val_mae_values,'g',label=\"Validating Mae\")\n",
        "plt.title('Training and validation Mae')\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Mae\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFaViWzJmvfJ",
        "outputId": "ed634681-c058-4a65-8a44-98bfccab53df"
      },
      "source": [
        "history_dict = Model_Results3.history\n",
        "val_acc_values = history_dict['val_mae']\n",
        "maxi = np.max(val_acc_values)\n",
        "mini = np.min(val_acc_values)\n",
        "avrg = (maxi+mini)/2\n",
        "print(f\"FOR MODEL1 Average Validation Absolute Error = {avrg}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOR MODEL1 Average Validation Absolute Error = 6719.3985595703125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqyyNAtQm0b6"
      },
      "source": [
        "# **MAE without K fold and with relu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWcYjZKlm9ow",
        "outputId": "268cf7fa-b363-4504-ea9f-64f95b853d4f"
      },
      "source": [
        "Model_Results4 = Train_Me_with(activation_function=\"relu\").fit(\n",
        "      train_data,train_labels,batch_size=20,epochs=500,validation_data=(test_data,test_labels)\n",
        "  )"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 1s 31ms/step - loss: 291089546.6667 - mae: 14361.0438 - val_loss: 146567792.0000 - val_mae: 11351.2930\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 261262796.4444 - mae: 13499.8126 - val_loss: 146564480.0000 - val_mae: 11351.1494\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 256342179.5556 - mae: 13557.5787 - val_loss: 146560240.0000 - val_mae: 11350.9688\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 282112168.8889 - mae: 14076.3043 - val_loss: 146554400.0000 - val_mae: 11350.7197\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 289182865.7778 - mae: 14520.0056 - val_loss: 146546080.0000 - val_mae: 11350.3643\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 244307443.5556 - mae: 13231.0567 - val_loss: 146533200.0000 - val_mae: 11349.8418\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 249423777.7778 - mae: 13623.2324 - val_loss: 146514576.0000 - val_mae: 11349.1064\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 257074700.4444 - mae: 13573.0166 - val_loss: 146492032.0000 - val_mae: 11348.2139\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 265650456.8889 - mae: 13676.8961 - val_loss: 146462272.0000 - val_mae: 11347.0391\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 269384268.4444 - mae: 13815.4038 - val_loss: 146429680.0000 - val_mae: 11345.7422\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 293300672.0000 - mae: 14713.9311 - val_loss: 146388000.0000 - val_mae: 11344.0977\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 259480284.4444 - mae: 13775.9016 - val_loss: 146339536.0000 - val_mae: 11342.1729\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 291766632.8889 - mae: 14362.0612 - val_loss: 146280624.0000 - val_mae: 11339.8398\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 280287086.2222 - mae: 14027.7737 - val_loss: 146210896.0000 - val_mae: 11337.0869\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 273241498.6667 - mae: 14109.4574 - val_loss: 146125504.0000 - val_mae: 11333.7451\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 280181511.1111 - mae: 14067.4847 - val_loss: 146033936.0000 - val_mae: 11330.1396\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 253790325.3333 - mae: 13269.6252 - val_loss: 145924880.0000 - val_mae: 11325.8662\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 261254092.4444 - mae: 13566.4368 - val_loss: 145804432.0000 - val_mae: 11321.1260\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 255476949.3333 - mae: 13668.8280 - val_loss: 145671312.0000 - val_mae: 11315.8633\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 261137367.1111 - mae: 13578.0089 - val_loss: 145518304.0000 - val_mae: 11309.8291\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 294856650.6667 - mae: 14419.5698 - val_loss: 145342096.0000 - val_mae: 11302.8984\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 282728501.3333 - mae: 14065.6645 - val_loss: 145153600.0000 - val_mae: 11295.4883\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 247345806.2222 - mae: 13279.1186 - val_loss: 144928976.0000 - val_mae: 11286.7588\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 263762158.2222 - mae: 13746.0109 - val_loss: 144704064.0000 - val_mae: 11277.8564\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 280754355.5556 - mae: 14019.7778 - val_loss: 144473072.0000 - val_mae: 11268.6709\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 262530999.1111 - mae: 13741.7206 - val_loss: 144168384.0000 - val_mae: 11256.7773\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 271423404.4444 - mae: 14047.7349 - val_loss: 143875152.0000 - val_mae: 11245.1904\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 263970220.4444 - mae: 13789.7218 - val_loss: 143596656.0000 - val_mae: 11234.0420\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 249680819.5556 - mae: 13321.6604 - val_loss: 143230128.0000 - val_mae: 11219.6221\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 273137912.8889 - mae: 13872.4141 - val_loss: 142880624.0000 - val_mae: 11205.6299\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 263975880.8889 - mae: 13800.9821 - val_loss: 142502896.0000 - val_mae: 11190.6426\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 290631089.7778 - mae: 14535.8970 - val_loss: 142075568.0000 - val_mae: 11173.6904\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 290686065.7778 - mae: 13977.3085 - val_loss: 141546592.0000 - val_mae: 11152.9111\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 280724746.6667 - mae: 14122.8855 - val_loss: 141157360.0000 - val_mae: 11137.0752\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 291578272.0000 - mae: 14394.5310 - val_loss: 140629776.0000 - val_mae: 11116.0225\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 290168881.7778 - mae: 14219.5623 - val_loss: 140152464.0000 - val_mae: 11096.5645\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 269765480.8889 - mae: 13894.3285 - val_loss: 139601760.0000 - val_mae: 11074.3193\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 261571166.2222 - mae: 13642.8943 - val_loss: 139000112.0000 - val_mae: 11049.9883\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 282175520.0000 - mae: 14074.8881 - val_loss: 138372624.0000 - val_mae: 11024.6025\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 244268950.2222 - mae: 13268.7695 - val_loss: 137675872.0000 - val_mae: 10996.3760\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 256969601.7778 - mae: 13476.2995 - val_loss: 136916064.0000 - val_mae: 10965.6416\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 271174151.1111 - mae: 13856.7027 - val_loss: 136167440.0000 - val_mae: 10935.0527\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 261870256.0000 - mae: 13690.8149 - val_loss: 135386480.0000 - val_mae: 10903.1748\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 292761292.4444 - mae: 14214.4877 - val_loss: 134506112.0000 - val_mae: 10867.1123\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 271770053.3333 - mae: 13744.4355 - val_loss: 133623088.0000 - val_mae: 10830.7393\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 270955761.7778 - mae: 13701.2480 - val_loss: 132671600.0000 - val_mae: 10791.4980\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 276462638.2222 - mae: 13868.3367 - val_loss: 131616920.0000 - val_mae: 10748.1221\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 241694608.0000 - mae: 13108.3743 - val_loss: 130477720.0000 - val_mae: 10701.3740\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 266049070.2222 - mae: 13669.4116 - val_loss: 129454568.0000 - val_mae: 10658.4082\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 244899603.5556 - mae: 13143.0406 - val_loss: 128333464.0000 - val_mae: 10611.4287\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 233676965.3333 - mae: 13031.1574 - val_loss: 127145968.0000 - val_mae: 10561.3916\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 241420177.7778 - mae: 12910.6386 - val_loss: 125895336.0000 - val_mae: 10508.5098\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 234605523.5556 - mae: 12781.1640 - val_loss: 124563944.0000 - val_mae: 10451.9365\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 253941512.8889 - mae: 13422.6558 - val_loss: 123314024.0000 - val_mae: 10398.2266\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 270981185.7778 - mae: 13723.9081 - val_loss: 121909152.0000 - val_mae: 10337.7090\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 253290215.1111 - mae: 13299.1763 - val_loss: 120411648.0000 - val_mae: 10273.0225\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 231027760.0000 - mae: 12711.9433 - val_loss: 118881640.0000 - val_mae: 10206.3779\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 217207989.3333 - mae: 12340.1742 - val_loss: 117232144.0000 - val_mae: 10134.2881\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 214443660.4444 - mae: 12373.3880 - val_loss: 115504320.0000 - val_mae: 10058.3564\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 240379976.8889 - mae: 12956.5997 - val_loss: 113767696.0000 - val_mae: 9980.8242\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 195536456.8889 - mae: 11726.5639 - val_loss: 112106952.0000 - val_mae: 9906.0664\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 209685402.6667 - mae: 12269.2282 - val_loss: 110387936.0000 - val_mae: 9827.7891\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 194685246.2222 - mae: 11659.0405 - val_loss: 108629936.0000 - val_mae: 9746.9004\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 200492892.4444 - mae: 11898.7968 - val_loss: 106643664.0000 - val_mae: 9655.7451\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 233757242.6667 - mae: 12689.8562 - val_loss: 104789112.0000 - val_mae: 9568.8086\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 210720556.4444 - mae: 12095.4184 - val_loss: 102727352.0000 - val_mae: 9471.9111\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 209949720.8889 - mae: 12062.2471 - val_loss: 100697752.0000 - val_mae: 9375.2480\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 194430856.8889 - mae: 11596.0219 - val_loss: 98602488.0000 - val_mae: 9274.0801\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 214366821.3333 - mae: 12099.1554 - val_loss: 96515616.0000 - val_mae: 9172.0117\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 180767397.3333 - mae: 11238.3902 - val_loss: 94235848.0000 - val_mae: 9059.7842\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 200345169.7778 - mae: 11703.4357 - val_loss: 91909184.0000 - val_mae: 8943.8096\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 209532679.1111 - mae: 11724.3087 - val_loss: 89465800.0000 - val_mae: 8820.1660\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 187182081.7778 - mae: 11350.0161 - val_loss: 86853296.0000 - val_mae: 8686.6660\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 167951507.5556 - mae: 10747.1573 - val_loss: 84601032.0000 - val_mae: 8568.3125\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 161129784.8889 - mae: 10395.1797 - val_loss: 82086144.0000 - val_mae: 8435.7529\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 179587331.5556 - mae: 10879.8215 - val_loss: 79739736.0000 - val_mae: 8308.1982\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 166774725.3333 - mae: 10617.4201 - val_loss: 77207008.0000 - val_mae: 8169.3062\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 151787888.0000 - mae: 9983.7762 - val_loss: 74738376.0000 - val_mae: 8030.8232\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 155473896.0000 - mae: 10009.9847 - val_loss: 72199232.0000 - val_mae: 7885.6392\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 175906839.1111 - mae: 10582.8054 - val_loss: 69590064.0000 - val_mae: 7733.8257\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 156754872.8889 - mae: 10085.3277 - val_loss: 66876136.0000 - val_mae: 7572.6982\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 150150030.2222 - mae: 9891.5071 - val_loss: 64165476.0000 - val_mae: 7408.2510\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 156100737.7778 - mae: 10064.9347 - val_loss: 61526468.0000 - val_mae: 7243.5181\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 138125686.2222 - mae: 9246.7237 - val_loss: 58832268.0000 - val_mae: 7071.6919\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 111995170.6667 - mae: 8470.1147 - val_loss: 56147604.0000 - val_mae: 6894.8721\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 137500805.3333 - mae: 9269.9517 - val_loss: 53305184.0000 - val_mae: 6702.6401\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 106944164.4444 - mae: 8162.1644 - val_loss: 50397656.0000 - val_mae: 6501.3589\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 111566656.8889 - mae: 8432.8730 - val_loss: 47825668.0000 - val_mae: 6315.8633\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 114043455.1111 - mae: 8285.5305 - val_loss: 45339292.0000 - val_mae: 6129.9062\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 97810980.8889 - mae: 7719.6757 - val_loss: 42604008.0000 - val_mae: 5917.8394\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 101737603.5556 - mae: 7947.3580 - val_loss: 40144208.0000 - val_mae: 5720.3164\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 83547503.1111 - mae: 6924.8580 - val_loss: 37392388.0000 - val_mae: 5492.4634\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 94058407.1111 - mae: 7439.5002 - val_loss: 34807064.0000 - val_mae: 5266.9570\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 85380649.7778 - mae: 6900.6839 - val_loss: 32592828.0000 - val_mae: 5072.1938\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 62883489.7778 - mae: 6046.9914 - val_loss: 30300778.0000 - val_mae: 4861.6929\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 69766269.3333 - mae: 6235.7614 - val_loss: 28047918.0000 - val_mae: 4643.6265\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 69826483.5556 - mae: 6056.9971 - val_loss: 25698878.0000 - val_mae: 4409.4614\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 75030459.1111 - mae: 6100.8989 - val_loss: 23412840.0000 - val_mae: 4184.1680\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 60693655.1111 - mae: 5493.6601 - val_loss: 21526132.0000 - val_mae: 3982.2949\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 73700194.2222 - mae: 5745.6963 - val_loss: 19599560.0000 - val_mae: 3760.5330\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 56728284.4444 - mae: 5169.6374 - val_loss: 17762120.0000 - val_mae: 3540.8765\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 51384918.6667 - mae: 4965.2014 - val_loss: 16235687.0000 - val_mae: 3356.7131\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 46976028.4444 - mae: 4748.8160 - val_loss: 14540862.0000 - val_mae: 3147.2312\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 44245322.6667 - mae: 4576.2227 - val_loss: 13409442.0000 - val_mae: 3007.7703\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 43139546.6667 - mae: 4504.8750 - val_loss: 12246095.0000 - val_mae: 2866.4502\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 39637793.7778 - mae: 4269.4162 - val_loss: 11193566.0000 - val_mae: 2726.1387\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 33421627.5556 - mae: 3910.5768 - val_loss: 10282922.0000 - val_mae: 2597.9290\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 32251023.5556 - mae: 3947.9954 - val_loss: 9443577.0000 - val_mae: 2479.8120\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 29636041.5556 - mae: 3728.9639 - val_loss: 8994881.0000 - val_mae: 2404.4407\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 31863265.5556 - mae: 3766.9758 - val_loss: 8670583.0000 - val_mae: 2340.5342\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24311267.8889 - mae: 3222.4244 - val_loss: 8446428.0000 - val_mae: 2282.0928\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 31283144.8889 - mae: 3756.0842 - val_loss: 8377327.5000 - val_mae: 2249.1011\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 26481983.3333 - mae: 3448.0394 - val_loss: 8386694.0000 - val_mae: 2233.0073\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 22688038.2222 - mae: 3461.8050 - val_loss: 8499250.0000 - val_mae: 2240.5735\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 23313032.7778 - mae: 3535.6464 - val_loss: 8590938.0000 - val_mae: 2245.5720\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 23910962.8889 - mae: 3526.8469 - val_loss: 8760750.0000 - val_mae: 2257.1729\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19825544.4444 - mae: 3245.4858 - val_loss: 9176469.0000 - val_mae: 2292.9253\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19853081.5556 - mae: 3243.7664 - val_loss: 9301267.0000 - val_mae: 2303.9119\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19002026.4444 - mae: 3229.7744 - val_loss: 9405204.0000 - val_mae: 2311.6572\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 20923213.5556 - mae: 3417.9546 - val_loss: 9533782.0000 - val_mae: 2328.1348\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 20274412.1111 - mae: 3353.2575 - val_loss: 9738246.0000 - val_mae: 2348.8171\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 22867022.4444 - mae: 3512.5110 - val_loss: 9638671.0000 - val_mae: 2342.3374\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18479698.5556 - mae: 3289.3956 - val_loss: 10097875.0000 - val_mae: 2392.1819\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 20172266.8889 - mae: 3408.5232 - val_loss: 9849892.0000 - val_mae: 2367.6763\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19310885.3333 - mae: 3333.4009 - val_loss: 9979957.0000 - val_mae: 2383.8022\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 22195006.6667 - mae: 3445.7031 - val_loss: 9982658.0000 - val_mae: 2382.6504\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 21376066.4444 - mae: 3423.8773 - val_loss: 10096918.0000 - val_mae: 2398.7263\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 22250083.3333 - mae: 3517.7494 - val_loss: 9991097.0000 - val_mae: 2390.1880\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 21723646.2222 - mae: 3415.7090 - val_loss: 9813647.0000 - val_mae: 2372.7849\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19118670.8889 - mae: 3186.6022 - val_loss: 9836723.0000 - val_mae: 2377.1096\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 17624152.6667 - mae: 3196.0238 - val_loss: 10104483.0000 - val_mae: 2411.4360\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 22523142.6667 - mae: 3561.1517 - val_loss: 10232502.0000 - val_mae: 2421.9155\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18738424.2222 - mae: 3320.3870 - val_loss: 10436027.0000 - val_mae: 2445.0220\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18491149.5556 - mae: 3266.1949 - val_loss: 10180476.0000 - val_mae: 2416.1589\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17006013.1111 - mae: 3150.0000 - val_loss: 10248890.0000 - val_mae: 2424.6899\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 18275409.7778 - mae: 3286.8104 - val_loss: 10578052.0000 - val_mae: 2468.8435\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16856141.7778 - mae: 3132.1491 - val_loss: 10585247.0000 - val_mae: 2471.6206\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16420409.8889 - mae: 3058.0918 - val_loss: 10527114.0000 - val_mae: 2463.0996\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16610002.2222 - mae: 3103.0140 - val_loss: 10528485.0000 - val_mae: 2464.5708\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16605010.3333 - mae: 3114.7646 - val_loss: 10271502.0000 - val_mae: 2433.6221\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16615992.8889 - mae: 3054.8850 - val_loss: 10156229.0000 - val_mae: 2418.9929\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19215051.7778 - mae: 3256.0668 - val_loss: 10378655.0000 - val_mae: 2448.3745\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 16309700.7778 - mae: 3066.1411 - val_loss: 10734771.0000 - val_mae: 2499.2219\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19816410.8889 - mae: 3330.6787 - val_loss: 10503090.0000 - val_mae: 2469.3271\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 19437116.2222 - mae: 3289.6429 - val_loss: 10610259.0000 - val_mae: 2488.4375\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 17483883.2222 - mae: 3188.7910 - val_loss: 10420862.0000 - val_mae: 2462.8147\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14605775.2222 - mae: 2875.6349 - val_loss: 10769113.0000 - val_mae: 2511.4526\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17427481.8889 - mae: 3170.8578 - val_loss: 10670726.0000 - val_mae: 2495.1638\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 17236579.5556 - mae: 3195.2561 - val_loss: 10506314.0000 - val_mae: 2469.7542\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 17267893.6667 - mae: 3091.1523 - val_loss: 10737607.0000 - val_mae: 2503.2546\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 15563459.1111 - mae: 2917.1168 - val_loss: 10558995.0000 - val_mae: 2480.3586\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 16746214.6667 - mae: 3019.8174 - val_loss: 10316026.0000 - val_mae: 2444.7886\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18196342.5556 - mae: 3168.6399 - val_loss: 10331559.0000 - val_mae: 2445.0093\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17117127.3333 - mae: 3012.6455 - val_loss: 10440128.0000 - val_mae: 2460.9136\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 16907720.1111 - mae: 3014.3508 - val_loss: 10365315.0000 - val_mae: 2448.3345\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12973352.5000 - mae: 2576.9017 - val_loss: 10720491.0000 - val_mae: 2498.5801\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16898624.0000 - mae: 3098.3601 - val_loss: 10520034.0000 - val_mae: 2467.7983\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 14794400.7778 - mae: 2863.0909 - val_loss: 10367063.0000 - val_mae: 2444.7927\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15566824.0000 - mae: 2893.7051 - val_loss: 10323272.0000 - val_mae: 2440.2898\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 17308345.6667 - mae: 2985.4025 - val_loss: 10255892.0000 - val_mae: 2433.3457\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12873652.6667 - mae: 2711.4167 - val_loss: 10107313.0000 - val_mae: 2417.2371\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12999084.8889 - mae: 2576.0377 - val_loss: 9968282.0000 - val_mae: 2401.8325\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13467337.2222 - mae: 2671.3160 - val_loss: 9954601.0000 - val_mae: 2403.9907\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16158651.0000 - mae: 2944.0194 - val_loss: 10014848.0000 - val_mae: 2410.3254\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 14850548.6667 - mae: 2740.0714 - val_loss: 9954538.0000 - val_mae: 2405.0706\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13012564.2222 - mae: 2619.4179 - val_loss: 10327703.0000 - val_mae: 2449.0591\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16350352.3333 - mae: 2956.7309 - val_loss: 10076438.0000 - val_mae: 2421.5642\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14659661.3333 - mae: 2878.5820 - val_loss: 10194435.0000 - val_mae: 2433.8901\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12830388.3333 - mae: 2567.2337 - val_loss: 10340162.0000 - val_mae: 2454.1509\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13055590.4444 - mae: 2656.4452 - val_loss: 10251859.0000 - val_mae: 2446.4133\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14963117.7778 - mae: 2749.4823 - val_loss: 10190688.0000 - val_mae: 2440.3953\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11796374.8333 - mae: 2471.9547 - val_loss: 10526177.0000 - val_mae: 2476.6609\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10049570.1389 - mae: 2353.9532 - val_loss: 10876367.0000 - val_mae: 2519.9500\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 13598007.4444 - mae: 2717.8873 - val_loss: 11123908.0000 - val_mae: 2548.8787\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 14764625.2222 - mae: 2832.1806 - val_loss: 10819042.0000 - val_mae: 2510.5142\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13244304.8889 - mae: 2775.7597 - val_loss: 10494008.0000 - val_mae: 2475.8875\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13690470.8889 - mae: 2631.7863 - val_loss: 10673755.0000 - val_mae: 2497.8662\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13018581.1111 - mae: 2641.1345 - val_loss: 11039247.0000 - val_mae: 2538.1833\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13890054.4444 - mae: 2692.9584 - val_loss: 11178750.0000 - val_mae: 2553.1387\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13746756.4444 - mae: 2745.7655 - val_loss: 11169439.0000 - val_mae: 2552.1589\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11704594.3333 - mae: 2562.1273 - val_loss: 11105225.0000 - val_mae: 2544.9197\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11815977.2222 - mae: 2570.1932 - val_loss: 10960348.0000 - val_mae: 2528.2598\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12818418.2222 - mae: 2677.5334 - val_loss: 10536070.0000 - val_mae: 2484.0681\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10091572.5000 - mae: 2348.9132 - val_loss: 10923340.0000 - val_mae: 2526.2737\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13894578.4444 - mae: 2692.1350 - val_loss: 10899873.0000 - val_mae: 2521.2166\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13924983.5556 - mae: 2829.3806 - val_loss: 11047370.0000 - val_mae: 2536.2715\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11954123.2778 - mae: 2616.2843 - val_loss: 10763930.0000 - val_mae: 2507.5835\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12499813.3333 - mae: 2655.0838 - val_loss: 10539460.0000 - val_mae: 2487.7771\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13440112.0000 - mae: 2597.8826 - val_loss: 10284002.0000 - val_mae: 2461.3599\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10231320.3333 - mae: 2267.3493 - val_loss: 10222303.0000 - val_mae: 2455.3584\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11479956.6667 - mae: 2485.7361 - val_loss: 10171901.0000 - val_mae: 2450.9355\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8721543.8889 - mae: 2147.9964 - val_loss: 10791909.0000 - val_mae: 2513.7131\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9318107.9444 - mae: 2236.6702 - val_loss: 10631202.0000 - val_mae: 2496.5767\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9102626.8333 - mae: 2157.0821 - val_loss: 10381454.0000 - val_mae: 2474.8513\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11524965.1111 - mae: 2473.9889 - val_loss: 10284555.0000 - val_mae: 2465.1370\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9241714.8333 - mae: 2176.0018 - val_loss: 10499791.0000 - val_mae: 2483.7766\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10564245.7778 - mae: 2365.7370 - val_loss: 10533538.0000 - val_mae: 2485.5266\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10454816.5556 - mae: 2243.3162 - val_loss: 10258586.0000 - val_mae: 2460.1223\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10733004.3333 - mae: 2252.5754 - val_loss: 10451898.0000 - val_mae: 2473.7458\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11842870.8889 - mae: 2466.5853 - val_loss: 10389450.0000 - val_mae: 2469.8545\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8611703.7778 - mae: 2176.2706 - val_loss: 10912382.0000 - val_mae: 2523.0183\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10020409.0000 - mae: 2285.6069 - val_loss: 10621844.0000 - val_mae: 2500.9031\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8660954.9444 - mae: 2134.6785 - val_loss: 11083205.0000 - val_mae: 2546.3315\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10036906.8889 - mae: 2293.0512 - val_loss: 10998540.0000 - val_mae: 2537.7385\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10209886.4444 - mae: 2260.2795 - val_loss: 10827176.0000 - val_mae: 2520.5071\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10157953.5556 - mae: 2328.1268 - val_loss: 10814069.0000 - val_mae: 2519.8401\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8584416.6111 - mae: 2132.9102 - val_loss: 10916899.0000 - val_mae: 2527.5549\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10712756.7778 - mae: 2353.3223 - val_loss: 10996590.0000 - val_mae: 2536.6045\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8853762.3889 - mae: 2177.9963 - val_loss: 10843310.0000 - val_mae: 2522.9106\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11815174.3333 - mae: 2374.8862 - val_loss: 10761118.0000 - val_mae: 2515.2732\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8612981.5556 - mae: 2110.7960 - val_loss: 11057787.0000 - val_mae: 2545.6980\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10725084.7778 - mae: 2276.6763 - val_loss: 10652290.0000 - val_mae: 2508.2712\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8477221.4444 - mae: 2097.9713 - val_loss: 10897970.0000 - val_mae: 2528.5466\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8504337.1111 - mae: 2057.1839 - val_loss: 11304601.0000 - val_mae: 2571.6052\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9563384.2222 - mae: 2122.4388 - val_loss: 11178716.0000 - val_mae: 2557.6975\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7478306.3889 - mae: 2029.6283 - val_loss: 11084266.0000 - val_mae: 2550.2595\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8696489.5556 - mae: 2133.2960 - val_loss: 11575498.0000 - val_mae: 2599.5242\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10082375.5556 - mae: 2230.7888 - val_loss: 11444884.0000 - val_mae: 2587.7642\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10585882.6667 - mae: 2265.8633 - val_loss: 11068083.0000 - val_mae: 2553.9321\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7809874.4444 - mae: 2002.9836 - val_loss: 11029774.0000 - val_mae: 2551.5239\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9532690.2222 - mae: 2197.1531 - val_loss: 10929133.0000 - val_mae: 2540.6616\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8533814.1111 - mae: 2017.1475 - val_loss: 10999537.0000 - val_mae: 2545.4573\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9263522.9444 - mae: 2244.8159 - val_loss: 11160593.0000 - val_mae: 2557.0591\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8184643.1667 - mae: 2067.4294 - val_loss: 11272526.0000 - val_mae: 2567.7483\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9227780.8333 - mae: 2095.0980 - val_loss: 11263092.0000 - val_mae: 2567.6409\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8825935.9444 - mae: 2122.8629 - val_loss: 11277402.0000 - val_mae: 2570.1387\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7789362.9444 - mae: 1952.6006 - val_loss: 11472066.0000 - val_mae: 2588.0327\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7002247.3889 - mae: 1918.6884 - val_loss: 11283203.0000 - val_mae: 2572.8755\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8851021.7778 - mae: 1991.7241 - val_loss: 10970596.0000 - val_mae: 2547.2078\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6777570.1111 - mae: 1838.6205 - val_loss: 11066893.0000 - val_mae: 2554.0881\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8454785.3889 - mae: 2009.5232 - val_loss: 11288165.0000 - val_mae: 2574.7612\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6891279.5556 - mae: 1788.9682 - val_loss: 11006465.0000 - val_mae: 2549.3955\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7026646.5556 - mae: 1917.6346 - val_loss: 10853380.0000 - val_mae: 2534.8604\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9039094.0000 - mae: 2126.4624 - val_loss: 11257754.0000 - val_mae: 2574.8516\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7814090.5000 - mae: 1984.8738 - val_loss: 11279309.0000 - val_mae: 2578.3586\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7933150.6667 - mae: 1929.9994 - val_loss: 11201259.0000 - val_mae: 2572.7039\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7658124.6111 - mae: 1944.5959 - val_loss: 10980302.0000 - val_mae: 2553.8408\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6392675.8889 - mae: 1747.2155 - val_loss: 10839362.0000 - val_mae: 2540.5510\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8400138.3333 - mae: 1962.8275 - val_loss: 10792842.0000 - val_mae: 2536.4729\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7439542.2778 - mae: 1874.9973 - val_loss: 10936003.0000 - val_mae: 2551.4802\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7486029.0000 - mae: 1795.0647 - val_loss: 10908702.0000 - val_mae: 2550.4233\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7377618.8333 - mae: 1838.9314 - val_loss: 11149664.0000 - val_mae: 2573.8872\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5601862.3611 - mae: 1637.4444 - val_loss: 11684722.0000 - val_mae: 2622.7703\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6518501.0000 - mae: 1783.4497 - val_loss: 11801452.0000 - val_mae: 2634.8682\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7779231.2222 - mae: 1893.1819 - val_loss: 11513995.0000 - val_mae: 2609.8921\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5811726.1667 - mae: 1713.6399 - val_loss: 11771422.0000 - val_mae: 2634.8862\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6749011.6667 - mae: 1729.0049 - val_loss: 11412549.0000 - val_mae: 2604.6392\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5901831.8333 - mae: 1705.1897 - val_loss: 11282461.0000 - val_mae: 2593.4326\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8100480.5556 - mae: 1974.0679 - val_loss: 11018418.0000 - val_mae: 2567.0439\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5898352.6667 - mae: 1662.2973 - val_loss: 11319234.0000 - val_mae: 2595.1638\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5848586.8333 - mae: 1674.0517 - val_loss: 11281480.0000 - val_mae: 2590.3770\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7436794.1667 - mae: 1871.6068 - val_loss: 11424366.0000 - val_mae: 2603.2085\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6337379.8333 - mae: 1700.8355 - val_loss: 11855898.0000 - val_mae: 2643.2861\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 7341374.3889 - mae: 1796.5912 - val_loss: 11551739.0000 - val_mae: 2617.8413\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6174028.0000 - mae: 1760.3611 - val_loss: 12020217.0000 - val_mae: 2661.7896\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7202130.6667 - mae: 1871.3971 - val_loss: 11869687.0000 - val_mae: 2649.5359\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7445213.1111 - mae: 1857.5224 - val_loss: 11444821.0000 - val_mae: 2611.8662\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5352193.5556 - mae: 1605.4276 - val_loss: 11892277.0000 - val_mae: 2653.1970\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5342924.0556 - mae: 1567.2787 - val_loss: 11598220.0000 - val_mae: 2627.7603\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7067518.1111 - mae: 1777.6546 - val_loss: 11390443.0000 - val_mae: 2608.5115\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6025134.7778 - mae: 1735.0721 - val_loss: 11662520.0000 - val_mae: 2632.7888\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5242105.6944 - mae: 1600.3035 - val_loss: 11670345.0000 - val_mae: 2634.0906\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5623013.0000 - mae: 1629.9653 - val_loss: 11604954.0000 - val_mae: 2628.4043\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5884643.8889 - mae: 1643.7713 - val_loss: 11634439.0000 - val_mae: 2632.9412\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5116252.5556 - mae: 1586.3910 - val_loss: 11558474.0000 - val_mae: 2627.9358\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5601749.4444 - mae: 1603.2365 - val_loss: 11624809.0000 - val_mae: 2634.4919\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 7062434.0556 - mae: 1790.8149 - val_loss: 11843840.0000 - val_mae: 2654.4641\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6531331.0556 - mae: 1690.2030 - val_loss: 12128892.0000 - val_mae: 2680.9739\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6275386.3333 - mae: 1714.4225 - val_loss: 12109621.0000 - val_mae: 2679.0654\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6337866.6667 - mae: 1708.3552 - val_loss: 12085924.0000 - val_mae: 2677.1079\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5287170.2778 - mae: 1615.5479 - val_loss: 12056677.0000 - val_mae: 2674.4873\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5370947.5000 - mae: 1600.7982 - val_loss: 12287924.0000 - val_mae: 2689.5327\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5327263.4444 - mae: 1550.6931 - val_loss: 12110997.0000 - val_mae: 2675.6790\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5496463.7222 - mae: 1626.9479 - val_loss: 12201525.0000 - val_mae: 2683.5354\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4944382.1111 - mae: 1465.5155 - val_loss: 12403174.0000 - val_mae: 2700.3411\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5826751.3889 - mae: 1677.2820 - val_loss: 12238515.0000 - val_mae: 2686.8433\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5911472.9444 - mae: 1567.7575 - val_loss: 12170930.0000 - val_mae: 2682.6433\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6256493.8889 - mae: 1634.8524 - val_loss: 12094767.0000 - val_mae: 2676.9500\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6064346.1667 - mae: 1637.7284 - val_loss: 11752904.0000 - val_mae: 2650.7424\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4782822.5556 - mae: 1486.7101 - val_loss: 12062271.0000 - val_mae: 2677.5476\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5385006.6111 - mae: 1574.4833 - val_loss: 12148954.0000 - val_mae: 2686.4172\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4451968.8611 - mae: 1484.0428 - val_loss: 11901361.0000 - val_mae: 2667.1904\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4917861.3333 - mae: 1555.6237 - val_loss: 12111959.0000 - val_mae: 2682.9495\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5616697.7778 - mae: 1551.6110 - val_loss: 12230310.0000 - val_mae: 2691.7920\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5401979.8333 - mae: 1552.5729 - val_loss: 11837514.0000 - val_mae: 2664.2874\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5524104.7778 - mae: 1575.2574 - val_loss: 11751306.0000 - val_mae: 2658.8201\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5166090.9167 - mae: 1500.7968 - val_loss: 11772155.0000 - val_mae: 2660.9077\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5094391.4167 - mae: 1564.6045 - val_loss: 12122863.0000 - val_mae: 2687.6145\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4539129.1389 - mae: 1426.0882 - val_loss: 12134887.0000 - val_mae: 2689.7878\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5002387.7778 - mae: 1412.7048 - val_loss: 12284298.0000 - val_mae: 2698.6611\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4117166.0972 - mae: 1374.9335 - val_loss: 12010083.0000 - val_mae: 2675.6509\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6798504.1111 - mae: 1765.9967 - val_loss: 11665766.0000 - val_mae: 2649.2434\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4228212.5000 - mae: 1447.8502 - val_loss: 11732017.0000 - val_mae: 2656.4990\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4233213.5278 - mae: 1393.6019 - val_loss: 11909733.0000 - val_mae: 2670.2861\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4811385.1389 - mae: 1433.7888 - val_loss: 12056381.0000 - val_mae: 2684.0881\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4573782.8889 - mae: 1429.7809 - val_loss: 12226543.0000 - val_mae: 2696.2297\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4909005.0278 - mae: 1500.8819 - val_loss: 12122794.0000 - val_mae: 2688.2488\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4457150.1389 - mae: 1394.7833 - val_loss: 11901042.0000 - val_mae: 2672.0415\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4127908.4444 - mae: 1436.7917 - val_loss: 12408266.0000 - val_mae: 2713.5176\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4704129.7778 - mae: 1467.8473 - val_loss: 12373416.0000 - val_mae: 2708.8640\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4233161.8611 - mae: 1438.6386 - val_loss: 12396321.0000 - val_mae: 2710.4268\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5164419.7222 - mae: 1505.7000 - val_loss: 12503869.0000 - val_mae: 2719.5530\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4341417.8333 - mae: 1432.7154 - val_loss: 12401509.0000 - val_mae: 2713.1453\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5135118.3889 - mae: 1488.5822 - val_loss: 12291772.0000 - val_mae: 2705.2588\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3916117.6111 - mae: 1342.9382 - val_loss: 11973437.0000 - val_mae: 2679.4631\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4677697.8333 - mae: 1487.0123 - val_loss: 12561895.0000 - val_mae: 2725.2307\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3605935.9861 - mae: 1269.6379 - val_loss: 12163910.0000 - val_mae: 2692.8870\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4181765.3333 - mae: 1355.9523 - val_loss: 12068131.0000 - val_mae: 2684.6633\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4397607.0556 - mae: 1457.0737 - val_loss: 12113842.0000 - val_mae: 2686.2795\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3901340.9722 - mae: 1376.5153 - val_loss: 12215668.0000 - val_mae: 2693.6990\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5046685.3333 - mae: 1429.7103 - val_loss: 12368216.0000 - val_mae: 2703.0725\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4324798.8889 - mae: 1398.2476 - val_loss: 12120596.0000 - val_mae: 2683.6951\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6163402.5556 - mae: 1645.7938 - val_loss: 12294551.0000 - val_mae: 2697.3599\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4144164.9444 - mae: 1370.3263 - val_loss: 12802562.0000 - val_mae: 2739.2585\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4391819.3056 - mae: 1425.7811 - val_loss: 12673741.0000 - val_mae: 2730.4448\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4782756.3333 - mae: 1486.7112 - val_loss: 12464005.0000 - val_mae: 2716.6123\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3694462.1667 - mae: 1334.7799 - val_loss: 12249975.0000 - val_mae: 2698.7505\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3850507.6944 - mae: 1377.7122 - val_loss: 12844475.0000 - val_mae: 2748.6299\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4007434.0833 - mae: 1418.9637 - val_loss: 13206883.0000 - val_mae: 2780.9387\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4348804.1944 - mae: 1364.9130 - val_loss: 13118877.0000 - val_mae: 2773.1375\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4766532.7778 - mae: 1362.0401 - val_loss: 12902182.0000 - val_mae: 2754.3584\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4378480.8889 - mae: 1442.7128 - val_loss: 12542397.0000 - val_mae: 2721.2354\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3566957.8889 - mae: 1276.1475 - val_loss: 12591862.0000 - val_mae: 2726.8506\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3225649.4444 - mae: 1268.9556 - val_loss: 12388930.0000 - val_mae: 2713.1938\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4346822.3889 - mae: 1384.1306 - val_loss: 12447345.0000 - val_mae: 2715.0002\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3960569.1111 - mae: 1318.3134 - val_loss: 12367622.0000 - val_mae: 2709.2500\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3609450.6528 - mae: 1288.1402 - val_loss: 12362038.0000 - val_mae: 2709.4871\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4315676.5556 - mae: 1358.7085 - val_loss: 12248058.0000 - val_mae: 2701.7534\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3628013.1667 - mae: 1296.9833 - val_loss: 12414614.0000 - val_mae: 2710.4822\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4780977.3333 - mae: 1452.1720 - val_loss: 12380343.0000 - val_mae: 2710.6997\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4122368.2778 - mae: 1338.7474 - val_loss: 12649101.0000 - val_mae: 2731.9307\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4037280.0833 - mae: 1309.0182 - val_loss: 12506509.0000 - val_mae: 2720.2405\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4218800.5833 - mae: 1293.9591 - val_loss: 12606579.0000 - val_mae: 2727.0732\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4636811.1944 - mae: 1377.2566 - val_loss: 12674008.0000 - val_mae: 2732.0244\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3214408.4444 - mae: 1193.6799 - val_loss: 12355208.0000 - val_mae: 2704.3665\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4419437.4444 - mae: 1356.2376 - val_loss: 12225022.0000 - val_mae: 2694.1467\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3441485.6944 - mae: 1244.9395 - val_loss: 12345252.0000 - val_mae: 2703.8037\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3620191.4722 - mae: 1190.8688 - val_loss: 12483381.0000 - val_mae: 2716.6074\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3600884.5556 - mae: 1234.1816 - val_loss: 12381202.0000 - val_mae: 2706.6980\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3068277.5278 - mae: 1218.9394 - val_loss: 12495906.0000 - val_mae: 2715.5015\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3468156.4444 - mae: 1274.1562 - val_loss: 12672223.0000 - val_mae: 2729.6484\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3632578.5833 - mae: 1166.7234 - val_loss: 12212211.0000 - val_mae: 2693.1484\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3140356.5833 - mae: 1188.4884 - val_loss: 12506465.0000 - val_mae: 2715.5354\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3530541.7778 - mae: 1206.5077 - val_loss: 12521539.0000 - val_mae: 2717.7258\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2728059.6389 - mae: 1118.7713 - val_loss: 12552353.0000 - val_mae: 2721.0081\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3016643.1389 - mae: 1169.2654 - val_loss: 12291771.0000 - val_mae: 2697.3831\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3043074.8611 - mae: 1198.8258 - val_loss: 12344547.0000 - val_mae: 2702.5359\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2643459.0833 - mae: 1138.8194 - val_loss: 12863453.0000 - val_mae: 2748.9082\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2928607.4444 - mae: 1184.2893 - val_loss: 12517780.0000 - val_mae: 2720.3611\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3654384.6389 - mae: 1223.5594 - val_loss: 12261061.0000 - val_mae: 2696.4329\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2980126.1944 - mae: 1181.8600 - val_loss: 12591750.0000 - val_mae: 2727.0054\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3179883.9722 - mae: 1211.5458 - val_loss: 12856825.0000 - val_mae: 2747.8352\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4007417.8889 - mae: 1261.1410 - val_loss: 12607219.0000 - val_mae: 2728.9702\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3048146.2083 - mae: 1199.9444 - val_loss: 12860054.0000 - val_mae: 2745.8811\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3085009.1667 - mae: 1146.6437 - val_loss: 12806488.0000 - val_mae: 2739.0210\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3045744.2361 - mae: 1190.2728 - val_loss: 12814528.0000 - val_mae: 2739.8257\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3276551.1944 - mae: 1177.4383 - val_loss: 13147478.0000 - val_mae: 2770.2949\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3986394.1667 - mae: 1282.1297 - val_loss: 13146060.0000 - val_mae: 2769.8015\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3157840.6111 - mae: 1191.7286 - val_loss: 13108608.0000 - val_mae: 2770.0337\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2936353.0000 - mae: 1120.6666 - val_loss: 13016084.0000 - val_mae: 2762.0378\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2926723.9167 - mae: 1124.1403 - val_loss: 12933627.0000 - val_mae: 2751.3684\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2496145.8056 - mae: 1070.0854 - val_loss: 12899464.0000 - val_mae: 2746.7717\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2351639.7917 - mae: 1061.5477 - val_loss: 13227634.0000 - val_mae: 2775.9785\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3256595.3611 - mae: 1163.6973 - val_loss: 12935731.0000 - val_mae: 2754.3877\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3356352.7222 - mae: 1148.1345 - val_loss: 12814539.0000 - val_mae: 2742.6943\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3514903.4444 - mae: 1151.8164 - val_loss: 12653379.0000 - val_mae: 2730.1624\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3235966.8611 - mae: 1203.3837 - val_loss: 12441644.0000 - val_mae: 2713.8657\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2889014.7778 - mae: 1129.3499 - val_loss: 12604379.0000 - val_mae: 2725.9802\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2647380.4722 - mae: 1110.0363 - val_loss: 12309867.0000 - val_mae: 2701.6934\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2298971.4167 - mae: 1054.9944 - val_loss: 13063317.0000 - val_mae: 2766.0408\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2390495.4861 - mae: 1029.1199 - val_loss: 13449991.0000 - val_mae: 2802.8318\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2697647.8194 - mae: 1071.4139 - val_loss: 13401469.0000 - val_mae: 2799.9836\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3066233.8333 - mae: 1152.9385 - val_loss: 13254261.0000 - val_mae: 2785.7170\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2850530.1806 - mae: 1057.1390 - val_loss: 13396093.0000 - val_mae: 2797.3337\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3219004.3889 - mae: 1113.1835 - val_loss: 13203954.0000 - val_mae: 2779.3113\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3212070.7778 - mae: 1153.4311 - val_loss: 12948852.0000 - val_mae: 2759.7021\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2429319.0694 - mae: 1033.2480 - val_loss: 13153139.0000 - val_mae: 2773.6052\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2879116.0556 - mae: 1150.6262 - val_loss: 13160952.0000 - val_mae: 2772.9177\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2103364.3889 - mae: 995.6309 - val_loss: 13420394.0000 - val_mae: 2799.1438\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2202986.2083 - mae: 970.1072 - val_loss: 13453215.0000 - val_mae: 2804.6860\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2964374.8889 - mae: 1204.3237 - val_loss: 13413401.0000 - val_mae: 2802.8145\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2967745.1389 - mae: 1183.1710 - val_loss: 13063512.0000 - val_mae: 2773.0676\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2781851.0278 - mae: 1126.8775 - val_loss: 13001720.0000 - val_mae: 2769.3364\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2497838.4306 - mae: 1040.0807 - val_loss: 12927697.0000 - val_mae: 2761.5806\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3171403.6389 - mae: 1169.3955 - val_loss: 12541469.0000 - val_mae: 2730.1970\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2542994.9861 - mae: 1052.8905 - val_loss: 12966053.0000 - val_mae: 2758.8367\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2882377.9167 - mae: 1099.4842 - val_loss: 13014809.0000 - val_mae: 2762.4575\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2179340.7361 - mae: 1008.2812 - val_loss: 13101819.0000 - val_mae: 2769.7588\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3558076.6111 - mae: 1184.2170 - val_loss: 13252312.0000 - val_mae: 2784.6838\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3254660.9167 - mae: 1144.4897 - val_loss: 13108498.0000 - val_mae: 2772.3518\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2797590.2639 - mae: 1087.8491 - val_loss: 12915651.0000 - val_mae: 2759.3518\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2053536.1389 - mae: 966.7219 - val_loss: 12975693.0000 - val_mae: 2759.4375\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3080116.3333 - mae: 1121.4828 - val_loss: 13340324.0000 - val_mae: 2789.5393\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2097989.9236 - mae: 938.7643 - val_loss: 13387131.0000 - val_mae: 2794.9585\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3202631.5278 - mae: 1120.7248 - val_loss: 13241011.0000 - val_mae: 2786.3269\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3435029.1389 - mae: 1156.5500 - val_loss: 13231150.0000 - val_mae: 2785.1135\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1832779.4236 - mae: 873.8819 - val_loss: 13340409.0000 - val_mae: 2795.4614\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2395838.6944 - mae: 990.6633 - val_loss: 12960626.0000 - val_mae: 2764.0581\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2536804.1944 - mae: 1020.2794 - val_loss: 12872982.0000 - val_mae: 2756.3645\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2207074.5139 - mae: 1023.4139 - val_loss: 12844113.0000 - val_mae: 2754.2722\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2272845.4583 - mae: 1021.3005 - val_loss: 13250643.0000 - val_mae: 2785.8574\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1680821.5347 - mae: 875.3020 - val_loss: 13303193.0000 - val_mae: 2791.2554\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2174799.2917 - mae: 932.6696 - val_loss: 13264860.0000 - val_mae: 2785.3601\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2141460.2500 - mae: 977.1204 - val_loss: 12890421.0000 - val_mae: 2754.4597\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2194807.3819 - mae: 963.8183 - val_loss: 12664226.0000 - val_mae: 2740.1265\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3114838.6667 - mae: 1121.6881 - val_loss: 12654553.0000 - val_mae: 2740.2053\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2322117.0833 - mae: 1066.1747 - val_loss: 12716178.0000 - val_mae: 2745.0234\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2126676.5000 - mae: 965.1127 - val_loss: 12857905.0000 - val_mae: 2757.8691\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2432380.9167 - mae: 1086.8912 - val_loss: 13601257.0000 - val_mae: 2822.0786\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2661595.3889 - mae: 1083.4624 - val_loss: 13253857.0000 - val_mae: 2792.0190\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2398550.3889 - mae: 1020.8838 - val_loss: 13658869.0000 - val_mae: 2830.5137\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2132394.5417 - mae: 1026.6009 - val_loss: 13319443.0000 - val_mae: 2806.6140\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1867937.5903 - mae: 916.8934 - val_loss: 13472143.0000 - val_mae: 2817.3455\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3277344.4167 - mae: 1160.3882 - val_loss: 13359931.0000 - val_mae: 2808.8159\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1933223.2014 - mae: 892.7300 - val_loss: 13590293.0000 - val_mae: 2824.8906\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2304703.4583 - mae: 1000.7765 - val_loss: 13584938.0000 - val_mae: 2826.4043\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1649194.7222 - mae: 839.9570 - val_loss: 13753903.0000 - val_mae: 2844.9470\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2491265.4722 - mae: 1016.1357 - val_loss: 13006951.0000 - val_mae: 2781.0498\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2966558.6667 - mae: 1050.5278 - val_loss: 12970426.0000 - val_mae: 2779.0544\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2824077.7778 - mae: 1128.1987 - val_loss: 12948760.0000 - val_mae: 2775.1130\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1784012.3750 - mae: 880.0252 - val_loss: 13635254.0000 - val_mae: 2834.4902\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2081124.0486 - mae: 881.9478 - val_loss: 13550794.0000 - val_mae: 2826.6470\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2140717.8333 - mae: 934.0749 - val_loss: 13809373.0000 - val_mae: 2847.8149\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1750188.0486 - mae: 870.3530 - val_loss: 13498286.0000 - val_mae: 2820.8726\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2400944.3194 - mae: 981.2184 - val_loss: 13570533.0000 - val_mae: 2827.7395\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2091370.4167 - mae: 921.1980 - val_loss: 13069524.0000 - val_mae: 2784.1614\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1916218.3194 - mae: 954.4445 - val_loss: 13410651.0000 - val_mae: 2814.4172\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2186942.3472 - mae: 947.7552 - val_loss: 13468741.0000 - val_mae: 2819.8040\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2703645.6111 - mae: 1011.6238 - val_loss: 13042432.0000 - val_mae: 2783.5447\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2515304.0278 - mae: 935.2601 - val_loss: 13273191.0000 - val_mae: 2805.9944\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1745434.4167 - mae: 904.7807 - val_loss: 13766665.0000 - val_mae: 2850.0474\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2014172.0764 - mae: 881.8577 - val_loss: 13773894.0000 - val_mae: 2853.4473\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1687557.5417 - mae: 865.2316 - val_loss: 13814262.0000 - val_mae: 2853.4714\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1978233.8889 - mae: 902.8350 - val_loss: 13335471.0000 - val_mae: 2811.4087\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2210474.7083 - mae: 897.3359 - val_loss: 13183625.0000 - val_mae: 2801.5762\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1549825.8056 - mae: 825.0521 - val_loss: 13211727.0000 - val_mae: 2800.4116\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2202811.6667 - mae: 882.3650 - val_loss: 13012177.0000 - val_mae: 2783.3503\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2185514.4583 - mae: 909.1675 - val_loss: 13354517.0000 - val_mae: 2811.6689\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1939358.6111 - mae: 908.9722 - val_loss: 13259563.0000 - val_mae: 2807.5303\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1773567.4861 - mae: 842.4606 - val_loss: 13456561.0000 - val_mae: 2823.3943\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1596697.4792 - mae: 790.6853 - val_loss: 13151859.0000 - val_mae: 2798.9426\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1875171.9444 - mae: 900.2917 - val_loss: 13012602.0000 - val_mae: 2788.5974\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1516003.9062 - mae: 799.5901 - val_loss: 13427886.0000 - val_mae: 2825.2556\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2116568.2083 - mae: 813.7929 - val_loss: 12937903.0000 - val_mae: 2781.4597\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1693193.6597 - mae: 815.3295 - val_loss: 13116617.0000 - val_mae: 2797.3137\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1919096.3194 - mae: 871.5033 - val_loss: 13657425.0000 - val_mae: 2845.3096\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2191771.1528 - mae: 951.6203 - val_loss: 13531425.0000 - val_mae: 2837.2480\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1776661.3194 - mae: 811.2106 - val_loss: 13102186.0000 - val_mae: 2797.8323\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1675980.0764 - mae: 842.7919 - val_loss: 13127295.0000 - val_mae: 2801.1079\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2502081.5139 - mae: 944.5752 - val_loss: 13239005.0000 - val_mae: 2811.6743\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1747093.2361 - mae: 903.9464 - val_loss: 13537240.0000 - val_mae: 2835.9988\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1946747.1250 - mae: 864.8806 - val_loss: 13257293.0000 - val_mae: 2812.4495\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2078827.1111 - mae: 883.5355 - val_loss: 13733219.0000 - val_mae: 2853.4871\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1956362.7500 - mae: 924.7164 - val_loss: 13609562.0000 - val_mae: 2844.3940\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2407836.9306 - mae: 931.3969 - val_loss: 13554697.0000 - val_mae: 2841.8215\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2666825.3472 - mae: 985.3465 - val_loss: 13647493.0000 - val_mae: 2848.8743\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2696051.2778 - mae: 999.7327 - val_loss: 13696959.0000 - val_mae: 2849.2925\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1875486.4583 - mae: 827.2957 - val_loss: 13098870.0000 - val_mae: 2795.9314\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1930064.1528 - mae: 865.9086 - val_loss: 13097190.0000 - val_mae: 2794.6208\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1550081.5694 - mae: 844.7389 - val_loss: 13189521.0000 - val_mae: 2801.9861\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2401428.2778 - mae: 946.8647 - val_loss: 13342022.0000 - val_mae: 2816.9792\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1543053.3750 - mae: 817.3822 - val_loss: 13462335.0000 - val_mae: 2828.9697\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2391039.4861 - mae: 919.7411 - val_loss: 13146715.0000 - val_mae: 2798.7991\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1596724.1944 - mae: 795.8156 - val_loss: 13424586.0000 - val_mae: 2827.9048\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1330339.8264 - mae: 763.1686 - val_loss: 13170875.0000 - val_mae: 2803.7134\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1113822.4583 - mae: 683.4335 - val_loss: 13818419.0000 - val_mae: 2863.4353\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1498427.3750 - mae: 799.5433 - val_loss: 13764233.0000 - val_mae: 2859.4438\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1685786.6528 - mae: 808.9360 - val_loss: 13626299.0000 - val_mae: 2849.8474\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1948377.3056 - mae: 906.8028 - val_loss: 13745662.0000 - val_mae: 2859.2712\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2333787.8472 - mae: 917.4775 - val_loss: 13790014.0000 - val_mae: 2861.6382\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1651712.3611 - mae: 810.9823 - val_loss: 13675305.0000 - val_mae: 2854.5403\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1396700.2708 - mae: 741.9034 - val_loss: 14079743.0000 - val_mae: 2890.3276\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1743102.5000 - mae: 823.2888 - val_loss: 13658831.0000 - val_mae: 2855.9116\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1380476.7014 - mae: 741.8085 - val_loss: 13326362.0000 - val_mae: 2823.8682\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1439012.7118 - mae: 731.7584 - val_loss: 13501048.0000 - val_mae: 2841.7029\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1490076.6736 - mae: 725.0196 - val_loss: 13670835.0000 - val_mae: 2855.9846\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1693399.5972 - mae: 823.4752 - val_loss: 13806209.0000 - val_mae: 2870.1938\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2121224.9306 - mae: 847.9849 - val_loss: 13975436.0000 - val_mae: 2883.0032\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1478382.0000 - mae: 801.9441 - val_loss: 13731443.0000 - val_mae: 2862.0383\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1893623.9722 - mae: 815.5615 - val_loss: 13482034.0000 - val_mae: 2837.8923\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1412930.0347 - mae: 734.6301 - val_loss: 13739611.0000 - val_mae: 2861.9995\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1693044.3333 - mae: 801.8603 - val_loss: 13749416.0000 - val_mae: 2864.4976\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2138783.6944 - mae: 830.1638 - val_loss: 13549997.0000 - val_mae: 2846.6299\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1973160.8194 - mae: 869.5118 - val_loss: 13663512.0000 - val_mae: 2852.6643\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1273919.6875 - mae: 709.0939 - val_loss: 14045091.0000 - val_mae: 2886.0962\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1252531.1597 - mae: 686.6449 - val_loss: 14048394.0000 - val_mae: 2886.7185\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1573995.6285 - mae: 741.4259 - val_loss: 13947489.0000 - val_mae: 2879.1536\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2161574.3750 - mae: 867.0873 - val_loss: 13683167.0000 - val_mae: 2856.8960\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2111636.3611 - mae: 849.7197 - val_loss: 13929446.0000 - val_mae: 2875.2627\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1301930.4444 - mae: 704.8028 - val_loss: 13318043.0000 - val_mae: 2820.7036\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1633385.1389 - mae: 803.2539 - val_loss: 13723052.0000 - val_mae: 2855.3560\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1444523.1042 - mae: 720.7440 - val_loss: 13780889.0000 - val_mae: 2862.4290\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1905070.2361 - mae: 766.8962 - val_loss: 13964273.0000 - val_mae: 2881.4756\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1259553.8056 - mae: 689.0451 - val_loss: 13742987.0000 - val_mae: 2861.2898\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1186847.4028 - mae: 717.5553 - val_loss: 13767829.0000 - val_mae: 2863.1187\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1867752.1528 - mae: 747.5246 - val_loss: 13396029.0000 - val_mae: 2831.7874\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1143839.8889 - mae: 689.3555 - val_loss: 14028488.0000 - val_mae: 2888.8303\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1339404.1875 - mae: 716.1966 - val_loss: 13759251.0000 - val_mae: 2867.1895\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1526032.7500 - mae: 752.0501 - val_loss: 13791534.0000 - val_mae: 2868.5029\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1046719.0278 - mae: 634.7770 - val_loss: 13922329.0000 - val_mae: 2880.5981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "QdOcvV5puIU3",
        "outputId": "aef069e7-ffb9-4053-c26a-64685e90c898"
      },
      "source": [
        "history_dict = Model_Results4.history\n",
        "mae_values = history_dict['mae']\n",
        "val_mae_values = history_dict['val_mae']\n",
        "epoches = np.arange(1,len(history_dict['mae'])+1)\n",
        "plt.plot(epoches,mae_values,'r',label=\"Training Mae\")\n",
        "plt.plot(epoches,val_mae_values,'g',label=\"Validating Mae\")\n",
        "plt.title('Training and validation Mae')\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Mae\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hVVdb48e9K76QQkkCAAEIwlBAIHRFQESygiAr6UxjbjG0cHbsz6ujo6Oj7Wt6ZseuI44jYUZGigqAUCb33AKGGEJIASUjZvz/2SUhCOkluyvo8z33uvfvsc+46CdyVXc4+YoxBKaWUqg03VweglFKq6dIkopRSqtY0iSillKo1TSJKKaVqTZOIUkqpWtMkopRSqtY0iahGQ0S+E5EpdV3XlUQkWUQurIfjGhE5x3n9uoj8uTp1a/E514vI3NrGqZo/0etE1NkQkeMl3voBuUCB8/63xpgPGz6qxkNEkoFbjDHf1/FxDdDVGLO9ruqKSAywC/A0xuTXRZyVfNYIYD7wpTHmyhLl8cBq4CdjzIj6jEHVDQ9XB6CaNmNMQNHryr4wRcSjvr+YVJOTCgwWkTBjTJpTNgXY6sKYVA1pd5aqFyIyQkRSROQhETkIvCciISLyjYikiki68zq6xD4LROQW5/VUEflZRF506u4SkbG1rNtJRBaKSJaIfC8i/xSR/1QQd3VifFpEfnGON1dEWpfYfoOI7BaRNBF5rJKfz0AROSgi7iXKrhSRtc7rASKyRESOicgBEfmHiHhVcKx/i8hfS7x/wNlnv4jcVKbupSKySkQyRWSviDxZYvNC5/mYiBwXkcFFP9sS+w8RkeUikuE8D6nuz6Ycp4AvgUnO/u7AtUCp1quIvOLEmikiK0TkvBLb3ETkYRHZ4fzMZ4hIaCWfqeqYJhFVnyKBUKAjcBv239t7zvsOQDbwj0r2HwhsAVoDfwfeERGpRd3/Ar8CYcCTwA2VfGZ1YrwO+A3QBvAC7gcQkTjgNef4bZ3Pi6YcxphlwAlgVJnj/td5XQDc65zPYOAC4I5K4saJYYwTz0VAV6DseMwJ4EYgGLgUuF1ErnC2DXeeg40xAcaYJWWOHQp8C7zqnNv/At+KSFiZczjjZ1OJaU48ABcD64H9ZeosB/pg/y39F/hERHycbXcDVwDnY3/m6cA/q/hMVYc0iaj6VAg8YYzJNcZkG2PSjDGfGWNOGmOygGew//krstsY85YxpgB4H4gCImpSV0Q6AP2Bx40xp4wxPwMzK/rAasb4njFmqzEmG5iB/YIDmAh8Y4xZaIzJBf7s/Awq8hEwGUBEAoFLnDKMMSuMMUuNMfnGmGTgjXLiKM81TnzrjTEnsEmz5PktMMasM8YUGmPWOp9XneOCTTrbjDEfOHF9BGwGLi9Rp6KfTbmMMYuBUBGJxSaTaeXU+Y/ze8k3xvwP4A3EOpt/BzxmjElxfuZPAhNFRLvqG4gmEVWfUo0xOUVvRMRPRN5wunsysd0nwSW7dMo4WPTCGHPSeRlQw7ptgaMlygD2VhRwNWM8WOL1yRIxtS15bOdLPI2K/ReYICLewARgpTFmtxNHN6cr7aATx7PYVklVSsUA7C5zfgNFZL7TXZeB/RKuznGLjr27TNluoF2J9xX9bCrzAXAXMBL4ouxGEblfRDY5XWjHgFYlYu4IfOF0+x0DNmFbcRX9saHqmCYRVZ/KTv37I/YvyIHGmCBOd59U1EVVFw5g/9L1K1HWvpL6ZxPjgZLHdj4zrKLKxpiN2C/hsZTuygLbLbYZO6sqCHi0NjFgu+RK+i+2JdbeGNMKeL3Ecauaqrkf+6VdUgdgXzXiqswH2K66WWWSPc74x4PYFlaIMSYYyCgR815grDEmuMTDxxhztjGpatIkohpSIHaM4ZjTv/5EfX+g85d9EvCkiHiJyGBKd7/UZYyfApeJyDBnEPwpqv4/9l/gHmyy+qRMHJnAcRHpDtxezRhmAFNFJM5JYmXjD8S2zHJEZAA2eRVJxXa/da7g2LOAbiJynYh4iMi1QBzwTTVjK5cxZhe2S628iQiBQL4Tm4eIPA4Eldj+OvCMiHQEEJFwERl/NvGomtEkohrSy4AvcARYCsxuoM+9Hjs4nQb8FfgYez1LeWodozFmA3AnNjEcwA7yplSxW9GYxI/GmCMlyu/HfsFnAW85MVcnhu+cc/gR2O48l3QH8JSIZAGPY5NO0b4nsWNAvzjdQ4PKHDsNuAzbWkvDthAuKxN3rRhjfjbGlB1QB5iD/R1sxbbacijdXfcKtmU11zmnpdhJFqqB6MWGqsURkY+BzcaYem8JKdXcaUtENXsi0l9EujjXFIwBxmOvT1BKnSWdBqdagkjgc+wgdwpwuzFmlWtDUqp50O4spZRStabdWUoppWqtxXVntW7d2sTExLg6DKWUajJat27NnDlz5hhjxpTd1uKSSExMDElJSa4OQymlmpSKFtPU7iyllFK1pklEKaVUrWkSUUopVWstbkxEKdVw8vLySElJIScnp+rKqlHw8fEhOjoaT0/PatXXJKKUqjcpKSkEBgYSExNDxfcTU42FMYa0tDRSUlLo1KlTtfbR7iylVL3JyckhLCxME0gTISKEhYXVqOWoSUQpVa80gTQtNf191Vt3loi8i102+rAxpmeZbX8EXgTCjTFHnHthv4K9PehJYKoxZqVTdwrwJ2fXvxpj3nfK+wH/xi7bPQu4x9TnGi7/939w9Ch4eoKXl32UfB0aCm3a2Ed0NLhXdLM+pZRqRowx9fLA3mSnL7C+THl77D0CdgOtnbJLgO+wdysbBCxzykOBnc5ziPM6xNn2q1NXnH3HVieufv36mVrp0cMYqN7D29uY3r2NmTTJmJdeMmb1amMKCmr3uUo1YRs3bnTZZx85csTEx8eb+Ph4ExERYdq2bVv8Pjc3t9J9ly9fbu6+++4qP2Pw4MF1Euv8+fMNYN56663islWrVhnAvPDCC3XyGTVR3u8NSDLlfKfWW0vEGLNQRGLK2fQS9mY2X5UoGw9McwJdKiLBIhIFjADmGWOOAojIPGCMiCwAgowxS53yacAV2GRSP9avh8JCyMuDU6dOP586Bbm5tpVy+DAcPAhbt8KmTbBkCUyfbvePiIDrr4cpU6B373oLUyllhYWFsXr1agCefPJJAgICuP/++4u35+fn4+FR/ldgYmIiiYmJVX7G4sWL6yZYoGfPnsyYMYNbbrkFgI8++oj4+Pg6O359adAxEee2lfuMMWvKbGpH6buVpThllZWnlFNe0efeJiJJIpKUmppa+xNwcwNvbwgMtN1XkZHQoQN07QoDB8Lll8Ott8ILL8A330ByMuzZA++/D0OG2C6x+Hjo3x+++sq2W5RSDWbq1Kn87ne/Y+DAgTz44IP8+uuvDB48mISEBIYMGcKWLVsAWLBgAZdddhlgE9BNN93EiBEj6Ny5M6+++mrx8QICAorrjxgxgokTJ9K9e3euv/76op4XZs2aRffu3enXrx+///3vi49bVseOHcnJyeHQoUMYY5g9ezZjx44t3v7WW2/Rv39/4uPjueqqqzh50t6OPjU1lauuuor+/fvTv39/fvnll7r/wVWiwab4Ovd7fhQY3VCfWcQY8ybwJkBiYmLDfnO3bw833mgfR47Ylskrr8AVV0C/fjbhjBzZoCEp5RJ/+AM4LYM606cPvPxyjXZJSUlh8eLFuLu7k5mZyaJFi/Dw8OD777/n0Ucf5bPPPjtjn82bNzN//nyysrKIjY3l9ttvP+M6ilWrVrFhwwbatm3L0KFD+eWXX0hMTOS3v/0tCxcupFOnTkyePLnS2CZOnMgnn3xCQkICffv2xdvbu3jbhAkTuPXWWwH405/+xDvvvMPdd9/NPffcw7333suwYcPYs2cPF198MZs2barRz+RsNOR1Il2ATsAaZ/Q/GlgpIgOAfdixkiLRTtk+bJdWyfIFTnl0OfUbt9at4a674He/g//8Bx5/HEaNguuus62U0FBXR6hUs3f11Vfj7kx8ycjIYMqUKWzbtg0RIS8vr9x9Lr30Ury9vfH29qZNmzYcOnSI6OjoUnUGDBhQXNanTx+Sk5MJCAigc+fOxddcTJ48mTfffLPC2K655hquvfZaNm/ezOTJk0t1l61fv54//elPHDt2jOPHj3PxxRcD8P3337Nx48biepmZmRw/fry4lVTfGiyJGGPWAW2K3otIMpBo7OysmcBdIjIdGAhkGGMOiMgc4FkRCXF2Gw08Yow5KiKZIjIIWAbcCPxfQ53LWfPwgKlTYdIk+Nvf7OOXX+Djj223mFLNUQ1bDPXF39+/+PWf//xnRo4cyRdffEFycjIjRowod5+SLQJ3d3fy8/NrVacqkZGReHp6Mm/ePF555ZVSSWTq1Kl8+eWXxMfH8+9//5sFCxYAUFhYyNKlS/Hx8anx59WFehsTEZGPgCVArIikiMjNlVSfhZ15tR14C7gDwBlQfxpY7jyeKhpkd+q87eyzg/ocVK8vPj7wl7/Azz/b98OHw+efuzYmpVqQjIwM2rWzw6n//ve/6/z4sbGx7Ny5k+TkZAA+/vjjKvd56qmneP7554tbS0WysrKIiooiLy+PDz/8sLh89OjR/N//nf4benVddxlWoT5nZ1Xa+WeMiSnx2gB3VlDvXeDdcsqTgJ5n7tEEDRgAK1fCZZfB1VfDO+/YlopSql49+OCDTJkyhb/+9a9ceumldX58X19f/vWvfzFmzBj8/f3p379/lfsMGTKk3PKnn36agQMHEh4ezsCBA8nKygLg1Vdf5c4776R3797k5+czfPhwXn/99To9j8q0uHusJyYmmkZ7U6rjx+HKK+H77+HNN+1ML6WasE2bNnHuuee6OgyXKhqfMMZw55130rVrV+69915Xh1Wp8n5vIrLCGHPGvGdd9qQxCQiwU4PHjrWD77NmuToipdRZeuutt+jTpw89evQgIyOD3/72t64OqU5pS6QxOn4czj8ftmyBxYv14kTVZGlLpGnSlkhTV9QiCQyEyZMhO9vVESmlVLk0iTRWUVEwbRps3AgllmpQSqnGRJNIY3bRRfDHP8K//gUzZ7o6GqWUOoMmkcbumWcgIQFuugn273d1NEopVYomkcbO2xv++184ccK2SpRS1TZy5EjmzJlTquzll1/m9ttvr3CfESNGUDT55pJLLuHYsWNn1HnyySd58cUXK/3sL7/8stRyJI8//jjff/99TcKvUExMDOedd16psj59+tCzZ8NfOqdJpCno3h0efNAu3rhwoaujUarJmDx5MtOLbsfgmD59epULIRaZNWsWwcHBtfrssknkqaee4sILL6zVscqTlZXF3r12kfOGXHCxLE0iTcVDD9ll5+++G2qxJo9SLdHEiRP59ttvOXXqFADJycns37+f8847j9tvv53ExER69OjBE088Ue7+MTExHDlyBIBnnnmGbt26MWzYsOIl46H8JdoXL17MzJkzeeCBB+jTpw87duxg6tSpfPrpp8XHfeKJJ+jbty+9evVi8+bNgF3W/aKLLqJHjx7ccsstdOzYsfjzy7rmmmuKl1H56KOPSiXG5ORkzjvvPPr27Uvfvn1LrcH1wgsv0L9/f3r37l3heddEQ67iq86Gnx/87//CxInwxhtwZ7mrxCjVaP1h9h9YfbBu13XqE9mHl8dUvLBjaGgoAwYM4LvvvmP8+PFMnz6da665BhHhmWeeITQ0lIKCAi644ALWrl1L7wquyVqxYgXTp09n9erV5Ofn07dvX/r16wdUvET7uHHjuOyyy5g4cWK5x2zdujUrV67kX//6Fy+++CJvv/02f/nLXxg1ahSPPPIIs2fP5p133qnw3K666ip+85vfcP/99/P111/z4Ycf8sEHHwDQpk0b5s2bh4+PD9u2bWPy5MkkJSUxd+5ctm3bxq+//ooxhnHjxrFw4UKGDx9erZ93ebQl0pRMmGCXjn/ySTtGopSqUskurZJdWTNmzKBv374kJCSwYcOGUl1PZS1atIgrr7wSPz8/goKCGDduXPG29evXc95559GrVy8+/PBDNmzYUK24JkyYAEC/fv2KF2j8+eefmTRpEgBjxowhJCSkot0JCwsjJCSE6dOnc+655+Ln51e8LS8vj1tvvZVevXpx9dVXF5/b3LlzmTt3bvH9SjZv3sy2bduqFW9FtCXSlIjAU0/BsGHw1lv2Jj9KNRGVtRjq0/jx47n33ntZuXIlJ0+epF+/fuzatYsXX3yR5cuXExISwtSpU8nJyanV8Staor0qRUvH13bZeIBrr72WO++884wViF966SUiIiJYs2YNhYWFxcvEG2N45JFH6nTpFW2JNDVDh9olUV54wd7bXSlVqYCAAEaOHMlNN91U3ArJzMzE39+fVq1acejQIb77rvI7SQwfPpwvv/yS7OxssrKy+Prrr4u3VbREe2BgYPFKu9U1dOhQZsyYAdhWQ3p6eqX1r7zySh588MHiG1QVycjIICoqCjc3Nz744AMKCgoAuPjii3n33Xc5fvw4APv27ePw4cM1irEsTSJN0WOP2WtG3n/f1ZEo1SRMnjyZNWvWFCeR+Ph4EhIS6N69O9dddx1Dhw6tdP++ffty7bXXEh8fz9ixY0st6V60RPvQoUPp3r17cfmkSZN44YUXSEhIYMeOHdWK84knnmDu3Ln07NmTTz75hMjISAIDAyusHxgYyEMPPYSXl1ep8jvuuIP333+f+Ph4Nm/eXHwjrtGjR3PdddcxePBgevXqxcSJE2uc6MrSBRibImPsPUgyMmDzZnDTvwVU46QLMNZMbm4u7u7ueHh4sGTJEm6//fYGv8kU1GwBRh0TaYpE7IWHkyfDt9/C5Ze7OiKlVB3Ys2cP11xzDYWFhXh5efHWW2+5OqQqaRJpqq66CqKj4aWXNIko1Ux07dqVVatWuTqMGtF+kKbK0xN+/3uYPx+a2D861bK0tC7zpq6mvy9NIk3ZrbeCv79tjSjVCPn4+JCWlqaJpIkwxpCWllY8Jbg66q07S0TeBS4DDhtjejplLwCXA6eAHcBvjDHHnG2PADcDBcDvjTFznPIxwCuAO/C2MeY5p7wTMB0IA1YANxhjTtXX+TRKwcF2dd/XX7dTfiMiXB2RUqVER0eTkpJCamqqq0NR1eTj40N0dHS169fb7CwRGQ4cB6aVSCKjgR+NMfki8jyAMeYhEYkDPgIGAG2B74FuzqG2AhcBKcByYLIxZqOIzAA+N8ZMF5HXgTXGmNeqiqtZzM4qaeNG6NHDLoly772ujkYp1Uw1+O1xjTELgaNlyuYaY4ouzVwKFKW78cB0Y0yuMWYXsB2bUAYA240xO51WxnRgvIgIMAr41Nn/feCK+jqXRi0uDvr3hzJXrCqlVENw5ZjITUDRZaLtgL0ltqU4ZRWVhwHHSiSkovJyichtIpIkIknNslk9dSqsXQsumE+ulGrZXJJEROQxIB/4sKq6dcEY86YxJtEYkxgeHt4QH9mwJk0CLy9tjSilGlyDJxERmYodcL/enB6Q2Qe0L1Et2imrqDwNCBYRjzLlLVNoKIwbBx9+CKda1twCpZRrNWgScWZaPQiMM8acLLFpJjBJRLydWVddgV+xA+ldRaSTiHgBk4CZTvKZDxQt1D8F+KqhzqNRmjoVjhyBKhaSU0qpulRvSUREPgKWALEikiIiNwP/AAKBeSKy2plVhTFmAzAD2AjMBu40xhQ4Yx53AXOATcAMpy7AQ8B9IrIdO0ZS8d1bWoKLL4Y2bez92JVSqoHoAozNye23wwcfwOHD9k6ISilVRxp8iq9ygYkT7R0PZ892dSRKqRZCk0hzcv750Lo1fPpp1XWVUqoOaBJpTjw84Mor4euvITvb1dEopVoAXQq+mm6deSspWSl4uHng6eZpn93ts7+nP6G+oYT5htHarzUxwTF0C+tGG/822IvrG9DVV9v7r8+dC+PHN+xnK6VaHE0i1XQi7wRpJ9PIL8wnvzCfvMI8+1yQx/FTx0nPSafQFJbaJ8g7iP5t+zO843DO73g+g6IH4e3hXb+BjhgBgYH2ZlWaRJRS9UxnZ9WRQlNIRk4GqSdT2Zm+k61pW9l8ZDOL9y5m7aG1GAxB3kFc1u0ybk64mZExI+uvlTJhAixfDnv22LsgKqXUWapodpYmkQaQnp3Ooj2LmLllJl9s/oKj2UfpEd6DPwz6Azf0vqHuWydvv23vNbJuHfTsWbfHVkq1SDrF14VCfEMYFzuOt8e9zb779vHe+PfwcPPg1q9vJfYfsUxbM+2MrrCzMmaMfdar15VS9UyTSAPz8fBhap+prPrtKmZfP5swvzCmfDmF0R+MZk/Gnrr5kOho6NVLk4hSqt5pEnEREeHicy5m+a3LeeOyN1i2bxm9XuvF11u+rpsPGDsWfv4ZsrLq5nhKKVUOTSIu5iZu3NbvNtb8bg3nhJ7DuOnjePqnp8/+ntRjx0JeHvzwQ90EqpRS5dAk0kh0DunMz7/5mRt638DjCx7nvjn3nV0iGTrUTvWdNavuglRKqTL0OpFGxNfTl/eveJ8QnxBeXvYyBaaAV8a8UrupwJ6ecMEF9qJDpZSqJ5pEGhkR4eUxL+Pu5s5LS18iJjiG+wbfV7uDjRoFX34JyckQE1OXYSqlFKDdWY2SiPDi6BeZGDeR++fezxebvqjdgUaMsM8LFtRVaEopVYomkUbKTdyYdsU0BkYP5PrPr+fXfb/W/CA9ethVfefPr/sAlVIKTSKNmq+nL19N+orIgEgmfDyBo9lHa3YANze7PPyCBdDCViZQSjUMTSKNXBv/Nnxy9SccOnGIO769o+YztkaOtGtoJSfXS3xKqZZNk0gT0K9tP/4y4i98vOFj/ruuhvdQLxoX0S4tpVQ90CTSRDw09CGGth/KHbPuICUzpfo7xsVBeLgOriul6oUmkSbC3c2daVdO41TBKf4494/V31HEtkbmz9dxEaVUnau3JCIi74rIYRFZX6IsVETmicg25znEKRcReVVEtovIWhHpW2KfKU79bSIypUR5PxFZ5+zzqjT4LQQbXueQzjwy7BFmbJjB/F016J4aORJSUmDnzvoLTinVItVnS+TfwJgyZQ8DPxhjugI/OO8BxgJdncdtwGtgkw7wBDAQGAA8UZR4nDq3ltiv7Gc1Sw8MeYAOrTrw4PcPVn+QXcdFlFL1pN6SiDFmIVB2Tup44H3n9fvAFSXKpxlrKRAsIlHAxcA8Y8xRY0w6MA8Y42wLMsYsNfabdFqJYzVrvp6+/GXEX0jan8Rnmz6r3k7du0NEhI6LKKXqXEOPiUQYYw44rw8CEc7rdsDeEvVSnLLKylPKKS+XiNwmIkkikpSamnp2Z9AI3ND7BuLC43jsx8fIL8yvegcRe73ITz/Vf3BKqRbFZQPrTguiQUZ6jTFvGmMSjTGJ4eHhDfGR9crdzZ1nRz3L1rStvLfqvertNGSIHRdJqcHMLqWUqkJDJ5FDTlcUzvNhp3wf0L5EvWinrLLy6HLKW4xxseMYHD2YJ396kuy87Kp3GDTIPi9bVr+BKaValIZOIjOBohlWU4CvSpTf6MzSGgRkON1ec4DRIhLiDKiPBuY42zJFZJAzK+vGEsdqEUSE5y58jv1Z+3kt6bWqd+jTB7y8YOnS+g9OKdVi1OcU34+AJUCsiKSIyM3Ac8BFIrINuNB5DzAL2AlsB94C7gAwxhwFngaWO4+nnDKcOm87++wAWtwNxYd3HM7wjsN5ddmrVY+NeHtDv36aRJRSdUrO+jasTUxiYqJJSkpydRh15otNXzBhxgQ+vfpTroq7qvLK990Hr70GmZn2plVKKVVNIrLCGJNYtlyvWG/ixsWOIyY4hleWvVJ15UGDICcH1q6t/8CUUi2CJpEmzt3NnbsH3M2iPYtYsX9F5ZWLBte1S0spVUc0iTQDNyfcTIBXQNWtkfbtISoKlixpmMCUUs2eJpFmoJVPK37T5zdMXz+dA1kHKq4oAgMGQDMaE1JKuZYmkWbi7gF3k1+Yzxsr3qi8YmIibNliB9eVUuosaRJpJrqGdeWiLhfx7qp3KSgsqLhiojO5YuXKhglMKdWsaRJpRm5OuJm9mXv5YdcPFVfq188+r6hiEF4ppapBk0gzMj52PKG+oby76t2KK4WHQ4cOOi6ilKoTmkSaEW8Pbyb1mMTMLTPJys2quGJioiYRpVSd0CTSzEzuNZns/Gy+3vp1xZUSE2H7dkhPb7jAlFLNkiaRZmZI+yFEB0Uzff30iivp4LpSqo5oEmlm3MSNa+KuYfb22WTmVjCNt2hwXbu0lFJnSZNIM3TluVeSV5jHnO1zyq8QGgodO8Lq1Q0bmFKq2dEk0gwNjh5MmG8YM7fOrLhS7966EKNS6qxpEmmG3N3cubTbpXy79duK7zMSH2+vXM/JadjglFLNiiaRZmpct3Gk56SzeO/i8ivEx0NBAWzY0LCBKaWaFU0izdToLqPxcvdi5pYKurTi4+3zmjUNF5RSqtnRJNJMBXoHMqrTKL7a8hXl3r2ySxfw99ckopQ6K5pEmrFx3cax/eh2tqRtOXOjmxv06qWD60qps6JJpBm7PPZygIq7tHr3ti2R8loqSilVDS5JIiJyr4hsEJH1IvKRiPiISCcRWSYi20XkYxHxcup6O++3O9tjShznEad8i4hc7Ipzacyig6LpG9W38nGR9HRISWnYwJRSzUaDJxERaQf8Hkg0xvQE3IFJwPPAS8aYc4B04GZnl5uBdKf8JaceIhLn7NcDGAP8S0TcG/JcmoLLu13OkpQlpJ5IPXOjDq4rpc6Sq7qzPABfEfEA/IADwCjgU2f7+8AVzuvxznuc7ReIiDjl040xucaYXcB2YEADxd9kjIsdR6EpZNa2WWdu7N3bPmsSUUrVUoMnEWPMPuBFYA82eWQAK4BjxpiiK+NSgHbO63bAXmfffKd+WMnycvZRjoTIBNoFtiv/6vXAQOjcWQfXlVK1Vu0kIiIdReRC57WviATW5gNFJATbiugEtAX8sd1R9UZEbhORJBFJSk0tp1unGRMRxsWOY872OeTkl3N1etHgulJK1UK1koiI3IrtSnrDKYoGvqzlZ14I7DLGpBpj8oDPgaFAsNO9VXT8fc7rfUB7Jw4PoBWQVrK8nH1KMca8abGBHuQAACAASURBVIxJNMYkhoeH1zLspmtc7DhO5J1g/q75Z27s3Ru2bdPlT5RStVLdlsid2C/6TABjzDagTS0/cw8wSET8nLGNC4CNwHxgolNnCvCV83qm8x5n+4/GXj03E5jkzN7qBHQFfq1lTM3ayJiRBHgFlD9LKy4OCgth69aGD0wp1eRVN4nkGmNOFb1xWgS1urjAGLMM26pZCaxzYngTeAi4T0S2Y8c83nF2eQcIc8rvAx52jrMBmIFNQLOBO40xBbWJqbnz9vBmdJfRfLvt2zOvXo+Ls88bNzZ8YEqpJs+j6ioA/CQij2JnVF0E3AFUcv/VyhljngCeKFO8k3JmVxljcoCrKzjOM8AztY2jJbmg0wV8vulzko8l0ymk0+kN3brZq9c1iSilaqG6LZGHgVRsy+G3wCzgT/UVlKp753c8H4AFyQtKb/D2tutobdrU8EEppZq8aiURY0yhMeYtY8zVxpiJzmtdK6MJiQuPo7VfaxbsXlDOxjhtiSilaqW6s7O6isinIrJRRHYWPeo7OFV3RIQRMSNYkLyg/HGRrVshL881wSmlmqzqdme9B7wG5AMjgWnAf+orKFU/RnQcwZ6MPSQfSy69IS4O8vNhxw6XxKWUarqqm0R8jTE/AGKM2W2MeRK4tP7CUvXh/Bg7LvLT7p9Kbzj3XPusXVpKqRqq9hRfEXEDtonIXSJyJRBQj3GpelA8LlJ2cL17d/usSUQpVUPVTSL3YBdK/D3QD7iB0xcAqibCTdw4v+P5ZyYRf3+IidEkopSqserOzlpujDlujEkxxvzGGDPBGLO0voNTdW9EzAh2Z+w+c1zk3HN1mq9SqsYqvdhQRCq4m5FljBlXt+Go+ja843AAFu1eRExwzOkNcXEwfz4UFIC73pZFKVU9VV2xPhi73PpHwDJA6j0iVa96hPcg0CuQJSlLuCH+htMb4uLsIozJyfbiQ6WUqoaqurMigUeBnsArwEXAEWPMT8aYnyrdUzVK7m7uDIoexOK9i0tv0DW0lFK1UGkSMcYUGGNmG2OmAIOwdw9cICJ3NUh0ql4Mjh7MusPryMrNOl1YNM1Xx0WUUjVQ5cC6s9T6BOzFhXcCrwJf1Hdgqv4Mbj+YQlPI8v3LTxe2agVt22pLRClVI5UmERGZBiwB+gJ/Mcb0N8Y87dziVjVRg6IHAbBk75LSG3QNLaVUDVXVEvl/2Js93QMsFpFM55ElIpn1H56qD8E+wcSGxZJ0IKn0hqJpvrq2plKqmiqdnWWMqfY92FXT0q9tPxbuXli6MC4Ojh+HlBRo3778HZVSqgRNEi1UYlQiKZkpHDp+6HShztBSStWQJpEWql/bfgCsOLDidKEmEaVUDWkSaaESIhMQhKT9JcZFWre2D53mq5SqJk0iLVSgdyDdW3cv3RIBnaGllKoRTSItWL+2/Uq3ROB0EtEZWkqpanBJEhGRYOd2u5tFZJOIDBaRUBGZJyLbnOcQp66IyKsisl1E1opI3xLHmeLU3yYiujR9DSVGJbI/az8Hsg6cLjz3XEhPh0OHKt5RKaUcrmqJvALMNsZ0B+KBTcDDwA/GmK7AD857gLHYa1W6Ardhb9OLiIQCTwADgQHAE0WJR1VPYttEoILBdR0XUUpVQ4MnERFpBQwH3gEwxpwyxhwDxgPvO9XeB65wXo8HphlrKRAsIlHAxcA8Y8xRY0w6MA8Y04Cn0uT1ieyDm7iV7tLSGVpKqRpwRUukE5AKvCciq0TkbRHxByKMMUX9KgeBCOd1O+xy9EVSnLKKys8gIreJSJKIJKWmptbhqTRt/l7+nNv63NJJJCrKrqOlSUQpVQ2uSCIe2LW4XjPGJAAnON11BYAxxgB1NrJrjHnTGJNojEkMDw+vq8M2C4ltE1lxYAWmaCBdRO9yqJSqNlckkRQgxRizzHn/KTapHHK6qXCeDzvb9wEl1+CIdsoqKlc10C+qHwePH2R/1v7ThTrNVylVTQ2eRIwxB4G9IhLrFF0AbARmAkUzrKYAXzmvZwI3OrO0BgEZTrfXHGC0iIQ4A+qjnTJVA0WD62eMixw6BGlpLopKKdVUuGp21t3AhyKyFugDPAs8B1wkItuAC533ALOAndgbYr0F3AFgjDkKPA0sdx5POWWqBuIj43ETt9IztPQGVUqpaqrqHuv1whizGkgsZ9MF5dQ12JthlXecd4F36za6lsXP048e4T3Kn6G1aRMMG+aawJRSTYJesa5IbJtI0v6k04PrHTqAn5+OiyilqqRJRNEvqh+pJ1NJyUyxBW5utktLk4hSqgqaRFT5g+uaRJRS1aBJRNE7ojcebh5njoukpECm3gVZKVUxTSIKX09feoT3KH8Nrc2bXROUUqpJ0CSigHIG14um+WqXllKqEppEFGCTSFp2GrszdtuCzp3By0uvFVFKVUqTiALsDC2AFfudLi0PD4iN1ZaIUqpSmkQUYAfXPd08zxxc1ySilKqEJhEFgLeHNz3b9CTpQJlpvrt2QXa26wJTSjVqmkRUscS2iazYX2JZ+Lg4e691naGllKqAJhFVrF9UP9Jz0k8PrsfH2+cVKyreSSnVomkSUcUSohIAWHlgpS3o2hXCwmDxYhdGpZRqzDSJqGK92vTCXdxZdWCVLRCBIUPgl19cG5hSqtHSJKKK+Xr60r11d1YdXHW6cOhQ2LoVjhxxXWBKqUZLk4gqpW9U39PdWWBbIgBLlrgmIKVUo6ZJRJWSEJnAgeMHOHT8kC1ITARPT+3SUkqVS5OIKqVocL24S8vXF/r21cF1pVS5NImoUvpE9gE4s0tr+XI4dcpFUSmlGitNIqqUYJ9gOod0PnNwPScHVq2qeEelVIvksiQiIu4iskpEvnHedxKRZSKyXUQ+FhEvp9zbeb/d2R5T4hiPOOVbRORi15xJ85MQmXB6mi/A4MH2Wbu0lFJluLIlcg9Qcp3x54GXjDHnAOnAzU75zUC6U/6SUw8RiQMmAT2AMcC/RMS9gWJv1vpG9WVH+g4ycjJsQdu2EBMDP//s0riUUo2PS5KIiEQDlwJvO+8FGAV86lR5H7jCeT3eeY+z/QKn/nhgujEm1xizC9gODGiYM2jeEiLt4Prqg6tPF44YAQsWQEGBS2JSSjVOrmqJvAw8CBQ678OAY8aYfOd9CtDOed0O2AvgbM9w6heXl7OPOgtnzNACuOgiOHpUx0WUUqU0eBIRkcuAw8aYBlvVT0RuE5EkEUlKTU1tqI9tsiIDIokKiCo9Q+uCC+zz99+7JiilVKPkipbIUGCciCQD07HdWK8AwSLi4dSJBvY5r/cB7QGc7a2AtJLl5exTijHmTWNMojEmMTw8vG7PpplKiEoo3RKJiIDevWHePNcFpZRqdBo8iRhjHjHGRBtjYrAD4z8aY64H5gMTnWpTgK+c1zOd9zjbfzT2hhczgUnO7K1OQFfg1wY6jWYvITKBTambyM4rcUOq0aPt4HpmpusCU0o1Ko3pOpGHgPtEZDt2zOMdp/wdIMwpvw94GMAYswGYAWwEZgN3GmN01LeO9I3qS4EpYN3hdacLx4+3FxzOmuW6wJRSjYpH1VXqjzFmAbDAeb2TcmZXGWNygKsr2P8Z4Jn6i7DlKpqhterAKga0c34tgwdDu3bw7rswaZILo1NKNRaNqSWiGpGY4BiCfYJLj4u4u8Ndd9lxkR9/dF1wSqlGQ5OIKpeI0CeyT+kZWgB33w2xsXDjjbB7t2uCU0o1GppEVIX6RvZl7aG15BXknS7094ePPrLXjHTrBmPHwvPPw7JlkJvrumCVUi6hSURVKCEqgdyCXDYf2VxmQwJs3gy33gopKfDwwzBoEPj4QOvWcOGF8PjjsGaNawJXSjUYlw6sq8ateHD94Cp6RfQqvbFDB/jHP+zrDRvsY+tWSEqC776DH36Ap5+GuDi44gqYOBG6doWAgAY+C6VUfdKWiKpQbOtYfD18S6/oW54ePeCaa+BPf4Ivv7TdWgcOwLPP2sUbn33W3tiqXTuYPBnmzIFjxxrmJJRS9UqTiKqQh5sHvSN6s/LgyqorlxUZCY88YmdyrVoF//mPTTRz5sCYMRAaatfjmjYNMjLqPnilVIPQJKIqNaDdAJbvW176yvWa6tMHrr8e3noL9u2D2bPhscdg506YMgXCwmDYMPjb32DPnroLXilV7zSJqEpd0vUSsvOz+XFXHV0X4usLF19sx0u2b7c3unr4YdsF9uij0LEjDBgAL70Ee/dWfTyllEtpElGVGhEzAn9Pf77Z+k3dH1zEXgX/17/ae7ivWwcvvGBvxXvffXDuufZ6lF91STSlGiuxaxm2HImJiSYpKcnVYTQpEz6ewPL9y9nzhz3Y+4E1gK1b7UD93Ll2zGT4cPjd7+z6XX5+DRODUlUwxrA3cy/e7t5EBERUWq/k/52j2Ufxdvem0BTi5+mHu5t7qbo/7/mZML8wsnKzWJqylORjyTw96ml2pe/ii81fEBsWS0xwDCfzTnLw+EFmbZ9F+6D2RAVEcVGXi1i0exH5hfm0b9Web7d+S1x4HFvTtvLq2Fdr/X9YRFYYYxLPKNckoqry3qr3uGnmTay8bWXxDasaTFYWvP02vPKKvUI+IACuugr+3/+DkSPtUiyqwRQUFmAweLjV/9UBZb94CwoL+GLzF3i4eRDkHcSwDsMoNIV8s/UbMnMzubTrpaW+yI+cPEKYbxjpOemsPLCSVt6tMBj6t+1PRm4GW9O20i2sG8E+wRSaQh774TG+2fYNXUK6EBkQyc70nSxNWcr/jP4f9mft551V75Cek06/qH5EBEQQ6BXIjvQdLEhegCA8NPQhzgk9h72Ze9mTsYeOrTqyJW0LXu5efLrxUy6PvZyogCimr5/OgeMHiuOMC4/jrv53sWjPInak72DlgZXkF+ZTVpB3EJm55a+gHewTTEZOBoaKv88j/CNYd/s6wv1rdzsMTSIOTSI1d/jEYSJfjOTJEU/y+PmPuyaIwkJYuNDO8vrkE7scfVSUvbDxxhvtOEpQkGtia8Ky87LJLcjlyMkjRAdFk56djqe7J639WhfXmbdjHsdPHSfML4zrPruO9Jx0bupzE9f2vJbOIZ1p7dcad3Fn17FdbEvbRqEppGNwR3qE9yD1ZCpZuVlk5mYSFRjFkZNHiAyI5OWlL3Nl9ytJ2p/E3kw79rX20FqS9icR4htCVEAUaw6tIbFtIjf0voFzQs/hhcUv8OnGT4vj8vXwJSc/p/iL09vdm25h3fD28ObIySMkH0umbWBbsnKzyDqVVbxfbFgsezP3cjLvJME+wdyScAs70nfwxeYviuv4efrRKbgTG1I3FJe18W9D19Cu/LL3l1I/w4eHPsz61PWVdvlG+Edw6MQh3MSNYJ9gBkcPZmj7oRw/dZznf3meAlNAK+9WZOTamYpjzxnL9b2uJ8g7CD9PP3Lyc3hn1TuMiBnBtT2uZUHyAjJyMwj1DeVUwSkmxk1kf9Z+3l/9PusOr+ORYY/g4ebBJxs/YXD0YHq26Un7Vu1xk9qPYGgScWgSqZ3B7wwmvzCf5bcud3UokJ0N33wDn31mn0+csC2Sq6+2F0H27Ak33ODqKGul0BSy4fAGvNy9CPQOpI1/m1J/9R/NPsqry17laPZRCk0hqSdTSc9O5/ip4/Rs05Mg7yBST6YS5BXE3sy9jDlnDDvTd/LT7p/w9/TnnoH3sP3odr7d9i1Zp7JYdWAVBWXuoBDiE8Kg6EHsOraLvII8dqTvKN7WNrAtQ9oPKfVlDuDl7sWpglPF7wUh1DeUtOy0ap+7r4cvl3W7jAJTwNa0rZzMO8mJUyc4dOJQcZ0/DPwD47uPZ1/mPr7d9i2RAZGM6jSKUN9QZmyYwTdbv+Hg8YNc1u0yuoV1Y/ORzRSYAm5JuIWc/BzWHlrLkpQleLp7cn2v63ljxRv8lPwTgd6BXBN3DX8c8kdiw2KLW0Dp2en8Z+1/cBM3bkq4CV9PX/Zl7iMlMwVfT1+MMcRHxgO25bPu0Do6hXSifVB7Vh5YicFw+MRhxp4zlqPZRwnwCsDX07fUeadkppCVm0X31t05lnOMQO9ABCnVxdUYaBJxaBKpnWcXPctjPz7Gvvv20TawravDOS0zE5YuhS++gBkz7JpeACNGQHi4XaLl5puhTZs6+0hjDF9v/ZouIV3o0aZHqW0703fS2q81Qd5BxXXTc9Jp5d2q+Eth97Hd3PjljWw/up0g7yAeGPIA3cK6sebgGu7+7u5SXRIR/hH4ePiQV5iHp5snR04eITs/m1bercjOz8bf059Q31CCfYLZmraVjNwMfDx8yM3PxdvDm5z8HACGdxzO9qPb2Z+1H4Ae4T3Iyc8hwCuAG+NvJNArkDWH1vDxho+J8I/Ay92LtoFtSctOo3/b/oyLHcd3277j1n630r11d1YfXM32o9s5fOIwh08c5vip40QHRdMlpAv+Xv78uOtH9mTsoUd4D3w9fdlyZAuhvqF0aNWBX/f9yvkx57Pm4BqGtB/CwOiBtPZrjZu4ndFNVmgKWbJ3CesOr+No9lHuH3I/Xu5eFf5uThWc4sSpE4T4hlT791loCs/qL/SWQpOIQ5NI7aw/vJ5er/Xin5f8kzv631Evn3Gq4BSC4OnuWav9txzZwuu//pMH1wSwaM6bTO94nFYZuYzb6UHY+WPZOaArA4ZdS1wne3+UYznHCPYJLnWMvRl7WZKyhBX7VzC843AycjOKu0Oy87L5Zpv9S3dPhr2e5ZKulxDiE1LcLXMy7yT+nv50CulEenY6IkJKZgrBPsFcHXc12fnZ/LDzB47lHCMiIILkY8lnnMeFnS8kyDuI9YfX4+vhS6hvKF1CupBTkEOAZwB3DriTnm16lvvzW7h7Ied3PJ/8wnw83DzYkb4DHw8fYoJjyMrNYuHuhcRHxhMdFA2cOe6gVEU0iTg0idSOMYaer/Uk2CeYX276peodypGVm8WxnGNMWzONIO8g+kb1xcvdi6lfTSXYJ5jFexfj7+mPwXBh5wt5YMgDfL/zez7b9Bn3DrqX63tdj7eHd/HxDh0/RLBPMGsPrSUtO624v75IdFA0ObknOJJ7usy9EO7ITyBs+BieXPo3hrQfQueQzpzMO0lUQBRvr3yb3IKKVyP29/RneMfhBHgFEOwTzE+7fyIrN4t+bfvRLbQbrf1as/LgSnal7+JUwSm2Hd3GvYPuZXfGbr7Y9AV+nn70jujNcxc+x4B2Ayg0hczePpsNhzdwQecLiI+Ib3TdGEqBJpFimkRq76UlL3Hf3PuYdd0sxnYdW26dk3knWb5vOcE+wWxI3UCITwh5hXn8z5L/YeHuhWf0nZd1Tug57MnYQ15B3hkzTQRhUPQgLup8EYdOHOKNFW+U2h4bFsvfLvgbjy94nAs7XcjfL/o7APfNuQ+vk7lMyO3MB6ve443ArQDEnwwix8eD3Z4n8PX0Iz0nnQCvAK7reR1/Pv/PbE3bSphvGH6efuzJ2MOB4wc4r8N5dAzuWO2fWUFhQXFSKPq/pn/5q6ZIk4hDk0jt5ebn0vv13hhjWHv7Wnw8fIq3bT+6nRkbZvDP5f8s7ncvqUOrDnQK7oSvpy9/HflXwv3DeXfVu2w/up2nRj5Fp+BOZOdn4+fphzGGzUc2s3z/csL9wkmISmDJ3iWsOLCCzzd9zqYjm4qneV7a9VJGdRpFoSnkiu5XEOobWuV5pPw8i+0fv0bC10kE7T9CQUE+hZ07kXPJaAIfehxp24jGfJRqJDSJODSJnJ15O+Yx+j+juSXhFp694FlWHljJA/MeYN3hdQB0Cu5EzzY9ubL7lXRv3Z207DQOnzjMNT2uIcCrbpaBL/nX/VnbtQs++ABWr7aD8wCBgfbujUOH2kH5nj3t1fVKtWCaRByaRM7eI98/wnO/PFf8PjIgkkeHPcolXS+hS2gXF0Z2ltats1fIL1kC69fbBSLz8uyNtoYMgalT7QrEvr5VHkqp5qbRJBERaQ9MAyIAA7xpjHlFREKBj4EYIBm4xhiTLrYD+RXgEuAkMNUYs9I51hTgT86h/2qMeb+qz9ckUjfm7ZjH6oOr6R3Rm8HtBxdPaW1WjhyBTz+163p9/rm9B0pwsG2hDBsGXbrABRfYZe2VauYaUxKJAqKMMStFJBBYAVwBTAWOGmOeE5GHgRBjzEMicglwNzaJDAReMcYMdJJOEpCITUYrgH7GmPQzP/U0TSKqVlJTYdEi+PZbu/LwZueWwe7ucN55ttvriivsPei160s1QxUlkQa/wsYYc6CoJWGMyQI2Ae2A8UBRS+J9bGLBKZ9mrKVAsJOILgbmGWOOOoljHjCmAU9FtSTh4TBhArzzDmzaBGlpNpk89BDs32+vkA8MhPbt7dL28+bpzbZUi+DSyzRFJAZIAJYBEcaYolXJDmK7u8AmmJI3lkhxyioqL+9zbhORJBFJSk1NrbP4VQsWGmqXsX/mGZtUvvsOnnsOevWCv/8dRo+GkBDbOnn9dbucfW7F158o1VTV/1KcFRCRAOAz4A/GmMySc+eNMUZE6qyfzRjzJvAm2O6sujquUgC4udkB9zFjbMvk+HGYNQtWrIA33oCvvrL1PDxskjnvPLjsMujc2d6Ey8Nl/w2VOmsuaYmIiCc2gXxojPncKT7kdFMVjZscdsr3Ae1L7B7tlFVUrpRrBQTY+8k//zykp9sl7D/6CG6/3XZ5vf66bamcc47tJrvqKvjzn+1tg7OzoYXNmFRNW4P/CeTMtnoH2GSM+d8Sm2YCU4DnnOevSpTfJSLTsQPrGcaYAyIyB3hWRIpWWhsNPNIQ56BUtYnYlYU7dIBJk2zZsWOwapW9RuWXX2DBAvjyS7vcPdgZYH362Ds79u9vk01cnL0XvVKNjCtmZw0DFgHrAOd/DY9ix0VmAB2A3dgpvkedpPMP7KD5SeA3xpgk51g3OfsCPGOMea+qz9fZWapRysmBH3+ElSth2zbYscMmmpMnT9fp3Bm6doW+fe304mHDbJln7RasVKomGs0UX1fTJKKajLw82xVWlFBWr4aNG+2jwLkHiIhNKuecY5e9P/dc6N4dunVzbeyq2dEk4tAkopq8ggLYvt12he3caa9fSUmxr4uEhNjE0qWLHbxv1QoGDrRJJiDAjs0oVQMVJRGdFqJUU+Pubtf2io0tXZ6aalsuy5bBhg020fz6q73qPr/EPbtFbKslNhYiI+3aYNHRNtm0bm1vM6xdZKqaNIko1VyEh9tH4hl/LNo7QC5aZJNMSoptxfz4o70gMiendN3ISJtMiiYEdOhwejpyWJgdl1HKoUlEqZYgKAguvfTM8vx8m1j274fkZDhwwC5AeeyY7R5btsxenV9S+/bQtq1NNpGRNrH4+9vus6LxGdViaBJRqiXz8LDjJl262Isgy3P8uE0wycl2UH/DBjh40E5RXrLELlRZND0ZwMfHdrm5udmusuBgOyYTGwujRtnE1bmzbeEUFGjXWROnA+tKqbNjjF3SZe1aWLgQDh+2ySEz064v5uNjk0/ZbjNPT5t8hgyxLSURO/gfG2u70zIy7PUy0dFw6pRNSu7umnRcRAfWlVL1Q8QmigED7KM8mZm2W2z1atv1tXs3bN1qr9BfuNBOAgD45puKP8fNzSaX4cOhTRv7CA+3zxERtostKsomGQ8PXU25gWgSUUrVv6Ag++jUqfJ6aWl2fObIEXuh5ZYtdnzG0xP27rXXzKxbZ2eiHT1a8XECA22XWatWNrmAHavp2NFOf+7SxbaCevXSls1Z0iSilGo8wsJKL+9S3mSAInl5NukcPmzHaA4csI+cHFuenGwTzeLFthtsxozSYzdF/PxOJ7nwcOjd28bQpcvpxTE7d7b1oqJsYvLxqdPTbso0iSilmiZPz9MzxHr3rrr+qVM2yRw+bLvT8vJsl1pWlu1uy8qy5TNm2IUzy0s4YBNLUTeap6ftngsPt7dNDguzXW7t29tWl6+vTTihobZOM2z1aBJRSrUMXl62O6tjR7uwZWXy8+04jZubfb1rF5w4YbvaDh+2j5QUuy0nx04qOHnStohKXthZVmjo6YTSpo2duebmZrvcirYZYxfcDA62dYyxrR9397r9edQRTSJKKVWWh4ddg6xIXFz19svKss/799tWTU6OfRw9CocO2Ud6um0R7dply0+csGWVEbGJJCLCLltTMgn5+9sWT3q6TZC9etlk5OlpW0N+frX7GVSTJhGllKorRWuSlbcsTUWMsYnmxAnbrXbypE1A6em2ZePubl8fPWqTU0aGnXiwaJFtxWRn29aPt3f5d88MCLCJJiTEzo7z9q6780WTiFJKuZaIbUn4+trxFLAXaVbFmNPTmE+dsi2P1FS7Xlpenk0oO3faRFSUnOph2rMmEaWUaopKJgQvL/vcpo299XIDcsntcZVSSjUPmkSUUkrVmiYRpZRStaZJRCmlVK1pElFKKVVrmkSUUkrVmiYRpZRStaZJRCmlVK21uDsbikgqsLsWu7YGjtRxOI2dnnPLoOfcMpzNOR8BMMaMKbuhxSWR2hKRpPJuDdmc6Tm3DHrOLUN9nbN2ZymllKo1TSJKKaVqTZNI9b3p6gBcQM+5ZdBzbhnq5Zx1TEQppVStaUtEKaVUrWkSUUopVWuaRKpBRMaIyBYR2S4iD7s6nroiIu+KyGERWV+iLFRE5onINuc5xCkXEXnV+RmsFZG+rou89kSkvYjMF5GNIrJBRO5xypvteYuIj4j8KiJrnHP+i1PeSUSWOef2sYh4OeXezvvtzvYYV8ZfWyLiLiKrROQb532zPl8AEUkWkXUislpEkpyyev23rUmkCiLiDvwTGAvEAZNFJM61UdWZfwNlLx56GPjBGNMV+MF5D/b8uzqP24DXGijGupYP/NEYEwcMAu50fp/N+bxzgVHGmHigDzBGRAYBzwMvGWPOAdKBm536NwPpTvlLTr2m6B5gU4n3zf18i4w0xvQpcU1I/f7bNsboo5IHMBiYU+L9I8AjKTIMmQAABL1JREFUro6rDs8vBlhf4v0WIMp5HQVscV6/AUwur15TfgBfARe1lPMG/ICVwEDsVcgeTnnxv3NgDjDYee3h1BNXx17D84x2vjBHAd8A0pzPt8R5JwOty5TV679tbYlUrR2wt8T7FKesuYowxhxwXh8EIpzXze7n4HRbJADLaObn7XTtrAYOA/OAHcAxY0y+U6XkeRWfs7M9Awhr2IjP2svAg0Ch8z6M5n2+RQwwV0RWiMhtTlm9/tv2qG2kqvkzxhgRaZZzwEUkAPgM+IMxJlNEirc1x/M2/7+9+wmNq4riOP79IbUGldb/CKmERqEq1mKLinZRNwpV6sKWCkGLdKOLLgRBRMhaFATrH0Rx4aIoCi0UF2JNRAuKlaBpIxVtazehmraQiiClhOPingmPkBB8melzpr8PPObNecPLO+ElZ+69M/dGzADrJK0E9gFrGr6kjpH0GDAVEWOSNjV9PRfZxoiYlHQjcEDSL9WDnbi33RJZ3CSwqvK8P2O96k9JNwPk41TGe+b3IGkZpYDsiYi9Ge75vAEiYhr4itKds1JS641kNa/ZnPP4CuDsRb7UpXgQ2CLpJPAxpUvrDXo331kRMZmPU5Q3C/fS4XvbRWRxPwC35Sc7LgeeBPY3fE2dtB/Ykfs7KGMGrfjT+YmO+4FzlSZy11BpcnwAHI2I1yuHejZvSTdkCwRJfZQxoKOUYrI1XzY359bvYiswGtlp3g0i4qWI6I+IAcrf62hEDNGj+bZIulLS1a194GFggk7f200PBHXDBmwGfqX0I7/c9PW0Ma+PgFPABUp/6E5KX/AI8BvwJXBtvlaUT6kdB44AG5q+/po5b6T0Gx8Gfsptcy/nDawFfsycJ4DhjK8GDgHHgE+B5Rm/Ip8fy+Orm85hCblvAj67FPLN/MZz+7n1v6rT97anPTEzs9rcnWVmZrW5iJiZWW0uImZmVpuLiJmZ1eYiYmZmtbmImNUkaSZnS21tbZvhWdKAKrMrm/1fedoTs/r+iYh1TV+EWZPcEjFrs1zT4dVc1+GQpFszPiBpNNduGJF0S8ZvkrQv1/sYl/RAnuoySe/nGiBf5LfNkTQo6fOcZO+gpDUZ3yZpIs/xTSPJ2yXHRcSsvr453VnbK8fORcRdwFuUGWUB3gQ+jIi1wB5gd8Z3A19HWe/jHsq3jaGs8/B2RNwJTANPZPw9YFdErAdeAN7J+DDwSJ5nS7uTNZuPv7FuVpOkvyPiqnniJymLQJ3IyR7/iIjrJJ2hrNdwIeOnIuJ6SaeB/og4XznHAHAgykJCSHoRWEYpSKcpaz+0LI+I2yW9CwwCnwB7I6IrJxG07uIxEbPOiAX2/4vzlf0ZoI/SezA931hMRDwr6T7gUWBM0noXEus0d2eZdcb2yuN3uf8tZVZZgCHgYO6PAM/B7OJRKxY6aUT8BfwuaVu+XpLuzv3BiPg+IoYprZVVC53HrF1cRMzqmzsm8krl2DWSDlPW+X4+Y7uAZzL+VB4jHx+SdAQYA+5Y5OcOATsltWZrfTzjr+Vg/gSlYI0vNUGzxXhMxKzNckxkQ0ScafpazDrNLREzM6vNLREzM6vNLREzM6vNRcTMzGpzETEzs9pcRMzMrDYXETMzq+1fmssHxWQX9GIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJzju7v2mzCw",
        "outputId": "a4fcf059-890a-4d99-9636-492220f511ff"
      },
      "source": [
        "history_dict = Model_Results4.history\n",
        "val_acc_values = history_dict['val_mae']\n",
        "maxi = np.max(val_acc_values)\n",
        "mini = np.min(val_acc_values)\n",
        "avrg = (maxi+mini)/2\n",
        "print(f\"FOR MODEL1 Average Validation Absolute Error = {avrg}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOR MODEL1 Average Validation Absolute Error = 6792.150146484375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8BL5nKnnZbs"
      },
      "source": [
        "# **MAE with K fold and with relu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2wVTPJFnNjD",
        "outputId": "a391ad5d-d14b-4cf1-9de4-29da900c94fa"
      },
      "source": [
        "k =  4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores_relu = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  partial_train_targets = np.concatenate([train_labels[:i * num_val_samples],train_labels[(i + 1) * num_val_samples:]],axis=0)\n",
        "  model = Train_Me_with('relu')\n",
        "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores_relu.append(val_mae)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n",
            "WARNING:tensorflow:5 out of the last 2007 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc13bc3c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJhBSUxdoNVZ"
      },
      "source": [
        "# **MAE with K fold and with gelu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3qlJfxinD9A",
        "outputId": "b448d264-52ac-4e61-8e7f-1d78a3ca7b57"
      },
      "source": [
        "k =  4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores_gelu = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  partial_train_targets = np.concatenate([train_labels[:i * num_val_samples],train_labels[(i + 1) * num_val_samples:]],axis=0)\n",
        "  model = Train_Me_with('gelu')\n",
        "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores_gelu.append(val_mae)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "WARNING:tensorflow:6 out of the last 2009 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc132189e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 1\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc117b2cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 2\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc84bdbe60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 3\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc116633b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5i7tx8moUEE"
      },
      "source": [
        "# **MAE with K fold and with selu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EGHxt2eoI1W",
        "outputId": "f5645f1b-7b47-40c1-e4b8-d441ec6b363b"
      },
      "source": [
        "k =  4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores_selu = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  partial_train_targets = np.concatenate([train_labels[:i * num_val_samples],train_labels[(i + 1) * num_val_samples:]],axis=0)\n",
        "  model = Train_Me_with('selu')\n",
        "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores_selu.append(val_mae)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc17ce13b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 1\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc93f93560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 2\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc1328e440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 3\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc180ff710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xug1wYVDoLNd"
      },
      "source": [
        "# **MAE with K fold and with tanh**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju2_Av5soKF2",
        "outputId": "3328f752-f319-417b-c6c9-d1b881889e44"
      },
      "source": [
        "k =  4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores_tanh = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  partial_train_targets = np.concatenate([train_labels[:i * num_val_samples],train_labels[(i + 1) * num_val_samples:]],axis=0)\n",
        "  model = Train_Me_with('tanh')\n",
        "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores_tanh.append(val_mae)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc254cc560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 1\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc254cccb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 2\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc0eb1da70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 3\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc181d8440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_iPCkrkqYdu"
      },
      "source": [
        "# **Averages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC80FyDAo2KO",
        "outputId": "018c521b-b123-44c4-d151-6e65dadcb952"
      },
      "source": [
        "print(f\"Using activation function relu {np.average(all_scores_relu)}\")\n",
        "print(f\"Using activation function tanh {np.average(all_scores_tanh)}\")\n",
        "print(f\"Using activation function gelu {np.average(all_scores_gelu)}\")\n",
        "print(f\"Using activation function selu {np.average(all_scores_selu)}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using activation function relu 2697.8213500976562\n",
            "Using activation function tanh 14131.515625\n",
            "Using activation function gelu 2673.734649658203\n",
            "Using activation function selu 2751.7901611328125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoAUInuCuyJw"
      },
      "source": [
        "# **So Outcome of after all struggle**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MQGTMT8vQue"
      },
      "source": [
        "Relu functions give better results amoung all other //\\\\\\ Now paying with epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRUW0XEWulvA",
        "outputId": "b6ba0fbe-affd-4308-d01f-0a3ac9c89945"
      },
      "source": [
        "k =  4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 200\n",
        "all_scores_K_relu = []\n",
        "model = Train_Me_with('relu')\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  partial_train_targets = np.concatenate([train_labels[:i * num_val_samples],train_labels[(i + 1) * num_val_samples:]],axis=0)\n",
        "  Model_Results = model.fit(partial_train_data, partial_train_targets,epochs = num_epochs, batch_size=1,verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores_K_relu.append(val_mae)\n",
        "  history_dict = Model_Results.history\n",
        "  mae_values = history_dict['mae']\n",
        "print(f\"On Eveluation Average using RELU and having {num_epochs} epoches is {np.average(all_scores_K_relu)}\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "WARNING:tensorflow:6 out of the last 17 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc17f5c560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n",
            "On Eveluation Average using RELU and having 200 epoches is 1329.468505859375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIjfr6kehmwU"
      },
      "source": [
        "# **Prediction obtained**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcRk_ZkZxqNV"
      },
      "source": [
        "Predicted_val = model.predict(test_data)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P78vfdpV_V8M"
      },
      "source": [
        "y_pred = Predicted_val.flatten()\n",
        "y_true = test_labels\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "yUVNtVz68bam",
        "outputId": "95b663a2-032b-4c68-bb3b-4ca8aae83f80"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "coef = np.polyfit(y_true,y_pred,1)\n",
        "poly1d_fn = np.poly1d(coef) \n",
        "# poly1d_fn is now a function which takes in x and returns an estimate for y\n",
        "plt.figure()\n",
        "plt.plot(y_true,y_pred, 'yo', y_true, poly1d_fn(y_true), '--k')\n",
        "plt.title('MAE with K fold and with relu')\n",
        "plt.xlabel('Thousand Dollar True' )\n",
        "plt.ylabel('Thousand Dollar Predictions' )\n",
        "plt.xlim(500, 30000)\n",
        "plt.ylim(500, 30000)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500.0, 30000.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaOcloKN_9o5",
        "outputId": "555c47e7-3dbe-41e0-fd09-f07d1d051319"
      },
      "source": [
        "print(f\"On Eveluation Average using RELU is {np.average(all_scores_K_relu)}\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Eveluation Average using RELU is 1329.468505859375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azc_S84EStBZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}