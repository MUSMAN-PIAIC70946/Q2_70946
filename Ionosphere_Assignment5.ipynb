{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ionosphere_Assignment5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ahnoT3rQZ67"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cvZ6I8-0B-F"
      },
      "source": [
        "# **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VymCiVaQdBm"
      },
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/ramsha275/ML_Datasets/main/ionosphere_data.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "EUJatlivQj1r",
        "outputId": "e60eba82-963f-476e-bdc5-17829e56594e"
      },
      "source": [
        "data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99539</td>\n",
              "      <td>-0.05889</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>0.02306</td>\n",
              "      <td>0.83398</td>\n",
              "      <td>-0.37708</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.03760</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>-0.17755</td>\n",
              "      <td>0.59755</td>\n",
              "      <td>-0.44945</td>\n",
              "      <td>0.60536</td>\n",
              "      <td>-0.38223</td>\n",
              "      <td>0.84356</td>\n",
              "      <td>-0.38542</td>\n",
              "      <td>0.58212</td>\n",
              "      <td>-0.32192</td>\n",
              "      <td>0.56971</td>\n",
              "      <td>-0.29674</td>\n",
              "      <td>0.36946</td>\n",
              "      <td>-0.47357</td>\n",
              "      <td>0.56811</td>\n",
              "      <td>-0.51171</td>\n",
              "      <td>0.41078</td>\n",
              "      <td>-0.46168</td>\n",
              "      <td>0.21266</td>\n",
              "      <td>-0.34090</td>\n",
              "      <td>0.42267</td>\n",
              "      <td>-0.54487</td>\n",
              "      <td>0.18641</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.18829</td>\n",
              "      <td>0.93035</td>\n",
              "      <td>-0.36156</td>\n",
              "      <td>-0.10868</td>\n",
              "      <td>-0.93597</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.04549</td>\n",
              "      <td>0.50874</td>\n",
              "      <td>-0.67743</td>\n",
              "      <td>0.34432</td>\n",
              "      <td>-0.69707</td>\n",
              "      <td>-0.51685</td>\n",
              "      <td>-0.97515</td>\n",
              "      <td>0.05499</td>\n",
              "      <td>-0.62237</td>\n",
              "      <td>0.33109</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.13151</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>-0.18056</td>\n",
              "      <td>-0.35734</td>\n",
              "      <td>-0.20332</td>\n",
              "      <td>-0.26569</td>\n",
              "      <td>-0.20468</td>\n",
              "      <td>-0.18401</td>\n",
              "      <td>-0.19040</td>\n",
              "      <td>-0.11593</td>\n",
              "      <td>-0.16626</td>\n",
              "      <td>-0.06288</td>\n",
              "      <td>-0.13738</td>\n",
              "      <td>-0.02447</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.03365</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00485</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.88965</td>\n",
              "      <td>0.01198</td>\n",
              "      <td>0.73082</td>\n",
              "      <td>0.05346</td>\n",
              "      <td>0.85443</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54591</td>\n",
              "      <td>0.00299</td>\n",
              "      <td>0.83775</td>\n",
              "      <td>-0.13644</td>\n",
              "      <td>0.75535</td>\n",
              "      <td>-0.08540</td>\n",
              "      <td>0.70887</td>\n",
              "      <td>-0.27502</td>\n",
              "      <td>0.43385</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.57528</td>\n",
              "      <td>-0.40220</td>\n",
              "      <td>0.58984</td>\n",
              "      <td>-0.22145</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>-0.17365</td>\n",
              "      <td>0.60436</td>\n",
              "      <td>-0.24180</td>\n",
              "      <td>0.56045</td>\n",
              "      <td>-0.38238</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.45161</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.71216</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.14516</td>\n",
              "      <td>0.54094</td>\n",
              "      <td>-0.39330</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.54467</td>\n",
              "      <td>-0.69975</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.90695</td>\n",
              "      <td>0.51613</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.20099</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.32382</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02401</td>\n",
              "      <td>0.94140</td>\n",
              "      <td>0.06531</td>\n",
              "      <td>0.92106</td>\n",
              "      <td>-0.23255</td>\n",
              "      <td>0.77152</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>0.52798</td>\n",
              "      <td>-0.20275</td>\n",
              "      <td>0.56409</td>\n",
              "      <td>-0.00712</td>\n",
              "      <td>0.34395</td>\n",
              "      <td>-0.27457</td>\n",
              "      <td>0.52940</td>\n",
              "      <td>-0.21780</td>\n",
              "      <td>0.45107</td>\n",
              "      <td>-0.17813</td>\n",
              "      <td>0.05982</td>\n",
              "      <td>-0.35575</td>\n",
              "      <td>0.02309</td>\n",
              "      <td>-0.52879</td>\n",
              "      <td>0.03286</td>\n",
              "      <td>-0.65158</td>\n",
              "      <td>0.13290</td>\n",
              "      <td>-0.53206</td>\n",
              "      <td>0.02431</td>\n",
              "      <td>-0.62197</td>\n",
              "      <td>-0.05707</td>\n",
              "      <td>-0.59573</td>\n",
              "      <td>-0.04608</td>\n",
              "      <td>-0.65697</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.83508</td>\n",
              "      <td>0.08298</td>\n",
              "      <td>0.73739</td>\n",
              "      <td>-0.14706</td>\n",
              "      <td>0.84349</td>\n",
              "      <td>-0.05567</td>\n",
              "      <td>0.90441</td>\n",
              "      <td>-0.04622</td>\n",
              "      <td>0.89391</td>\n",
              "      <td>0.13130</td>\n",
              "      <td>0.81197</td>\n",
              "      <td>0.06723</td>\n",
              "      <td>0.79307</td>\n",
              "      <td>-0.08929</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02101</td>\n",
              "      <td>0.96639</td>\n",
              "      <td>0.06618</td>\n",
              "      <td>0.87605</td>\n",
              "      <td>0.01155</td>\n",
              "      <td>0.77521</td>\n",
              "      <td>0.06618</td>\n",
              "      <td>0.95378</td>\n",
              "      <td>-0.04202</td>\n",
              "      <td>0.83479</td>\n",
              "      <td>0.00123</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.12815</td>\n",
              "      <td>0.86660</td>\n",
              "      <td>-0.10714</td>\n",
              "      <td>0.90546</td>\n",
              "      <td>-0.04307</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.95113</td>\n",
              "      <td>0.00419</td>\n",
              "      <td>0.95183</td>\n",
              "      <td>-0.02723</td>\n",
              "      <td>0.93438</td>\n",
              "      <td>-0.01920</td>\n",
              "      <td>0.94590</td>\n",
              "      <td>0.01606</td>\n",
              "      <td>0.96510</td>\n",
              "      <td>0.03281</td>\n",
              "      <td>0.94171</td>\n",
              "      <td>0.07330</td>\n",
              "      <td>0.94625</td>\n",
              "      <td>-0.01326</td>\n",
              "      <td>0.97173</td>\n",
              "      <td>0.00140</td>\n",
              "      <td>0.94834</td>\n",
              "      <td>0.06038</td>\n",
              "      <td>0.92670</td>\n",
              "      <td>0.08412</td>\n",
              "      <td>0.93124</td>\n",
              "      <td>0.10087</td>\n",
              "      <td>0.94520</td>\n",
              "      <td>0.01361</td>\n",
              "      <td>0.93522</td>\n",
              "      <td>0.04925</td>\n",
              "      <td>0.93159</td>\n",
              "      <td>0.08168</td>\n",
              "      <td>0.94066</td>\n",
              "      <td>-0.00035</td>\n",
              "      <td>0.91483</td>\n",
              "      <td>0.04712</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.94701</td>\n",
              "      <td>-0.00034</td>\n",
              "      <td>0.93207</td>\n",
              "      <td>-0.03227</td>\n",
              "      <td>0.95177</td>\n",
              "      <td>-0.03431</td>\n",
              "      <td>0.95584</td>\n",
              "      <td>0.02446</td>\n",
              "      <td>0.94124</td>\n",
              "      <td>0.01766</td>\n",
              "      <td>0.92595</td>\n",
              "      <td>0.04688</td>\n",
              "      <td>0.93954</td>\n",
              "      <td>-0.01461</td>\n",
              "      <td>0.94837</td>\n",
              "      <td>0.02004</td>\n",
              "      <td>0.93784</td>\n",
              "      <td>0.01393</td>\n",
              "      <td>0.91406</td>\n",
              "      <td>0.07677</td>\n",
              "      <td>0.89470</td>\n",
              "      <td>0.06148</td>\n",
              "      <td>0.93988</td>\n",
              "      <td>0.03193</td>\n",
              "      <td>0.92489</td>\n",
              "      <td>0.02542</td>\n",
              "      <td>0.92120</td>\n",
              "      <td>0.02242</td>\n",
              "      <td>0.92459</td>\n",
              "      <td>0.00442</td>\n",
              "      <td>0.92697</td>\n",
              "      <td>-0.00577</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.90608</td>\n",
              "      <td>-0.01657</td>\n",
              "      <td>0.98122</td>\n",
              "      <td>-0.01989</td>\n",
              "      <td>0.95691</td>\n",
              "      <td>-0.03646</td>\n",
              "      <td>0.85746</td>\n",
              "      <td>0.00110</td>\n",
              "      <td>0.89724</td>\n",
              "      <td>-0.03315</td>\n",
              "      <td>0.89061</td>\n",
              "      <td>-0.01436</td>\n",
              "      <td>0.90608</td>\n",
              "      <td>-0.04530</td>\n",
              "      <td>0.91381</td>\n",
              "      <td>-0.00884</td>\n",
              "      <td>0.80773</td>\n",
              "      <td>-0.12928</td>\n",
              "      <td>0.88729</td>\n",
              "      <td>0.01215</td>\n",
              "      <td>0.92155</td>\n",
              "      <td>-0.02320</td>\n",
              "      <td>0.91050</td>\n",
              "      <td>-0.02099</td>\n",
              "      <td>0.89147</td>\n",
              "      <td>-0.07760</td>\n",
              "      <td>0.82983</td>\n",
              "      <td>-0.17238</td>\n",
              "      <td>0.96022</td>\n",
              "      <td>-0.03757</td>\n",
              "      <td>0.87403</td>\n",
              "      <td>-0.16243</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.84710</td>\n",
              "      <td>0.13533</td>\n",
              "      <td>0.73638</td>\n",
              "      <td>-0.06151</td>\n",
              "      <td>0.87873</td>\n",
              "      <td>0.08260</td>\n",
              "      <td>0.88928</td>\n",
              "      <td>-0.09139</td>\n",
              "      <td>0.78735</td>\n",
              "      <td>0.06678</td>\n",
              "      <td>0.80668</td>\n",
              "      <td>-0.00351</td>\n",
              "      <td>0.79262</td>\n",
              "      <td>-0.01054</td>\n",
              "      <td>0.85764</td>\n",
              "      <td>-0.04569</td>\n",
              "      <td>0.87170</td>\n",
              "      <td>-0.03515</td>\n",
              "      <td>0.81722</td>\n",
              "      <td>-0.09490</td>\n",
              "      <td>0.71002</td>\n",
              "      <td>0.04394</td>\n",
              "      <td>0.86467</td>\n",
              "      <td>-0.15114</td>\n",
              "      <td>0.81147</td>\n",
              "      <td>-0.04822</td>\n",
              "      <td>0.78207</td>\n",
              "      <td>-0.00703</td>\n",
              "      <td>0.75747</td>\n",
              "      <td>-0.06678</td>\n",
              "      <td>0.85764</td>\n",
              "      <td>-0.06151</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>351 rows Ã— 35 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature1  feature2  feature3  ...  feature33  feature34  label\n",
              "0           1         0   0.99539  ...    0.18641   -0.45300      g\n",
              "1           1         0   1.00000  ...   -0.13738   -0.02447      b\n",
              "2           1         0   1.00000  ...    0.56045   -0.38238      g\n",
              "3           1         0   1.00000  ...   -0.32382    1.00000      b\n",
              "4           1         0   1.00000  ...   -0.04608   -0.65697      g\n",
              "..        ...       ...       ...  ...        ...        ...    ...\n",
              "346         1         0   0.83508  ...    0.90546   -0.04307      g\n",
              "347         1         0   0.95113  ...    0.91483    0.04712      g\n",
              "348         1         0   0.94701  ...    0.92697   -0.00577      g\n",
              "349         1         0   0.90608  ...    0.87403   -0.16243      g\n",
              "350         1         0   0.84710  ...    0.85764   -0.06151      g\n",
              "\n",
              "[351 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DJpmlnY0GnV"
      },
      "source": [
        "# **Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPdC24-AQk_z",
        "outputId": "01677320-2d74-4eae-979e-0ca336e75311"
      },
      "source": [
        "data.isnull().any()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature1     False\n",
              "feature2     False\n",
              "feature3     False\n",
              "feature4     False\n",
              "feature5     False\n",
              "feature6     False\n",
              "feature7     False\n",
              "feature8     False\n",
              "feature9     False\n",
              "feature10    False\n",
              "feature11    False\n",
              "feature12    False\n",
              "feature13    False\n",
              "feature14    False\n",
              "feature15    False\n",
              "feature16    False\n",
              "feature17    False\n",
              "feature18    False\n",
              "feature19    False\n",
              "feature20    False\n",
              "feature21    False\n",
              "feature22    False\n",
              "feature23    False\n",
              "feature24    False\n",
              "feature25    False\n",
              "feature26    False\n",
              "feature27    False\n",
              "feature28    False\n",
              "feature29    False\n",
              "feature30    False\n",
              "feature31    False\n",
              "feature32    False\n",
              "feature33    False\n",
              "feature34    False\n",
              "label        False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "S2soWTpYQua-",
        "outputId": "a9e2a01f-bb7a-4498-93e9-c9fb48c79d19"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.0</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.891738</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.641342</td>\n",
              "      <td>0.044372</td>\n",
              "      <td>0.601068</td>\n",
              "      <td>0.115889</td>\n",
              "      <td>0.550095</td>\n",
              "      <td>0.119360</td>\n",
              "      <td>0.511848</td>\n",
              "      <td>0.181345</td>\n",
              "      <td>0.476183</td>\n",
              "      <td>0.155040</td>\n",
              "      <td>0.400801</td>\n",
              "      <td>0.093414</td>\n",
              "      <td>0.344159</td>\n",
              "      <td>0.071132</td>\n",
              "      <td>0.381949</td>\n",
              "      <td>-0.003617</td>\n",
              "      <td>0.359390</td>\n",
              "      <td>-0.024025</td>\n",
              "      <td>0.336695</td>\n",
              "      <td>0.008296</td>\n",
              "      <td>0.362475</td>\n",
              "      <td>-0.057406</td>\n",
              "      <td>0.396135</td>\n",
              "      <td>-0.071187</td>\n",
              "      <td>0.541641</td>\n",
              "      <td>-0.069538</td>\n",
              "      <td>0.378445</td>\n",
              "      <td>-0.027907</td>\n",
              "      <td>0.352514</td>\n",
              "      <td>-0.003794</td>\n",
              "      <td>0.349364</td>\n",
              "      <td>0.014480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.311155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.497708</td>\n",
              "      <td>0.441435</td>\n",
              "      <td>0.519862</td>\n",
              "      <td>0.460810</td>\n",
              "      <td>0.492654</td>\n",
              "      <td>0.520750</td>\n",
              "      <td>0.507066</td>\n",
              "      <td>0.483851</td>\n",
              "      <td>0.563496</td>\n",
              "      <td>0.494817</td>\n",
              "      <td>0.622186</td>\n",
              "      <td>0.494873</td>\n",
              "      <td>0.652828</td>\n",
              "      <td>0.458371</td>\n",
              "      <td>0.618020</td>\n",
              "      <td>0.496762</td>\n",
              "      <td>0.626267</td>\n",
              "      <td>0.519076</td>\n",
              "      <td>0.609828</td>\n",
              "      <td>0.518166</td>\n",
              "      <td>0.603767</td>\n",
              "      <td>0.527456</td>\n",
              "      <td>0.578451</td>\n",
              "      <td>0.508495</td>\n",
              "      <td>0.516205</td>\n",
              "      <td>0.550025</td>\n",
              "      <td>0.575886</td>\n",
              "      <td>0.507974</td>\n",
              "      <td>0.571483</td>\n",
              "      <td>0.513574</td>\n",
              "      <td>0.522663</td>\n",
              "      <td>0.468337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.472135</td>\n",
              "      <td>-0.064735</td>\n",
              "      <td>0.412660</td>\n",
              "      <td>-0.024795</td>\n",
              "      <td>0.211310</td>\n",
              "      <td>-0.054840</td>\n",
              "      <td>0.087110</td>\n",
              "      <td>-0.048075</td>\n",
              "      <td>0.021120</td>\n",
              "      <td>-0.065265</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.073725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.081705</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.225690</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.234670</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.243870</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.366885</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.332390</td>\n",
              "      <td>0.286435</td>\n",
              "      <td>-0.443165</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.236885</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.242595</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.165350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.871110</td>\n",
              "      <td>0.016310</td>\n",
              "      <td>0.809200</td>\n",
              "      <td>0.022800</td>\n",
              "      <td>0.728730</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.684210</td>\n",
              "      <td>0.018290</td>\n",
              "      <td>0.667980</td>\n",
              "      <td>0.028250</td>\n",
              "      <td>0.644070</td>\n",
              "      <td>0.030270</td>\n",
              "      <td>0.601940</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.590910</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.576190</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.499090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.531760</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.553890</td>\n",
              "      <td>-0.015050</td>\n",
              "      <td>0.708240</td>\n",
              "      <td>-0.017690</td>\n",
              "      <td>0.496640</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.442770</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.409560</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.194185</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.334655</td>\n",
              "      <td>0.969240</td>\n",
              "      <td>0.445675</td>\n",
              "      <td>0.953240</td>\n",
              "      <td>0.534195</td>\n",
              "      <td>0.957895</td>\n",
              "      <td>0.482375</td>\n",
              "      <td>0.955505</td>\n",
              "      <td>0.374860</td>\n",
              "      <td>0.919330</td>\n",
              "      <td>0.308975</td>\n",
              "      <td>0.935705</td>\n",
              "      <td>0.195285</td>\n",
              "      <td>0.899265</td>\n",
              "      <td>0.134370</td>\n",
              "      <td>0.894865</td>\n",
              "      <td>0.188760</td>\n",
              "      <td>0.911235</td>\n",
              "      <td>0.164630</td>\n",
              "      <td>0.905240</td>\n",
              "      <td>0.156765</td>\n",
              "      <td>0.999945</td>\n",
              "      <td>0.153535</td>\n",
              "      <td>0.883465</td>\n",
              "      <td>0.154075</td>\n",
              "      <td>0.857620</td>\n",
              "      <td>0.200120</td>\n",
              "      <td>0.813765</td>\n",
              "      <td>0.171660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         feature1  feature2    feature3  ...   feature32   feature33   feature34\n",
              "count  351.000000     351.0  351.000000  ...  351.000000  351.000000  351.000000\n",
              "mean     0.891738       0.0    0.641342  ...   -0.003794    0.349364    0.014480\n",
              "std      0.311155       0.0    0.497708  ...    0.513574    0.522663    0.468337\n",
              "min      0.000000       0.0   -1.000000  ...   -1.000000   -1.000000   -1.000000\n",
              "25%      1.000000       0.0    0.472135  ...   -0.242595    0.000000   -0.165350\n",
              "50%      1.000000       0.0    0.871110  ...    0.000000    0.409560    0.000000\n",
              "75%      1.000000       0.0    1.000000  ...    0.200120    0.813765    0.171660\n",
              "max      1.000000       0.0    1.000000  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[8 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2e4A-64ee9M",
        "outputId": "5ee4747c-8110-4455-8149-cfcebb252fff"
      },
      "source": [
        "np.unique(data.feature2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQl8HTdLi7Hg"
      },
      "source": [
        "data.sample(frac=0.4)\n",
        "data.drop(columns=[\"feature2\"] ,inplace=True,axis=0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x7r6VCW0Qjh"
      },
      "source": [
        "# **Split into 60 and 40 ratio.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez50Wv9UkIyi"
      },
      "source": [
        "labels = data.pop(\"label\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u1LWPpk2CdY"
      },
      "source": [
        "data -= data.mean()\n",
        "data /= data.std()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWw7vo1wmsId"
      },
      "source": [
        "labels = pd.Series([0 if lbl == 'g' else 1 for lbl in labels]) "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HncRgzlqk0Rd"
      },
      "source": [
        "data_len = len(data)\n",
        "train_data = data.iloc[:data_len*60//100]\n",
        "test_data = data.iloc[data_len*60//100:]\n",
        "labels_len = len(labels)\n",
        "train_labels = labels.iloc[:labels_len*60//100]\n",
        "test_labels = labels.iloc[labels_len*60//100:]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqGCFS1h0Zru"
      },
      "source": [
        "# **Model : 1 hidden layers including 16 unit.  Train the Model with Epochs (100).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC7FHwZnlB3_",
        "outputId": "e7e4fa58-5c18-4c21-c973-5f4e1d0e0f10"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(16,activation=\"relu\",input_shape=(len(train_data.columns),)))\n",
        "# network.add(layers.Dense(13,activation=\"relu\"))\n",
        "network.add(layers.Dropout(0.5))\n",
        "\n",
        "network.add(layers.Dense(1,activation=\"sigmoid\"))\n",
        "network.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "with tf.device('/device:GPU:1'):\n",
        "  %time MODEL = network.fit(train_data,train_labels,epochs=100,batch_size=128)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 3s 7ms/step - loss: 0.9535 - acc: 0.4338\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8743 - acc: 0.5090\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8271 - acc: 0.5855\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8792 - acc: 0.5300\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7850 - acc: 0.5442\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8208 - acc: 0.5090\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8076 - acc: 0.5858\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7358 - acc: 0.5558\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7352 - acc: 0.6372\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7848 - acc: 0.5638\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7187 - acc: 0.6693\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6939 - acc: 0.6803\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6998 - acc: 0.6525\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6922 - acc: 0.6652\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6607 - acc: 0.6349\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6692 - acc: 0.6479\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7095 - acc: 0.6216\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6588 - acc: 0.6901\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6958 - acc: 0.6490\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6786 - acc: 0.6759\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6764 - acc: 0.6147\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6657 - acc: 0.6643\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6298 - acc: 0.6947\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6416 - acc: 0.6516\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6402 - acc: 0.6606\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6616 - acc: 0.6958\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5983 - acc: 0.7054\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6267 - acc: 0.6721\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5694 - acc: 0.7496\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6092 - acc: 0.6921\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5714 - acc: 0.7227\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5698 - acc: 0.7184\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5367 - acc: 0.7553\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5573 - acc: 0.7048\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5550 - acc: 0.7290\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5654 - acc: 0.7557\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5410 - acc: 0.7663\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5646 - acc: 0.7626\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5227 - acc: 0.7314\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5532 - acc: 0.7421\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5172 - acc: 0.7467\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5280 - acc: 0.7207\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4893 - acc: 0.8120\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5264 - acc: 0.7557\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5443 - acc: 0.7490\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4941 - acc: 0.7695\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5199 - acc: 0.7799\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5083 - acc: 0.7727\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4980 - acc: 0.7799\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4814 - acc: 0.7458\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4642 - acc: 0.7811\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4796 - acc: 0.7380\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4762 - acc: 0.7721\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4718 - acc: 0.7990\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5033 - acc: 0.7669\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4628 - acc: 0.7738\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4555 - acc: 0.8137\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4483 - acc: 0.8004\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4037 - acc: 0.8247\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4542 - acc: 0.8131\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4553 - acc: 0.7984\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4182 - acc: 0.8152\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4410 - acc: 0.8131\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4399 - acc: 0.8042\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4320 - acc: 0.8284\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4274 - acc: 0.8362\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4174 - acc: 0.8001\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4657 - acc: 0.8152\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3957 - acc: 0.8484\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4381 - acc: 0.7958\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3990 - acc: 0.8620\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3814 - acc: 0.8120\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4482 - acc: 0.7885\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3849 - acc: 0.8290\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4064 - acc: 0.8226\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3808 - acc: 0.8694\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4141 - acc: 0.7796\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4104 - acc: 0.8305\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4159 - acc: 0.8134\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4027 - acc: 0.8189\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4085 - acc: 0.8157\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4250 - acc: 0.8160\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3813 - acc: 0.8437\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3470 - acc: 0.8651\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3600 - acc: 0.8406\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3665 - acc: 0.8305\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3923 - acc: 0.8521\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3883 - acc: 0.8469\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3456 - acc: 0.8611\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3794 - acc: 0.8273\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3686 - acc: 0.8527\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4031 - acc: 0.8273\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4126 - acc: 0.8296\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3630 - acc: 0.8322\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3900 - acc: 0.8327\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3605 - acc: 0.8484\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3975 - acc: 0.8322\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3279 - acc: 0.8521\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3648 - acc: 0.8747\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3634 - acc: 0.8359\n",
            "CPU times: user 2.18 s, sys: 393 ms, total: 2.57 s\n",
            "Wall time: 4.96 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMPZ-IFe0muX"
      },
      "source": [
        "# **Evaluation Step**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80xJvwUapWBy",
        "outputId": "7e9c92a3-5afb-4f23-e732-330242ec79be"
      },
      "source": [
        "loss , acc = network.evaluate(test_data,test_labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3645 - acc: 0.8936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmgzytJe0vhw"
      },
      "source": [
        "# **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dTAo1hnp6QO",
        "outputId": "3a748089-167b-4336-85a1-22634f145d80"
      },
      "source": [
        "prediction_test_data = test_data[test_labels == 1]\n",
        "predictions = network.predict(prediction_test_data)\n",
        "len(np.round(predictions))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QVfBis200MY"
      },
      "source": [
        "# **Model : 2 hidden layers including 33 and 13 unit.  Train the Model with Epochs (80).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrrxAqmVslgZ",
        "outputId": "335e6ffd-2125-48a8-883d-d83e88980900"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "network1 = models.Sequential()\n",
        "network1.add(layers.Dense(33,activation=\"relu\",input_shape=(len(train_data.columns),)))\n",
        "network1.add(layers.Dense(13,activation=\"relu\"))\n",
        "network1.add(layers.Dense(1,activation=\"sigmoid\"))\n",
        "network1.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "with tf.device('/device:GPU:1'):\n",
        "  %time MODEL1 = network1.fit(train_data,train_labels, validation_split=0.,epochs=80,batch_size=64)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6876 - acc: 0.4828\n",
            "Epoch 2/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6594 - acc: 0.5199\n",
            "Epoch 3/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6229 - acc: 0.6193\n",
            "Epoch 4/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6062 - acc: 0.7438\n",
            "Epoch 5/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5888 - acc: 0.8138\n",
            "Epoch 6/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5718 - acc: 0.8288\n",
            "Epoch 7/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5478 - acc: 0.8623\n",
            "Epoch 8/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5330 - acc: 0.8529\n",
            "Epoch 9/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5170 - acc: 0.8578\n",
            "Epoch 10/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5015 - acc: 0.8541\n",
            "Epoch 11/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4784 - acc: 0.8691\n",
            "Epoch 12/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4626 - acc: 0.8906\n",
            "Epoch 13/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4569 - acc: 0.8899\n",
            "Epoch 14/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4375 - acc: 0.8930\n",
            "Epoch 15/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4095 - acc: 0.8937\n",
            "Epoch 16/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4112 - acc: 0.8959\n",
            "Epoch 17/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4010 - acc: 0.8878\n",
            "Epoch 18/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3878 - acc: 0.8828\n",
            "Epoch 19/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3695 - acc: 0.8954\n",
            "Epoch 20/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3620 - acc: 0.8842\n",
            "Epoch 21/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3532 - acc: 0.8706\n",
            "Epoch 22/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3361 - acc: 0.8821\n",
            "Epoch 23/80\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3207 - acc: 0.8824\n",
            "Epoch 24/80\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3178 - acc: 0.8850\n",
            "Epoch 25/80\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3104 - acc: 0.8958\n",
            "Epoch 26/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3046 - acc: 0.8895\n",
            "Epoch 27/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3070 - acc: 0.8810\n",
            "Epoch 28/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2775 - acc: 0.8916\n",
            "Epoch 29/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2769 - acc: 0.8923\n",
            "Epoch 30/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2686 - acc: 0.9103\n",
            "Epoch 31/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2735 - acc: 0.9086\n",
            "Epoch 32/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2527 - acc: 0.9164\n",
            "Epoch 33/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2332 - acc: 0.9310\n",
            "Epoch 34/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2441 - acc: 0.9216\n",
            "Epoch 35/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2316 - acc: 0.9246\n",
            "Epoch 36/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2236 - acc: 0.9322\n",
            "Epoch 37/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2295 - acc: 0.9239\n",
            "Epoch 38/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2284 - acc: 0.9051\n",
            "Epoch 39/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2395 - acc: 0.9133\n",
            "Epoch 40/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2274 - acc: 0.9138\n",
            "Epoch 41/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2017 - acc: 0.9171\n",
            "Epoch 42/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2022 - acc: 0.9230\n",
            "Epoch 43/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2219 - acc: 0.9091\n",
            "Epoch 44/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2024 - acc: 0.9298\n",
            "Epoch 45/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1784 - acc: 0.9355\n",
            "Epoch 46/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1989 - acc: 0.9232\n",
            "Epoch 47/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1741 - acc: 0.9305\n",
            "Epoch 48/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1721 - acc: 0.9263\n",
            "Epoch 49/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1885 - acc: 0.9115\n",
            "Epoch 50/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1731 - acc: 0.9193\n",
            "Epoch 51/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1593 - acc: 0.9364\n",
            "Epoch 52/80\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1625 - acc: 0.9459\n",
            "Epoch 53/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1505 - acc: 0.9501\n",
            "Epoch 54/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1607 - acc: 0.9507\n",
            "Epoch 55/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1562 - acc: 0.9487\n",
            "Epoch 56/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1539 - acc: 0.9549\n",
            "Epoch 57/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1313 - acc: 0.9560\n",
            "Epoch 58/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1254 - acc: 0.9651\n",
            "Epoch 59/80\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1401 - acc: 0.9603\n",
            "Epoch 60/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1294 - acc: 0.9665\n",
            "Epoch 61/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1206 - acc: 0.9754\n",
            "Epoch 62/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1217 - acc: 0.9710\n",
            "Epoch 63/80\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1254 - acc: 0.9700\n",
            "Epoch 64/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1167 - acc: 0.9700\n",
            "Epoch 65/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1209 - acc: 0.9729\n",
            "Epoch 66/80\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1238 - acc: 0.9698\n",
            "Epoch 67/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1132 - acc: 0.9775\n",
            "Epoch 68/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1179 - acc: 0.9714\n",
            "Epoch 69/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1177 - acc: 0.9785\n",
            "Epoch 70/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0946 - acc: 0.9821\n",
            "Epoch 71/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1076 - acc: 0.9712\n",
            "Epoch 72/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1033 - acc: 0.9743\n",
            "Epoch 73/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1074 - acc: 0.9743\n",
            "Epoch 74/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1011 - acc: 0.9759\n",
            "Epoch 75/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1002 - acc: 0.9788\n",
            "Epoch 76/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0872 - acc: 0.9814\n",
            "Epoch 77/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0949 - acc: 0.9773\n",
            "Epoch 78/80\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1028 - acc: 0.9773\n",
            "Epoch 79/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0828 - acc: 0.9835\n",
            "Epoch 80/80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0933 - acc: 0.9726\n",
            "CPU times: user 1.91 s, sys: 209 ms, total: 2.12 s\n",
            "Wall time: 2.02 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NZTu3pg1IO-"
      },
      "source": [
        "# **Training loss visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "5gmQ4jMqvbvO",
        "outputId": "3f4d2c84-f0b2-4419-f68b-008899319dd0"
      },
      "source": [
        "history_dict = MODEL1.history\n",
        "acc_values = history_dict['loss']\n",
        "epoches = np.arange(1,len(history_dict['acc'])+1)\n",
        "plt.plot(epoches,acc_values,'r',label=\"Training Accuracy\")\n",
        "plt.title('Training loss')\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5imVa-A1c9s"
      },
      "source": [
        "# **Evaluation Step**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n40sn567tUhB",
        "outputId": "a8d9bc34-9172-43b2-98a3-3bcff5e71bef"
      },
      "source": [
        "loss , acc = network1.evaluate(test_data,test_labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0990 - acc: 0.9787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJTWugDN1hTZ"
      },
      "source": [
        "# **Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJiWAhdWtC6o"
      },
      "source": [
        "prediction_test_data = test_data\n",
        "predictions = network1.predict(prediction_test_data)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSwq41nKtIcV",
        "outputId": "ec4742f4-ef26-4e62-bd6c-d9ece37b49cc"
      },
      "source": [
        "print(f\"Alhumdullah got accuracy upto {acc*100}%\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alhumdullah got accuracy upto 97.8723406791687%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u7OHEtwXHTz"
      },
      "source": [
        "predictions = np.round(predictions)\n",
        "test_labels2 = test_labels"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOgNOnYC10DR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f12f4b-70eb-4ea9-e754-63b464cf1840"
      },
      "source": [
        "tf.math.confusion_matrix(\n",
        "    test_labels2, predictions, num_classes=None, weights=None, dtype=tf.dtypes.int32,\n",
        "    name=None\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[118,   1],\n",
              "       [  2,  20]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8bNiPSu7MIm"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}